# Source:Niebezpiecznik, URL:https://feeds.feedburner.com/niebezpiecznik/, language:pl-PL

## Wstrzyknęli backdoor do AI. Czy &#8220;zatrutą&#8221; sztuczną inteligencję da się oduczyć popełniania błędów?
 - [https://niebezpiecznik.pl/post/wstrzykneli-backdoor-do-ai](https://niebezpiecznik.pl/post/wstrzykneli-backdoor-do-ai)
 - RSS feed: https://feeds.feedburner.com/niebezpiecznik/
 - date published: 2024-01-18T12:16:27+00:00

<a href="https://niebezpiecznik.pl/post/wstrzykneli-backdoor-do-ai/"><img align="left" alt="" class="alignleft tfe wp-post-image" height="100" hspace="5" src="https://niebezpiecznik.pl/wp-content/uploads/2024/01/po-tuningu-150x150.png" width="100" /></a>Świadomość ryzyk związanych z AI wydaje się rosnąć. Na modnych debatach i panelach o zagrożeniach AI omawia się problemy programowania wspomaganego AI, bughuntingu, prompt enginieeringu, socjotechnik wspieranych AI itd. Ryzyka najlepiej jest analizować zawczasu, ale wciąż zdarza się, że ktoś bardzo pomysłowy wymyśli nowy problem: załóżmy, że twórca modelu sztucznej inteligencji (LLM) wbuduje w niego [&#8230;]

