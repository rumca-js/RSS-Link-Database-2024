[{"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-08-22T20:14:08+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone! I'm excited to announce the release of <strong>ScrapeBnB</strong>, a new Airbnb property and listings scraper. It's available as an npm package, making it easy to integrate into your projects or frameworks of choice. Whether you're working on a personal project, doing market research, or building something more complex, ScrapeBnB can help streamline your workflow.</p> <p>\ud83d\udd27 K<strong>ey Features:</strong></p> <ul> <li>Easy to install and use in any Node.js environment.</li> <li>Flexible and adaptable to different use cases.</li> <li>Regularly updated to handle changes in Airbnb's site structure.</li> </ul> <p>If you find it helpful or just want to support its development, I\u2019d greatly appreciate if you could leave a star on the GitHub repo! \u2b50</p> <p>\ud83d\udc49 <a href=\"https://github.com/fauxir/ScrapeBnB\">Check it out here</a></p> <p>Thanks for your support, and feel free to reach out if you have any feedback or questions!</p> </div><!-- SC_ON --> &", "id": 1044658, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1eytbyg/scrapebnb_airbnb_property_and_listings_scraper_as", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "ScrapeBnB - Airbnb Property and Listings Scraper as NPM package", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-08-22T19:28:50+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I'm trying to web scrap product details (title, price, picture) from Aliexpress.com website, so i use the official API, but it takes too much time to respond. can you please tell me how to scrap these details from the page itself ?</p> <p>thank you.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/smart_linux\"> /u/smart_linux </a> <br /> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1eys8j4/aliexpress_product_details/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1eys8j4/aliexpress_product_details/\">[comments]</a></span>", "id": 1044315, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1eys8j4/aliexpress_product_details", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "aliexpress product details", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-08-22T19:00:02+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi,</p> <p>I tried scraping a mobile app using the normal route:</p> <p>1) Install the app (or APK) on a mobile device<br /> 2) Install MITM proxy or fiddler on my PC<br /> 3) Configure CA cert and proxy settings on the mobile device to use fiddler (on PC) as proxy<br /> 4) Run the app<br /> 5) Monitor traffic on fiddler and find a way to scrape data using the app endpoints</p> <p><strong>Here comes the challenge. I live in country X. The app only works on country Y.</strong> </p> <p>I cannot use VPN on my mobile device (to country Y) since for the network traffic to be captured on fiddler both my PC and mobile device need to be on the same network.</p> <p>Is there a way to get around this? Appreciate your thoughts on this!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ScaredPear5282\"> /u/ScaredPear5282 </a> <br /> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1eyrjci/tricky_situation_in_scraping", "id": 1044316, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1eyrjci/tricky_situation_in_scraping_a_mobile_app_that", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Tricky situation in scraping a mobile app that whitelists regions", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-08-22T18:01:54+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I am considering taking a course which uses R for web scraping. The course is focused on web scraping and statistical analysis. </p> <p>I understand that R is very powerful for all sorts of statistical analysis, but do websites which track the prices of various goods (airline tickets, video games, amazon products) use R? Can such websites use R? </p> <p>Asking, as I am interested in using webscraping, not just for statistical analysis, but maybe to build such a website or app in the future. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/morecoffeemore\"> /u/morecoffeemore </a> <br /> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1eyq471/do_sites_which_rely_on_web_scraping_use_r/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1eyq471/do_sites_which_rely_on_web_scraping_use_r/\">[comments]</a></span>", "id": 1043868, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1eyq471/do_sites_which_rely_on_web_scraping_use_r", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Do sites which rely on web scraping use R?", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-08-22T13:53:13+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I currently maintain a rather complex scraper for personal purposes, which reuses a session login that I manually create and then continually autobrowses a website and pulls data off of it that it finds interesting.</p> <p>The Cloudflare bot protection on this site has gotten a lot stronger over the past couple of months. My current script implements pretty much every avoidance strategy, with long randomized waits and a probabilistic/time-based approach as to which specific URLs it ends up visiting on the site. Up until recently, I'd hit a turnstile every few days, at which point I'd clear the session, re-log, and then get another few days.</p> <p>Lately, it's getting detected every few hours, and I'm looking for a new solution/approach. It seems like a solver API might be the easiest and cheapest thing to integrate into how the script currently operates, but I don't see good examples for how to implement that, nor do I see consistent feedback that an", "id": 1042957, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1eyjwbd/suggestions_for_complex_browserbased", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Suggestions for complex browser-based (Python/Selenium/geckodriver) scraper?", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-08-22T11:00:36+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I'm new to Web Scraping </p> <p>I have this <a href=\"https://code.rdkcentral.com/r/c/rdkb/components/opensource/ccsp/Utopia/+/91978\">website</a> from there I want to extract <a href=\"https://jira.rdkcentral.com/jira/browse/RDKBDEV-2026\">RDKBDEV-2026</a> link, I have used Beautifulsoup, Selenium, Webdriver but nothing is able to extract the proper content, I saved the extracted content in .html but the content is missing. But when I'm doing right click Save as option as .html and I open that html file in editor I can see what I want to extract and able to extract also</p> <p>Here's the code I used which is not working</p> <blockquote> <p>import requests</p> <p>from bs4 import BeautifulSoup</p> <p>from selenium import webdriver</p> <p>from selenium.webdriver.chrome.service import Service</p> <p>from <a href=\"http://selenium.webdriver.common.by\">selenium.webdriver.common.by</a> import By</p> <p>from selenium.webdriver.support.ui import WebDriverWait</p> ", "id": 1040828, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1eygexd/how_to_extract_content_from_webpages_like_this", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "How to extract content from webpages like this", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-08-22T09:43:41+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I made a proxyscrapper which scrapes proxies from everywhere, checks it, timeout is set to 100 so only fast valid proxies are scrapped. would appreciate if you would visit and if possible star this repo. thank you.</p> <p><a href=\"https://github.com/zenjahid/FreeProxy4u\">https://github.com/zenjahid/FreeProxy4u</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/GoingGeek\"> /u/GoingGeek </a> <br /> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1eyf77m/made_a_proxyscrapper/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1eyf77m/made_a_proxyscrapper/\">[comments]</a></span>", "id": 1040826, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1eyf77m/made_a_proxyscrapper", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Made a proxyscrapper", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-08-22T07:49:39+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>connect form puppeteer-real-browser is not compatible with puppeteer.launch() method</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/xinhaiw\"> /u/xinhaiw </a> <br /> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1eydkof/how_to_combine_puppeteercluster_with/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1eydkof/how_to_combine_puppeteercluster_with/\">[comments]</a></span>", "id": 1040829, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1eydkof/how_to_combine_puppeteercluster_with", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "How to combine puppeteer-cluster with puppeteer-real-browser", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-08-22T07:39:41+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I'm trying to fetch some data from a market exchange website using <strong>python</strong> with <strong>httpx</strong> library,<br /> when making a request to the site api I get an error message..</p> <p><code>httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)</code></p> <p>but when I ignore the ssl verification <code>verify = False</code> I could bypass this issue and get the desired data.</p> <p>I have checked the website ssl certificate and the result was that there is <strong>Invalid intermediate certificate</strong> and it uses <strong>TLSv1 protocol</strong>.</p> <p>My question here, could they use the invalid certificate intentionally? as I have read some websites use it to prevent scraping data somehow but would a governmental website use this method too?!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Bassel_Fathy\"> /u/Bass", "id": 1040827, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1eydfnf/facing_invalid_intermediate_certificate_with_a", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "facing Invalid intermediate certificate with a governmental site! [SSL: CERTIFICATE_VERIFY_FAILED]", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-08-22T05:18:29+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Check out my first ever Micro-SaaS! It is a free online comment scraper tool for Youtube. You can search any word or phrase in a video and find how many people commented that word! Best for finding funny comments! Go check it out now: <a href=\"https://www.ytcommentscraper.com/\">https://www.ytcommentscraper.com/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/LackComprehensive469\"> /u/LackComprehensive469 </a> <br /> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1eybcmn/youtube_comment_scraper/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1eybcmn/youtube_comment_scraper/\">[comments]</a></span>", "id": 1040830, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1eybcmn/youtube_comment_scraper", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Youtube Comment Scraper!", "user": null, "vote": 0}]