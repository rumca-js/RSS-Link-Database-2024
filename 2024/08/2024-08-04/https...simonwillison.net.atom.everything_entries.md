# Source:Simon Willison's Weblog, URL:https://simonwillison.net/atom/everything, language:en-us

## There’s a Tool to Catch Students Cheating With ChatGPT. OpenAI Hasn’t Released It.
 - [https://simonwillison.net/2024/Aug/4/watermarking/#atom-everything](https://simonwillison.net/2024/Aug/4/watermarking/#atom-everything)
 - RSS feed: https://simonwillison.net/atom/everything
 - date published: 2024-08-04T19:11:13+00:00

<p><strong><a href="https://www.wsj.com/tech/ai/openai-tool-chatgpt-cheating-writing-135b755a?st=830dm1b5txdsqx4">There’s a Tool to Catch Students Cheating With ChatGPT. OpenAI Hasn’t Released It.</a></strong></p>
This attention-grabbing headline from the Wall Street Journal makes the underlying issue here sound less complex, but there's a lot more depth to it.</p>
<p>The story is actually about watermarking: embedding hidden patterns in generated text that allow that text to be identified as having come out of a specific LLM.</p>
<p>OpenAI evidently have had working prototypes of this for a couple of years now, but they haven't shipped it as a feature. I think this is the key section for understanding why:</p>
<blockquote>
<p>In April 2023, OpenAI commissioned a survey that showed people worldwide supported the idea of an AI detection tool by a margin of four to one, the internal documents show. </p>
<p>That same month, OpenAI surveyed ChatGPT users and found 69% believe cheating det

## How I Use "AI" by Nicholas Carlini
 - [https://simonwillison.net/2024/Aug/4/how-i-use-ai-by-nicholas-carlini/#atom-everything](https://simonwillison.net/2024/Aug/4/how-i-use-ai-by-nicholas-carlini/#atom-everything)
 - RSS feed: https://simonwillison.net/atom/everything
 - date published: 2024-08-04T16:55:33+00:00

<p><strong><a href="https://nicholas.carlini.com/writing/2024/how-i-use-ai.html">How I Use &quot;AI&quot; by Nicholas Carlini</a></strong></p>
Nicholas is an author on <a href="https://arxiv.org/abs/2307.15043">Universal and Transferable Adversarial Attacks on Aligned Language Models</a>, one of my favorite LLM security papers from last year. He understands the flaws in this class of technology at a deeper level than most people.</p>
<p>Despite that, this article describes several of the many ways he still finds utility in these models in his own work:</p>
<blockquote>
<p>But the reason I think that the recent advances we've made aren't just hype is that, over the past year, I have spent at least a few hours every week interacting with various large language models, and have been consistently impressed by their ability to solve increasingly difficult tasks I give them. And as a result of this, I would say I'm at least 50% faster at writing code for both my research projects and my sid

