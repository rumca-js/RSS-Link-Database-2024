# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## Microsoft learn documentation
 - [https://www.reddit.com/r/webscraping/comments/1ejv0co/microsoft_learn_documentation](https://www.reddit.com/r/webscraping/comments/1ejv0co/microsoft_learn_documentation)
 - RSS feed: https://www.reddit.com/r/webscraping/.rss
 - date published: 2024-08-04T13:16:15+00:00

<!-- SC_OFF --><div class="md"><p>I am new to scraping and would like to know what is the level of difficulty to scrape a whole product documentation, let say Power Apps, and save it in pdf format. Like I said, I’m new to this, but I know that I don’t want to do each page manually and there must be a better way. What would be the easiest way to do so?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Alno1"> /u/Alno1 </a> <br /> <span><a href="https://www.reddit.com/r/webscraping/comments/1ejv0co/microsoft_learn_documentation/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1ejv0co/microsoft_learn_documentation/">[comments]</a></span>

## Scraping Google Shopping pricing page
 - [https://www.reddit.com/r/webscraping/comments/1ejup0c/scraping_google_shopping_pricing_page](https://www.reddit.com/r/webscraping/comments/1ejup0c/scraping_google_shopping_pricing_page)
 - RSS feed: https://www.reddit.com/r/webscraping/.rss
 - date published: 2024-08-04T13:00:58+00:00

<!-- SC_OFF --><div class="md"><p>Is there a DIY method for scraping Google Shopping pricing pages? I've come across a paid solution that works flawlessly and provides a convenient JSON output, but it's quite pricey at $50 for around 20k requests. That's a bit steep for my hobby project. Any suggestions for more budget-friendly alternatives that could achieve similar results?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Kyxstrez"> /u/Kyxstrez </a> <br /> <span><a href="https://www.reddit.com/r/webscraping/comments/1ejup0c/scraping_google_shopping_pricing_page/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1ejup0c/scraping_google_shopping_pricing_page/">[comments]</a></span>

## Scraping Google Shopping pricing page
 - [https://www.reddit.com/r/webscraping/comments/1ejs8ou/scraping_google_shopping_pricing_page](https://www.reddit.com/r/webscraping/comments/1ejs8ou/scraping_google_shopping_pricing_page)
 - RSS feed: https://www.reddit.com/r/webscraping/.rss
 - date published: 2024-08-04T10:35:27+00:00

<!-- SC_OFF --><div class="md"><p>Is there a DIY method for scraping Google Shopping pricing pages? I've come across <a href="https://oxylabs.io/products/scraper-api/ecommerce/google-shopping">this Oxylabs API</a> that works flawlessly and provides a convenient JSON output, but it's quite pricey at $50 for 17,500 requests. That's a bit steep for my hobby project. Any suggestions for more budget-friendly alternatives that could achieve similar results?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Kyxstrez"> /u/Kyxstrez </a> <br /> <span><a href="https://www.reddit.com/r/webscraping/comments/1ejs8ou/scraping_google_shopping_pricing_page/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1ejs8ou/scraping_google_shopping_pricing_page/">[comments]</a></span>

## guys, i wrote a very silly reddit scraper in python today, made with pure requests and bs4 :3
 - [https://www.reddit.com/r/webscraping/comments/1ejkn8y/guys_i_wrote_a_very_silly_reddit_scraper_in](https://www.reddit.com/r/webscraping/comments/1ejkn8y/guys_i_wrote_a_very_silly_reddit_scraper_in)
 - RSS feed: https://www.reddit.com/r/webscraping/.rss
 - date published: 2024-08-04T02:29:55+00:00

<table> <tr><td> <a href="https://www.reddit.com/r/webscraping/comments/1ejkn8y/guys_i_wrote_a_very_silly_reddit_scraper_in/"> <img alt="guys, i wrote a very silly reddit scraper in python today, made with pure requests and bs4 :3" src="https://preview.redd.it/qan0xhv06kgd1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=986eb01f471026e68ac6903f1d7a36c453caa018" title="guys, i wrote a very silly reddit scraper in python today, made with pure requests and bs4 :3" /> </a> </td><td> &#32; submitted by &#32; <a href="https://www.reddit.com/user/zeper56"> /u/zeper56 </a> <br /> <span><a href="https://i.redd.it/qan0xhv06kgd1.png">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1ejkn8y/guys_i_wrote_a_very_silly_reddit_scraper_in/">[comments]</a></span> </td></tr></table>

## AttributeError: module 'selenium.webdriver' has no attribute 'PhantomJS'
 - [https://www.reddit.com/r/webscraping/comments/1ejka2d/attributeerror_module_seleniumwebdriver_has_no](https://www.reddit.com/r/webscraping/comments/1ejka2d/attributeerror_module_seleniumwebdriver_has_no)
 - RSS feed: https://www.reddit.com/r/webscraping/.rss
 - date published: 2024-08-04T02:10:03+00:00

<!-- SC_OFF --><div class="md"><p>I have the selenium 3.3 which supports PhantomJS but I still get this error when trying to use mediascraper. <a href="https://github.com/elvisyjlin/media-scraper/blob/master/README.md">https://github.com/elvisyjlin/media-scraper/blob/master/README.md</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/giosthebest"> /u/giosthebest </a> <br /> <span><a href="https://www.reddit.com/r/webscraping/comments/1ejka2d/attributeerror_module_seleniumwebdriver_has_no/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1ejka2d/attributeerror_module_seleniumwebdriver_has_no/">[comments]</a></span>

