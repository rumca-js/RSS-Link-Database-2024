# Source:Electronic Frontier Foundation, URL:https://www.eff.org/rss/updates.xml, language:en

## Worried about AI voice clone scams? Create a family password
 - [https://www.eff.org/deeplinks/2024/01/worried-about-ai-voice-clone-scams-create-family-password](https://www.eff.org/deeplinks/2024/01/worried-about-ai-voice-clone-scams-create-family-password)
 - RSS feed: https://www.eff.org/rss/updates.xml
 - date published: 2024-02-01T00:42:08+00:00

<div class="field field--name-body field--type-text-with-summary field--label-hidden"><div class="field__items"><div class="field__item even"><p><span>Your grandfather receives a call late at night from a person pretending to be you. The caller says that you are in jail or have been kidnapped and that they need money urgently to get you out of trouble. Perhaps they then bring on a fake police officer or kidnapper to heighten the tension. The money, of course, should be wired right away to an unfamiliar account at an unfamiliar bank. </span></p>

<p><span>It’s a classic and common scam, and like many scams it relies on a scary, urgent scenario to override the victim’s common sense and make them more likely to send money. Now, scammers are reportedly experimenting with a way to further heighten that panic by playing </span><a href="https://www.cnn.com/2023/04/29/us/ai-scam-calls-kidnapping-cec/index.html"><span>a simulated recording of “your” voice</span></a><span>. Fortunately

