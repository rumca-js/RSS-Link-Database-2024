# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## Can someone help me from which company this captcha is?
 - [https://www.reddit.com/r/webscraping/comments/1fzdl8m/can_someone_help_me_from_which_company_this](https://www.reddit.com/r/webscraping/comments/1fzdl8m/can_someone_help_me_from_which_company_this)
 - RSS feed: $source
 - date published: 2024-10-08T23:20:14+00:00

<table> <tr><td> <a href="https://www.reddit.com/r/webscraping/comments/1fzdl8m/can_someone_help_me_from_which_company_this/"> <img src="https://b.thumbs.redditmedia.com/AqqK1BQ4XT5zf9K0PBVBMHN3pgCgybXI0r7b9IuVH6c.jpg" alt="Can someone help me from which company this captcha is?" title="Can someone help me from which company this captcha is?" /> </a> </td><td> <!-- SC_OFF --><div class="md"><p>Hi everyone,</p> <p>I have been struggling lately to get rid of the following captcha, I can find anything online on who &quot;Fairlane&quot; is and how this has been implemented in their website. If someone has some tips on how to circumvent these that would be of a lot of help!</p> <p>Thanks in advance!</p> <p><a href="https://preview.redd.it/sx4jh8nh8mtd1.png?width=1450&amp;format=png&amp;auto=webp&amp;s=7017b05b613bc801e995389ebf8c0379d2a16300">https://preview.redd.it/sx4jh8nh8mtd1.png?width=1450&amp;format=png&amp;auto=webp&amp;s=7017b05b613bc801e995389ebf8c0379d2a16300</a></p> </div><!-- S

## Scraping popup text?
 - [https://www.reddit.com/r/webscraping/comments/1fz7c93/scraping_popup_text](https://www.reddit.com/r/webscraping/comments/1fz7c93/scraping_popup_text)
 - RSS feed: $source
 - date published: 2024-10-08T18:47:33+00:00

<!-- SC_OFF --><div class="md"><p>There are many plugins for capturing changes on a website, but none seem to capture pop-ups. The popups I am interested in are just the text, I don&#39;t care about capturing the graphics or screenshot. Ideally, it would integrate screen refresh (the popup trigger) then record the timestamp and text of the popup.</p> <p>I&#39;m willing to pay a bit for an effective app.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Appropriate-Week-718"> /u/Appropriate-Week-718 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fz7c93/scraping_popup_text/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1fz7c93/scraping_popup_text/">[comments]</a></span>

## How to aggregate products listed on a website?
 - [https://www.reddit.com/r/webscraping/comments/1fz2fvf/how_to_aggregate_products_listed_on_a_website](https://www.reddit.com/r/webscraping/comments/1fz2fvf/how_to_aggregate_products_listed_on_a_website)
 - RSS feed: $source
 - date published: 2024-10-08T15:23:48+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;m very new to all of this and just had an idea that I&#39;d like to try out. I want to gather products from a website that only contains a specific material into a database. So if you have a bunch of clothes on a website from uniqlo, I&#39;d like to get all the cotton items from that page. The issue is that the attribute of the item is only shown once clicked into that item and scrolling down to the items description. I realised this when I tried webscraping. Has anyone figured a way to do this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/toottootmcgroot"> /u/toottootmcgroot </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fz2fvf/how_to_aggregate_products_listed_on_a_website/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1fz2fvf/how_to_aggregate_products_listed_on_a_website/">[comments]</a></span>

## Most cost effective all-in-one tool to scrape Datadome frequently
 - [https://www.reddit.com/r/webscraping/comments/1fz2b03/most_cost_effective_allinone_tool_to_scrape](https://www.reddit.com/r/webscraping/comments/1fz2b03/most_cost_effective_allinone_tool_to_scrape)
 - RSS feed: $source
 - date published: 2024-10-08T15:18:09+00:00

<!-- SC_OFF --><div class="md"><p>In the past I&#39;ve had some success monitoring/scraping Klwines.com which is protected by Datadome. Mainly using curl_cffi and undetected_playwright. </p> <p>But recently I am, I am just getting blocked continuously. What is a good all-in-one tool that is not crazy expensive to help me get around Datadome more effectively?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Daednoise"> /u/Daednoise </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fz2b03/most_cost_effective_allinone_tool_to_scrape/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1fz2b03/most_cost_effective_allinone_tool_to_scrape/">[comments]</a></span>

## Webscraping Job Aggregator for Non Technical Founder
 - [https://www.reddit.com/r/webscraping/comments/1fz0qlq/webscraping_job_aggregator_for_non_technical](https://www.reddit.com/r/webscraping/comments/1fz0qlq/webscraping_job_aggregator_for_non_technical)
 - RSS feed: $source
 - date published: 2024-10-08T14:11:11+00:00

<!-- SC_OFF --><div class="md"><p>What&#39;s up guys,</p> <p>I know its a long shot here but my co founders and I are really looking to pivot our current business model and scale down to build a job aggregator website instead of the multi-functioning platform we had built. I&#39;ve been researching like crazy any kind of simple and effective ways to build a web scraper that collects jobs from different URLs we have saved, grabs certain job postings we want displayed on our aggregator, and configures the job posting details in a simple format to be posted on our website with an &quot;apply now&quot; button directing them back to the original source.</p> <p>We have an excel sheet going with all of the URL&#39;s to scrape including the keywords needed to refine them as much as possible so that only the jobs we want to scrape will populate (although its not always perfect).</p> <p>I figured we could use AI to configure them once we collect the datasets but this all seems a bit over our he

## Hero
 - [https://www.reddit.com/r/webscraping/comments/1fyos3y/hero](https://www.reddit.com/r/webscraping/comments/1fyos3y/hero)
 - RSS feed: $source
 - date published: 2024-10-08T01:51:45+00:00

<!-- SC_OFF --><div class="md"><p>has anyone used Hero, will it bypass cloudflare? would you recommend it for concurrent undetected scraping? Any advices? I am using undetected playwright and the concurrent contexts is not fast enough for me (network IO wise)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/escapethetrials"> /u/escapethetrials </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fyos3y/hero/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1fyos3y/hero/">[comments]</a></span>

## Any online xpath 2.0 tester that you can recommend?
 - [https://www.reddit.com/r/webscraping/comments/1fynwkm/any_online_xpath_20_tester_that_you_can_recommend](https://www.reddit.com/r/webscraping/comments/1fynwkm/any_online_xpath_20_tester_that_you_can_recommend)
 - RSS feed: $source
 - date published: 2024-10-08T01:07:14+00:00

<!-- SC_OFF --><div class="md"><p>Title. Chrome/FF/etc dev consoles use Xpath 1.0. Xpather sometimes works, sometimes is not selecting any items even for &quot;//div&quot;.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/MorePeppers9"> /u/MorePeppers9 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fynwkm/any_online_xpath_20_tester_that_you_can_recommend/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1fynwkm/any_online_xpath_20_tester_that_you_can_recommend/">[comments]</a></span>

