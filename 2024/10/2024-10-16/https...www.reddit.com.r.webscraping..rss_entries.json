[{"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-16T19:39:08+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello,</p> <p>I&#39;d like to scrape property tax information from a county like, <a href=\"https://www.acgov.org/ptax_pub_app/RealSearchInit.do?showSearchParmsFromLookup=true\">Alameda County</a>, and have it spit out a list of APNs / Addresses that are delinquent on their property taxes and the amount. An example property is 3042 Ford St in Oakland that is delinquent. </p> <p>Is there a way to do this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/raiderdude56\"> /u/raiderdude56 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g5824d/scrape_property_tax_data/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g5824d/scrape_property_tax_data/\">[comments]</a></span>", "id": 1337360, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g5824d/scrape_property_tax_data", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Scrape Property Tax Data", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-16T19:16:42+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone!</p> <p>I have a review scraping code in Python and automated scrolling setup in place.</p> <p>There is this location with almost 16k reviews. However, when I reach a certain amount (~5000) of reviews after scrolling (based on my code&#39;s count), Google will stop showing more reviews and hence my scraper won&#39;t get anymore reviews, which means that 11k reviews were going missing.</p> <p><a href=\"https://www.google.com/maps/place/?q=place_id:ChIJFVU9IBert5URU1sNDottiYM&amp;hl=en\">https://www.google.com/maps/place/?q=place_id:ChIJFVU9IBert5URU1sNDottiYM&amp;hl=en</a></p> <p>As an additional note, I have also tried sorting by &quot;Newest&quot;, &quot;More Relevant&quot; and rest of options of sorting. The one from &quot;Newest&quot; gave me the biggest amount of reviews.</p> <p>Any ideas on how to find out the 11k remaining reviews? Perhaps if anyone else has found a way to tackle their pagination and could share it, I would highly appr", "id": 1338120, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g57jvq/reviews_scraping_google_maps_doesnt_show_all_the", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Reviews Scraping - Google Maps doesn't show all the reviews", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-16T18:26:21+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m working on a research study that requires scraping around 9k of X tweets related to certain hashtags. Im wondering if there are some software with affordable pricing to do that automatically, knowing that Im not acknowledgeable about the field. I have searched a bit about this and I found some potential software like Brightdata. Is it feasible? And are there better alternatives? Thank you! </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/kandycane_47\"> /u/kandycane_47 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g56d9y/x_scraping_for_research_purposes/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g56d9y/x_scraping_for_research_purposes/\">[comments]</a></span>", "id": 1336992, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g56d9y/x_scraping_for_research_purposes", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "X scraping for research purposes", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-16T15:23:30+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I am scraping user data from shaadi.com , by using selenium to login and save it to a CSV , I\u2019m getting a lot of errors and confusion to handle it. Can anyone provide me the code for it? Please it would be a great help! this is for one of my clients!</p> <p>This is the Base code\u2014&gt;</p> <p>from selenium import webdriver from selenium.webdriver.common.by import By from selenium.webdriver.chrome.service import Service from selenium.webdriver.support.ui import WebDriverWait from selenium.webdriver.support import expected_conditions as EC from selenium.common.exceptions import TimeoutException from webdriver_manager.chrome import ChromeDriverManager import time import csv</p> <p>def wait_for_element(driver, xpath, timeout=10): print(f&quot;Waiting for element: {xpath}&quot;) return WebDriverWait(driver, timeout).until( EC.presence_of_element_located((By.XPATH, xpath)) )</p> <p>def click_element(driver, xpath): print(f&quot;Clicking element: {xpath}&quot;", "id": 1336993, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g51z1w/need_help", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Need help!", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-16T09:56:27+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m working on a project that requires retrieving GST data by PAN from the official GST portal (specifically from <a href=\"https://services.gst.gov.in/services/searchtpbypan\">https://services.gst.gov.in/services/searchtpbypan</a> ). However, I\u2019m running into issues with the CAPTCHA system, which prevents me from automating the data collection.</p> <p>Are there any government-approved APIs or datasets that provide GST-related information? Has anyone found ways to work with the GST authorities to get bulk data for analysis purposes? Other than api setu i applied but the rejected so i need , so please anyone help me to bypass the captcha</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Lopus_The_Rainmaker\"> /u/Lopus_The_Rainmaker </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g4vors/want_to_bypass_the_captcha_on_gst_website_for_web/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.", "id": 1333639, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g4vors/want_to_bypass_the_captcha_on_gst_website_for_web", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "want to bypass the Captcha on GST website for web scrapping", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-16T06:01:07+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I have a client who sells product on various region on Amazon, I am tasked with getting reviews consistently from all amazon stores. I keep on getting blocked by Amazon.</p> <p>Any thoughts? Thanks in advance!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Cautious_Bug_1905\"> /u/Cautious_Bug_1905 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g4sl5g/help_with_amazon_review_scraping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g4sl5g/help_with_amazon_review_scraping/\">[comments]</a></span>", "id": 1332668, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g4sl5g/help_with_amazon_review_scraping", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Help with Amazon Review Scraping", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-16T00:43:35+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I want to create a simple game that compares changes in a cryptos info hour to hour. So I would need a bot that collects that info and keeps a log of it hourly and when the next hour comes along you would guess if the info went up or down. How would I go about this? I can\u2019t code myself so I would have to find someone but i still want to know how to do it. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Localbabysitterclub\"> /u/Localbabysitterclub </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g4n2ni/i_want_to_collect_and_log_hourly_data_on_certain/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g4n2ni/i_want_to_collect_and_log_hourly_data_on_certain/\">[comments]</a></span>", "id": 1331768, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g4n2ni/i_want_to_collect_and_log_hourly_data_on_certain", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "I want to collect and log hourly data on certain cryptos.", "vote": 0}]