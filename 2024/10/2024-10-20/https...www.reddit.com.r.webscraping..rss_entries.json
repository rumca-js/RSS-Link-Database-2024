[{"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-20T23:00:34+00:00", "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1g8bk07/what_is_ioblackbox/\"> <img src=\"https://preview.redd.it/2y1lxqq2szvd1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fc6da08cc833a21ffc71efabf03fdb44c4ff3bf5\" alt=\"What is ioblackbox\" title=\"What is ioblackbox\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Question is in title. I am trying to login to mypoints.com via requests. No idea what this is or how to generate or scrape it. Google was no help. Found a few GitHub projects by the name black box that where unrelated. I am just looking for anyone that knows what this is and what purpose it servers and maybe even knows how to bypass it.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ultimategamester309\"> /u/ultimategamester309 </a> <br/> <span><a href=\"https://i.redd.it/2y1lxqq2szvd1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g8bk07/what_is_ioblackbox/\">[comme", "id": 1358678, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g8bk07/what_is_ioblackbox", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 86, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": "https://preview.redd.it/2y1lxqq2szvd1.png?width=640&crop=smart&auto=webp&s=fc6da08cc833a21ffc71efabf03fdb44c4ff3bf5", "title": "What is ioblackbox", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-20T22:28:12+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I recently started a job. A big part of how I\u2019ll solve some of our problems is via web scraping, and probably a lot of .gov sites, not very intensively though. It\u2019s been a while since ive set up a scraper.</p> <p>So I set one up that worked perfectly in my local dockerized environment. Then when I pushed it to GCP my requests failed. It seems the .gov site blocks requests from GCP IP ranges, I\u2019m just getting empty responses now. </p> <p>I\u2019ve tried a handful of proxy services, but two prohibited access to .gov sites with their proxies, through 403 errors. One wants to KYC me and charge at least $500 for access. I sent a query email to another before I purchased anything. All they said was that they prohibit illegal activity.</p> <p>What gives? Is this a new obstacle in the space? What do you all do when you must scrape a .gov site?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Delicious-Cicada9307\"> /u/Delicious", "id": 1358679, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g8avy5/scraping_gov_sites", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Scraping .gov sites", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-20T22:17:58+00:00", "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1g8aoaj/what_is_ioblackbox/\"> <img src=\"https://preview.redd.it/gibimc7hkzvd1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fb2c0f03bfae3760abed8d9e7f0a19c9a07ef6fb\" alt=\"What is ioblackbox\" title=\"What is ioblackbox\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Here is picture of the body of a login request I am trying to recreate. Does anyone know what ioblackbox is and how I could obtain this key. I do not see it any any previous requests captured. Google did not really help. I see two GitHub projects one that was for profiling devices fraud risk in mobile apps and another for storing secrets in git. Someone please shed some light on this or other ways I could go about this. </p> <p>Am currently using Javas http client.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ultimategamester309\"> /u/ultimategamester309 </a> <br/> <span><a href=\"https://i.redd.it/gibimc7h", "id": 1358557, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g8aoaj/what_is_ioblackbox", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 86, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": "https://preview.redd.it/gibimc7hkzvd1.png?width=640&crop=smart&auto=webp&s=fb2c0f03bfae3760abed8d9e7f0a19c9a07ef6fb", "title": "What is ioblackbox", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-20T20:11:46+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello are their any books I can read on bypassing Akamai it\u2019s hard to find information about it. I managed to teach myself how to bypass cloudflare, the recaptcha\u2019s etc but I am struggling to learn how to bypass more advanced systems like PayPal, google etc. I know these websites don\u2019t use Akamai but I am also struggling on Akamai websites. </p> <p>If anyone has any books that can help me out please let me know.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/pasttortobi419\"> /u/pasttortobi419 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g87uah/bypassing_akamai_waf_login/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g87uah/bypassing_akamai_waf_login/\">[comments]</a></span>", "id": 1358132, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g87uah/bypassing_akamai_waf_login", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Bypassing Akamai waf login", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-20T20:03:51+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I want to scrape tweets with a specific geolocation and I set up for the basic plan of 100$ on X developers account however, they said the geolocation option isn&#39;t possible with that plan but there are other ways to get the user location, tried many scripts but it doesn&#39;t work! help plz i&#39;m really stuck...</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Working-Height1691\"> /u/Working-Height1691 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g87nnp/how_to_scrape_geolocated_tweets_using_x_api/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g87nnp/how_to_scrape_geolocated_tweets_using_x_api/\">[comments]</a></span>", "id": 1358680, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g87nnp/how_to_scrape_geolocated_tweets_using_x_api", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "How to scrape geolocated tweets using X API", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-20T17:33:03+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I want to start off with learning automated web scraping. And then eventually I would like to explore the field of bot development.Have no idea where to begin at. I am very much familiar with web dev and backend concepts. Also I have learnt python. I just need some guidance regarding where I should begin and what I should learn.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Turbulent_2006\"> /u/Turbulent_2006 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g844sy/i_need_some_guidance/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g844sy/i_need_some_guidance/\">[comments]</a></span>", "id": 1357689, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g844sy/i_need_some_guidance", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "I need some guidance..", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-20T16:21:12+00:00", "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1g82h31/poetry_foundation/\"> <img src=\"https://external-preview.redd.it/7d5IWz-htOGW1kprgnrUW39dSNgsCd4hA08KOmmxuOA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3e6d9c0d247d841231d378f71092004f53f1ee7f\" alt=\"Poetry Foundation\" title=\"Poetry Foundation\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I want to make a webscraper for poetry foundation. The current goal is to scrape for the title, author, word choice, and publication date. I&#39;ve coded in class before, but I&#39;ve never coded on my own. I thought this would be a nice project, so I tried but I couldn&#39;t get beautiful soup to work. Im working in powershell and I coded !pip beautfulsoup but only error popped up. I don&#39;t know what I&#39;m doing wrong, so I asked my professor for help. He said that it&#39;d be to hard, but I really want to try!! :) This is a project just for myself! I&#39;ll show the professor once I&#39;m done, so maybe ", "id": 1357468, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g82h31/poetry_foundation", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 86, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": "https://external-preview.redd.it/7d5IWz-htOGW1kprgnrUW39dSNgsCd4hA08KOmmxuOA.jpg?width=640&crop=smart&auto=webp&s=3e6d9c0d247d841231d378f71092004f53f1ee7f", "title": "Poetry Foundation", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-20T14:01:44+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m trying to scrape <a href=\"https://www.goodyearautoservice.com/en_US/tire-stores\">https://www.goodyearautoservice.com/en_US/tire-stores</a></p> <p>I have this code, but whenever I execute it I always get inconsistent states number (Either 37 or 50). It happens not only in the states directory but with the cities one. </p> <p>Even when using the same data provided in the AJAX requests (hardcoded cookies and headers) I get inconsistent results</p> <p>I also tried to use requests-html because maybe the content is loaded using js but still same thing</p> <p>This is the code for extracting the states urls:</p> <pre><code>class Scraper: base_url = &#39;https://www.goodyearautoservice.com&#39; def __init__(self): self.headers = { &#39;accept&#39;: &#39;text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8&#39;, &#39;accept-language&#39;: &#39;en-US,en;q=0.9&#39;, &#39;cache-control&#39;: &#39;max-age=0&#39;, ", "id": 1358133, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g7zds8/inconsistent_html_content_despite_mimicking_ajax", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Inconsistent HTML content Despite Mimicking AJAX Calls", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-20T04:05:26+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m trying to bypass a Cloudflare captcha on a website (<a href=\"https://quizlet.com\">https://quizlet.com</a>) from a Replit, but I&#39;m struggling to get it to work. Whenever I run code that works on my machine on the Replit, it gets blocked. I&#39;ve tried curl_cffi, cloudscraper, etc. How would I fix this? Any suggestions would be appreciated.<br/> Code:</p> <pre><code>import cloudscraper from curl_cffi import requests scrapper = cloudscraper.create_scraper() print(scrapper.get(&#39;https://quizlet.com&#39;).text) response = requests.get(url = &#39;https://quizlet.com&#39;, impersonate = &quot;chrome99_android&quot;) print(response.text) </code></pre> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Blooper_Glooper6872\"> /u/Blooper_Glooper6872 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g7qh2p/bypassing_cloudflare_from_a_replit/\">[link]</a></span> &#32; <span><a href=\"https://www.r", "id": 1355421, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g7qh2p/bypassing_cloudflare_from_a_replit", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Bypassing Cloudflare from a Replit", "vote": 0}]