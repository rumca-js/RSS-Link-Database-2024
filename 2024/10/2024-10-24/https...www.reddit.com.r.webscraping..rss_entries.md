# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## GLiNER vs NuExtract: Best 2024 Extractors for Custom Entity Types
 - [https://www.reddit.com/r/webscraping/comments/1gbb6ec/gliner_vs_nuextract_best_2024_extractors_for](https://www.reddit.com/r/webscraping/comments/1gbb6ec/gliner_vs_nuextract_best_2024_extractors_for)
 - RSS feed: $source
 - date published: 2024-10-24T19:31:34+00:00

&#32; submitted by &#32; <a href="https://www.reddit.com/user/vtempest"> /u/vtempest </a> <br/> <span><a href="https://medium.com/@alexgulakov/gliner-vs-nuextract-best-2024-extractors-for-custom-entity-types-d369eb65f1e1">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1gbb6ec/gliner_vs_nuextract_best_2024_extractors_for/">[comments]</a></span>

## Does clicking "load more comments" have to be rate limited?
 - [https://www.reddit.com/r/webscraping/comments/1gbaumm/does_clicking_load_more_comments_have_to_be_rate](https://www.reddit.com/r/webscraping/comments/1gbaumm/does_clicking_load_more_comments_have_to_be_rate)
 - RSS feed: $source
 - date published: 2024-10-24T19:17:40+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;m currently working on a script to extract all the comments from a social media/forum website&#39;s posts.</p> <p>On some posts, there are hundreds of thousands of comments hidden behind the &quot;load more comments&quot; button.</p> <p>I understand the importance of limiting queries so as not to be detected as a bot, however I want to make sure that this step is necessary in this case.</p> <p>Currently I&#39;m limiting my rate of expanding the comments by clicking only ~10 seconds (normally distributed).</p> <p>Is clicking the &quot;load more comments&quot; button the type of call that needs to be rate limited? Does clicking that button trigger the same network load to the servers as loading a new page?</p> <p>Are all the comments already actually loaded in the page, and clicking &quot;load more comments&quot; justs reveals them? Or does clicking result in a query of some kind on their backend?</p> <p>Thanks for your time</p> </div><!-- SC_ON 

## Can someone DM me ASAP. i have a doubt
 - [https://www.reddit.com/r/webscraping/comments/1gb9wq5/can_someone_dm_me_asap_i_have_a_doubt](https://www.reddit.com/r/webscraping/comments/1gb9wq5/can_someone_dm_me_asap_i_have_a_doubt)
 - RSS feed: $source
 - date published: 2024-10-24T18:38:18+00:00

<!-- SC_OFF --><div class="md"><p>So i have a doubt regarding P.R.O.X.I.E.S. And i did post my question earlier as well. TWICE!!. But it got removed on both the occasions. I just have one single question to ask.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Turbulent_2006"> /u/Turbulent_2006 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1gb9wq5/can_someone_dm_me_asap_i_have_a_doubt/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1gb9wq5/can_someone_dm_me_asap_i_have_a_doubt/">[comments]</a></span>

## Headless browsers are killing my wallet! Render or not to render?
 - [https://www.reddit.com/r/webscraping/comments/1gb78bp/headless_browsers_are_killing_my_wallet_render_or](https://www.reddit.com/r/webscraping/comments/1gb78bp/headless_browsers_are_killing_my_wallet_render_or)
 - RSS feed: $source
 - date published: 2024-10-24T16:46:35+00:00

<!-- SC_OFF --><div class="md"><p>Hey everyone, </p> <p>I&#39;m running a web scraper that processes thousands of pages daily to extract text content. Currently, I&#39;m using a headless browser for every page because many sites use client-side rendering (Next.js, React, etc.). While this ensures I don&#39;t miss any content, it&#39;s expensive and slow. </p> <p>I&#39;m looking to optimize this process by implementing a &quot;smart&quot; detection system:<br/> 1. First, make a simple GET request (fast &amp; cheap)<br/> 2. Analyze the response to determine if rendering is actually needed<br/> 3. Only use headless browser when necessary </p> <p>What would be a reliable strategy to detect if a page requires JavaScript rendering? Looking for approaches that would cover most common use cases while minimizing false negatives (missing content). </p> <p>Has anyone solved this problem before? Would love to hear about your experiences and solutions. </p> <p>Thanks in advance!</p> </div><!-- SC

## Best library for scraping Aliexpress?
 - [https://www.reddit.com/r/webscraping/comments/1gb6z55/best_library_for_scraping_aliexpress](https://www.reddit.com/r/webscraping/comments/1gb6z55/best_library_for_scraping_aliexpress)
 - RSS feed: $source
 - date published: 2024-10-24T16:36:02+00:00

<!-- SC_OFF --><div class="md"><p>What is the best library for scraping Aliexpress.com?</p> <p>The first hit on github is this: <a href="https://github.com/Ekans111/Aliexpress-scraper-without-api-free">Japanese Scraping</a></p> <p>Any tips?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/stvaccount"> /u/stvaccount </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1gb6z55/best_library_for_scraping_aliexpress/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1gb6z55/best_library_for_scraping_aliexpress/">[comments]</a></span>

## Best library for scraping Aliexpress?
 - [https://www.reddit.com/r/webscraping/comments/1gb4nkf/best_library_for_scraping_aliexpress](https://www.reddit.com/r/webscraping/comments/1gb4nkf/best_library_for_scraping_aliexpress)
 - RSS feed: $source
 - date published: 2024-10-24T14:59:19+00:00

<!-- SC_OFF --><div class="md"><p>What is the best (inofficial) library for scrapping Aliexpress.com?</p> <p>I found two libs on github: <a href="https://github.com/Ekans111/Aliexpress-scraper-without-api-free">Japanese Scraping</a>, and <a href="https://github.com/oxylabs/aliexpress-scraper">Oxylabs</a> </p> <p>Any tips?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/stvaccount"> /u/stvaccount </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1gb4nkf/best_library_for_scraping_aliexpress/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1gb4nkf/best_library_for_scraping_aliexpress/">[comments]</a></span>

## Scraping a reviewer's page on Metacritic?
 - [https://www.reddit.com/r/webscraping/comments/1gb3swk/scraping_a_reviewers_page_on_metacritic](https://www.reddit.com/r/webscraping/comments/1gb3swk/scraping_a_reviewers_page_on_metacritic)
 - RSS feed: $source
 - date published: 2024-10-24T14:22:20+00:00

<!-- SC_OFF --><div class="md"><p>For example, Brian Truitt is a critic who writes for USA Today and is on metacritic <a href="https://www.metacritic.com/critic/brian-truitt/">https://www.metacritic.com/critic/brian-truitt/</a> </p> <p>How would I go about scraping all his ratings for the many movies he has rated, and export those to a file such as csv?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Weorking"> /u/Weorking </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1gb3swk/scraping_a_reviewers_page_on_metacritic/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1gb3swk/scraping_a_reviewers_page_on_metacritic/">[comments]</a></span>

## Scraping tools for reverse-engineering
 - [https://www.reddit.com/r/webscraping/comments/1gaycoo/scraping_tools_for_reverseengineering](https://www.reddit.com/r/webscraping/comments/1gaycoo/scraping_tools_for_reverseengineering)
 - RSS feed: $source
 - date published: 2024-10-24T09:15:41+00:00

<!-- SC_OFF --><div class="md"><h1>Please tell me what headless browser I can use to perform &quot;trial and error,&quot; to try changing various inputs systematically and record the resulting outputs. The idea is to uncover patterns that approximate the backend logic.</h1> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Complex-Diver-2858"> /u/Complex-Diver-2858 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1gaycoo/scraping_tools_for_reverseengineering/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1gaycoo/scraping_tools_for_reverseengineering/">[comments]</a></span>

## What do you think about video scraping by LLM?
 - [https://www.reddit.com/r/webscraping/comments/1gaxdr0/what_do_you_think_about_video_scraping_by_llm](https://www.reddit.com/r/webscraping/comments/1gaxdr0/what_do_you_think_about_video_scraping_by_llm)
 - RSS feed: $source
 - date published: 2024-10-24T07:58:21+00:00

<!-- SC_OFF --><div class="md"><p>re: <a href="https://simonwillison.net/2024/Oct/17/video-scraping/">https://simonwillison.net/2024/Oct/17/video-scraping/</a></p> <p>What do you think? Will it replace the conventional method if I want to scrape multiple dynamic website. In that case I can write a simple script to do the navigation for me then leave the extraction task to LLM.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/trantrungtin"> /u/trantrungtin </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1gaxdr0/what_do_you_think_about_video_scraping_by_llm/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1gaxdr0/what_do_you_think_about_video_scraping_by_llm/">[comments]</a></span>

