# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## where i can get web scraping client ?
 - [https://www.reddit.com/r/webscraping/comments/1fzz928/where_i_can_get_web_scraping_client](https://www.reddit.com/r/webscraping/comments/1fzz928/where_i_can_get_web_scraping_client)
 - RSS feed: $source
 - date published: 2024-10-09T19:02:41+00:00

<!-- SC_OFF --><div class="md"><p>Hello My friends any help i&#39;m looking for web scraping clients i have tried upwork and fiver two months already and no client at all did not even had chance to show my skills<br/> i will be thankful for any tips or help </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/ronoxzoro"> /u/ronoxzoro </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fzz928/where_i_can_get_web_scraping_client/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1fzz928/where_i_can_get_web_scraping_client/">[comments]</a></span>

## Help with simple utility truncate-html
 - [https://www.reddit.com/r/webscraping/comments/1fzysk8/help_with_simple_utility_truncatehtml](https://www.reddit.com/r/webscraping/comments/1fzysk8/help_with_simple_utility_truncatehtml)
 - RSS feed: $source
 - date published: 2024-10-09T18:43:12+00:00

<!-- SC_OFF --><div class="md"><p>Hi,</p> <p>So I am doing a little tool I would actually need. Basically I want this tool to grab an <code>html</code> document, take all the tags that are meant to display text (almost all of them), and that <code>innerText</code> truncate it to one word.</p> <p>The objective is to be able to reduce the documents greatly in size, without them loosing their actual <code>html</code> structure. This way I can feed them into <code>LLM</code>&#39;s such as <strong>chatGPT</strong> and I can ask questions about the <strong>shape</strong> of the document sort to say.</p> <p>The issue in here is that I have never used <code>python</code> . Being advanced at <code>bash</code>, <code>nodejs</code>, <code>puppeteer</code> . But <strong>Python</strong> is something I would need to be checking soon. Definitely not today as I am not having enough time hence why I am asking.</p> <p>Say the following document.</p> <p>``` &lt;html&gt; &lt;HEAD&gt;&lt;META HTTP-EQUIV=&

## Can someone help me on this Tennis website?
 - [https://www.reddit.com/r/webscraping/comments/1fzygai/can_someone_help_me_on_this_tennis_website](https://www.reddit.com/r/webscraping/comments/1fzygai/can_someone_help_me_on_this_tennis_website)
 - RSS feed: $source
 - date published: 2024-10-09T18:28:36+00:00

<!-- SC_OFF --><div class="md"><p>I have created a website that scrapes data from flashscore.com tennis website and directly hosts on our domain from github. I&#39;ve used selenium for this..I am looking to automate the daily refresh so that it scrapes daily and refreshes our website..but right now it is taking 5 minutes to update single players data ( minimum 3 min to switch between tabs and fetc all data from flashscore)</p> <p>We have around 450+ matches everyday...so you can imagine the time it would take to update if I have to go by current process...is there any way we can fasten this?</p> <p>P.S. We are already using threading in the project!!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/ChemistryOrdinary860"> /u/ChemistryOrdinary860 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fzygai/can_someone_help_me_on_this_tennis_website/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comme

## Are there any good google maps scrapping tools that are free?
 - [https://www.reddit.com/r/webscraping/comments/1fzy50n/are_there_any_good_google_maps_scrapping_tools](https://www.reddit.com/r/webscraping/comments/1fzy50n/are_there_any_good_google_maps_scrapping_tools)
 - RSS feed: $source
 - date published: 2024-10-09T18:15:31+00:00

<!-- SC_OFF --><div class="md"><p>That’s it really, I’m building a database and I’m sick of manually scrapping, is there such a thing as a free scrapping tool? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/ekaitzpk"> /u/ekaitzpk </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fzy50n/are_there_any_good_google_maps_scrapping_tools/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1fzy50n/are_there_any_good_google_maps_scrapping_tools/">[comments]</a></span>

## Looking for help with scraping a datadome protected site frequently
 - [https://www.reddit.com/r/webscraping/comments/1fzuhhn/looking_for_help_with_scraping_a_datadome](https://www.reddit.com/r/webscraping/comments/1fzuhhn/looking_for_help_with_scraping_a_datadome)
 - RSS feed: $source
 - date published: 2024-10-09T15:43:42+00:00

<!-- SC_OFF --><div class="md"><p>I am trying to scrape klwines.com which is protected by DataDome. </p> <p>I have tried curl_cffi and undetected_playwright but they are still getting blocked. Proxies are not enough. </p> <p>Is there an all-in-one tool or any other alternatives?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Daednoise"> /u/Daednoise </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fzuhhn/looking_for_help_with_scraping_a_datadome/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1fzuhhn/looking_for_help_with_scraping_a_datadome/">[comments]</a></span>

## Prompt in webscarping is not working
 - [https://www.reddit.com/r/webscraping/comments/1fzpsyz/prompt_in_webscarping_is_not_working](https://www.reddit.com/r/webscraping/comments/1fzpsyz/prompt_in_webscarping_is_not_working)
 - RSS feed: $source
 - date published: 2024-10-09T12:05:55+00:00

<!-- SC_OFF --><div class="md"><p>I am using python selenium to do some task</p> <p>Now after few steps I get to a point where I need to enter some id in a prompt that comes.</p> <p>When I click on inspect element, everything is empty.</p> <p>I am using chrome web driver</p> <p>I have tried driver.switch_to.send_keys(&#39;id&#39;).accept()</p> <p>But it is not typing anything in that box.</p> <p>Chat gpt is not helpful.</p> <p>Thanks in advance.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/WingPractical7932"> /u/WingPractical7932 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fzpsyz/prompt_in_webscarping_is_not_working/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1fzpsyz/prompt_in_webscarping_is_not_working/">[comments]</a></span>

## Scrape Airtable
 - [https://www.reddit.com/r/webscraping/comments/1fzpnru/scrape_airtable](https://www.reddit.com/r/webscraping/comments/1fzpnru/scrape_airtable)
 - RSS feed: $source
 - date published: 2024-10-09T11:58:19+00:00

<!-- SC_OFF --><div class="md"><p>We have included a service in our app which allows you to request a scrape of a publicly viewable Airtable, giving you a CSV of the full data. </p> <p>We prepared a short demo here of how it works:</p> <p><a href="https://www.youtube.com/watch?v=8xyUP5LAJnM">https://www.youtube.com/watch?v=8xyUP5LAJnM</a> </p> <p>Its a paid service but feel free to get in touch with me to hear a bit more about how it works.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/amjtech"> /u/amjtech </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fzpnru/scrape_airtable/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1fzpnru/scrape_airtable/">[comments]</a></span>

## Help figuring out an Ajax Site
 - [https://www.reddit.com/r/webscraping/comments/1fzmu6v/help_figuring_out_an_ajax_site](https://www.reddit.com/r/webscraping/comments/1fzmu6v/help_figuring_out_an_ajax_site)
 - RSS feed: $source
 - date published: 2024-10-09T08:45:47+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;m trying to learn other ways to scrape other html parsing and went to analyze this site <a href="https://mtg.wtf/pack/one-draft">https://mtg.wtf/pack/one-draft</a> to understand how, where does he get his data and what he uses to generate the doc html. Inspect element and the network tabs doesn&#39;t seem to be useful for this scenario.<br/> I know per sure that his pages under &quot;pack&quot; are generated but I can&#39;t figure out what he calls to get his data, in his JS there are ajax settings and parameters but the uri used refer to himself.<br/> What I m trying to get in the end, after the right cleanup and transformation, a CSV or JSON with the cards with their tags as is in the html</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/DarkzDrake"> /u/DarkzDrake </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fzmu6v/help_figuring_out_an_ajax_site/">[link]</a></span> &#32; <span><

## Project setup in Python on different targets
 - [https://www.reddit.com/r/webscraping/comments/1fzmfmo/project_setup_in_python_on_different_targets](https://www.reddit.com/r/webscraping/comments/1fzmfmo/project_setup_in_python_on_different_targets)
 - RSS feed: $source
 - date published: 2024-10-09T08:12:13+00:00

<!-- SC_OFF --><div class="md"><p>How are you guys seting up your projects if you have different targets that require some &quot;Non-reusable&quot; code.</p> <p>At the moment I have three targets all with kind of different setup. The first has one JSON-url, but one key in the url is changing each day so that key has to be fetched using selenium before the crape starts (And try refetched if fails mid-scrape). The second does not have an changing key but have the same information spread in 4 different JSON-targets. THe third is load data with javascript so here I need some other webdriver to get the data.</p> <p><strong>Case 1:</strong><br/> target1/fetch.py<br/> target1/transform.py<br/> target1/load.py</p> <p>target2/fetch.py<br/> target2/transform.py<br/> target2/load.py</p> <p>target3/fetch.py<br/> target3/transform.py<br/> target3/load.py</p> <p><strong>Case 2:</strong><br/> fetch.py with if target1, elif target2 etc.<br/> transform.py with if target1, elif target2 etc.<br/> load.p

## How we scraped authentication data without running browser
 - [https://www.reddit.com/r/webscraping/comments/1fzkbm9/how_we_scraped_authentication_data_without](https://www.reddit.com/r/webscraping/comments/1fzkbm9/how_we_scraped_authentication_data_without)
 - RSS feed: $source
 - date published: 2024-10-09T05:31:24+00:00

<table> <tr><td> <a href="https://www.reddit.com/r/webscraping/comments/1fzkbm9/how_we_scraped_authentication_data_without/"> <img src="https://external-preview.redd.it/QBMpWlWQFDXYmdoGy_5aD1dqmrC0inrLJ4s2bRbjCXE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d1f67686b8707bc2d347add65aa9dab9e507dd5d" alt="How we scraped authentication data without running browser" title="How we scraped authentication data without running browser" /> </a> </td><td> &#32; submitted by &#32; <a href="https://www.reddit.com/user/sauain"> /u/sauain </a> <br/> <span><a href="https://crawlee.dev/blog/scraping-dynamic-websites-using-python">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1fzkbm9/how_we_scraped_authentication_data_without/">[comments]</a></span> </td></tr></table>

## How to automate closing tabs in this website?
 - [https://www.reddit.com/r/webscraping/comments/1fzif6q/how_to_automate_closing_tabs_in_this_website](https://www.reddit.com/r/webscraping/comments/1fzif6q/how_to_automate_closing_tabs_in_this_website)
 - RSS feed: $source
 - date published: 2024-10-09T03:31:30+00:00

<!-- SC_OFF --><div class="md"><p>empire.goodgamestudios.com I want to automate closing tabs here. It uses canvas. And all the code in a script tags. I just need a start point or something to search for.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/PriorityComplete1336"> /u/PriorityComplete1336 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fzif6q/how_to_automate_closing_tabs_in_this_website/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1fzif6q/how_to_automate_closing_tabs_in_this_website/">[comments]</a></span>

## Scraping popups with interaction trigger
 - [https://www.reddit.com/r/webscraping/comments/1fzfoc9/scraping_popups_with_interaction_trigger](https://www.reddit.com/r/webscraping/comments/1fzfoc9/scraping_popups_with_interaction_trigger)
 - RSS feed: $source
 - date published: 2024-10-09T01:03:38+00:00

<!-- SC_OFF --><div class="md"><p>I would like to get a timestamp and text from popups that appear on NoFap dot com.</p> <p>I do not need an image from the site, just the text from the popup. The pop-ups claim to be from users performing action, but it is clear they are not tied to that. They only appear during interactions, such as a page refresh. They also have a pattern of showing the same text in a cycle. I would like to reverse engineer what the text order is, but I would like to automate the collection (rather than manually refreshing the page and copy+paste the pop-up text!). </p> <p>I&#39;ve tried VisualPing and Distill web monitor extensions. I can do some work in SQL and Python, although neither is a strength. </p> <p>Does anyone have anothe extension? Sample code? </p> <p>Thoughts appreciated!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Appropriate-Week-718"> /u/Appropriate-Week-718 </a> <br/> <span><a href="https://www.reddit.com/

