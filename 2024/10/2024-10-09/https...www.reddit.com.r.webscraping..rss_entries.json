[{"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-09T19:02:41+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello My friends any help i&#39;m looking for web scraping clients i have tried upwork and fiver two months already and no client at all did not even had chance to show my skills<br/> i will be thankful for any tips or help </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ronoxzoro\"> /u/ronoxzoro </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fzz928/where_i_can_get_web_scraping_client/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fzz928/where_i_can_get_web_scraping_client/\">[comments]</a></span>", "id": 1296975, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fzz928/where_i_can_get_web_scraping_client", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "where i can get web scraping client ?", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-09T18:43:12+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi,</p> <p>So I am doing a little tool I would actually need. Basically I want this tool to grab an <code>html</code> document, take all the tags that are meant to display text (almost all of them), and that <code>innerText</code> truncate it to one word.</p> <p>The objective is to be able to reduce the documents greatly in size, without them loosing their actual <code>html</code> structure. This way I can feed them into <code>LLM</code>&#39;s such as <strong>chatGPT</strong> and I can ask questions about the <strong>shape</strong> of the document sort to say.</p> <p>The issue in here is that I have never used <code>python</code> . Being advanced at <code>bash</code>, <code>nodejs</code>, <code>puppeteer</code> . But <strong>Python</strong> is something I would need to be checking soon. Definitely not today as I am not having enough time hence why I am asking.</p> <p>Say the following document.</p> <p>``` &lt;html&gt; &lt;HEAD&gt;&lt;META HTTP-EQUIV=&", "id": 1296466, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fzysk8/help_with_simple_utility_truncatehtml", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Help with simple utility truncate-html", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-09T18:28:36+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I have created a website that scrapes data from flashscore.com tennis website and directly hosts on our domain from github. I&#39;ve used selenium for this..I am looking to automate the daily refresh so that it scrapes daily and refreshes our website..but right now it is taking 5 minutes to update single players data ( minimum 3 min to switch between tabs and fetc all data from flashscore)</p> <p>We have around 450+ matches everyday...so you can imagine the time it would take to update if I have to go by current process...is there any way we can fasten this?</p> <p>P.S. We are already using threading in the project!!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ChemistryOrdinary860\"> /u/ChemistryOrdinary860 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fzygai/can_someone_help_me_on_this_tennis_website/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comme", "id": 1296467, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fzygai/can_someone_help_me_on_this_tennis_website", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Can someone help me on this Tennis website?", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-09T18:15:31+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>That\u2019s it really, I\u2019m building a database and I\u2019m sick of manually scrapping, is there such a thing as a free scrapping tool? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ekaitzpk\"> /u/ekaitzpk </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fzy50n/are_there_any_good_google_maps_scrapping_tools/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fzy50n/are_there_any_good_google_maps_scrapping_tools/\">[comments]</a></span>", "id": 1296465, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fzy50n/are_there_any_good_google_maps_scrapping_tools", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Are there any good google maps scrapping tools that are free?", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-09T15:43:42+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I am trying to scrape klwines.com which is protected by DataDome. </p> <p>I have tried curl_cffi and undetected_playwright but they are still getting blocked. Proxies are not enough. </p> <p>Is there an all-in-one tool or any other alternatives?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Daednoise\"> /u/Daednoise </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fzuhhn/looking_for_help_with_scraping_a_datadome/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fzuhhn/looking_for_help_with_scraping_a_datadome/\">[comments]</a></span>", "id": 1294986, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fzuhhn/looking_for_help_with_scraping_a_datadome", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Looking for help with scraping a datadome protected site frequently", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-09T12:05:55+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I am using python selenium to do some task</p> <p>Now after few steps I get to a point where I need to enter some id in a prompt that comes.</p> <p>When I click on inspect element, everything is empty.</p> <p>I am using chrome web driver</p> <p>I have tried driver.switch_to.send_keys(&#39;id&#39;).accept()</p> <p>But it is not typing anything in that box.</p> <p>Chat gpt is not helpful.</p> <p>Thanks in advance.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/WingPractical7932\"> /u/WingPractical7932 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fzpsyz/prompt_in_webscarping_is_not_working/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fzpsyz/prompt_in_webscarping_is_not_working/\">[comments]</a></span>", "id": 1293890, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fzpsyz/prompt_in_webscarping_is_not_working", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Prompt in webscarping is not working", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-09T11:58:19+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>We have included a service in our app which allows you to request a scrape of a publicly viewable Airtable, giving you a CSV of the full data. </p> <p>We prepared a short demo here of how it works:</p> <p><a href=\"https://www.youtube.com/watch?v=8xyUP5LAJnM\">https://www.youtube.com/watch?v=8xyUP5LAJnM</a> </p> <p>Its a paid service but feel free to get in touch with me to hear a bit more about how it works.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/amjtech\"> /u/amjtech </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fzpnru/scrape_airtable/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fzpnru/scrape_airtable/\">[comments]</a></span>", "id": 1293040, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fzpnru/scrape_airtable", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Scrape Airtable", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-09T08:45:47+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m trying to learn other ways to scrape other html parsing and went to analyze this site <a href=\"https://mtg.wtf/pack/one-draft\">https://mtg.wtf/pack/one-draft</a> to understand how, where does he get his data and what he uses to generate the doc html. Inspect element and the network tabs doesn&#39;t seem to be useful for this scenario.<br/> I know per sure that his pages under &quot;pack&quot; are generated but I can&#39;t figure out what he calls to get his data, in his JS there are ajax settings and parameters but the uri used refer to himself.<br/> What I m trying to get in the end, after the right cleanup and transformation, a CSV or JSON with the cards with their tags as is in the html</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/DarkzDrake\"> /u/DarkzDrake </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fzmu6v/help_figuring_out_an_ajax_site/\">[link]</a></span> &#32; <span><", "id": 1292238, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fzmu6v/help_figuring_out_an_ajax_site", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Help figuring out an Ajax Site", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-09T08:12:13+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>How are you guys seting up your projects if you have different targets that require some &quot;Non-reusable&quot; code.</p> <p>At the moment I have three targets all with kind of different setup. The first has one JSON-url, but one key in the url is changing each day so that key has to be fetched using selenium before the crape starts (And try refetched if fails mid-scrape). The second does not have an changing key but have the same information spread in 4 different JSON-targets. THe third is load data with javascript so here I need some other webdriver to get the data.</p> <p><strong>Case 1:</strong><br/> target1/fetch.py<br/> target1/transform.py<br/> target1/load.py</p> <p>target2/fetch.py<br/> target2/transform.py<br/> target2/load.py</p> <p>target3/fetch.py<br/> target3/transform.py<br/> target3/load.py</p> <p><strong>Case 2:</strong><br/> fetch.py with if target1, elif target2 etc.<br/> transform.py with if target1, elif target2 etc.<br/> load.p", "id": 1292239, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fzmfmo/project_setup_in_python_on_different_targets", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Project setup in Python on different targets", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-09T05:31:24+00:00", "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1fzkbm9/how_we_scraped_authentication_data_without/\"> <img src=\"https://external-preview.redd.it/QBMpWlWQFDXYmdoGy_5aD1dqmrC0inrLJ4s2bRbjCXE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d1f67686b8707bc2d347add65aa9dab9e507dd5d\" alt=\"How we scraped authentication data without running browser\" title=\"How we scraped authentication data without running browser\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/sauain\"> /u/sauain </a> <br/> <span><a href=\"https://crawlee.dev/blog/scraping-dynamic-websites-using-python\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fzkbm9/how_we_scraped_authentication_data_without/\">[comments]</a></span> </td></tr></table>", "id": 1291964, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fzkbm9/how_we_scraped_authentication_data_without", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 86, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": "https://external-preview.redd.it/QBMpWlWQFDXYmdoGy_5aD1dqmrC0inrLJ4s2bRbjCXE.jpg?width=640&crop=smart&auto=webp&s=d1f67686b8707bc2d347add65aa9dab9e507dd5d", "title": "How we scraped authentication data without running browser", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-09T03:31:30+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>empire.goodgamestudios.com I want to automate closing tabs here. It uses canvas. And all the code in a script tags. I just need a start point or something to search for.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PriorityComplete1336\"> /u/PriorityComplete1336 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fzif6q/how_to_automate_closing_tabs_in_this_website/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fzif6q/how_to_automate_closing_tabs_in_this_website/\">[comments]</a></span>", "id": 1291346, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fzif6q/how_to_automate_closing_tabs_in_this_website", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "How to automate closing tabs in this website?", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-09T01:03:38+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I would like to get a timestamp and text from popups that appear on NoFap dot com.</p> <p>I do not need an image from the site, just the text from the popup. The pop-ups claim to be from users performing action, but it is clear they are not tied to that. They only appear during interactions, such as a page refresh. They also have a pattern of showing the same text in a cycle. I would like to reverse engineer what the text order is, but I would like to automate the collection (rather than manually refreshing the page and copy+paste the pop-up text!). </p> <p>I&#39;ve tried VisualPing and Distill web monitor extensions. I can do some work in SQL and Python, although neither is a strength. </p> <p>Does anyone have anothe extension? Sample code? </p> <p>Thoughts appreciated!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Appropriate-Week-718\"> /u/Appropriate-Week-718 </a> <br/> <span><a href=\"https://www.reddit.com/", "id": 1290866, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fzfoc9/scraping_popups_with_interaction_trigger", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Scraping popups with interaction trigger", "vote": 0}]