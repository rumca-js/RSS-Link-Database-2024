[{"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-18T21:16:40+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi,</p> <p>Devs used to name components with classes for styling purposes, which became an important advantage for DOM-based scraping.</p> <p>But with more and more devs switching to CSS frameworks using utility classes (e.g. Tailwind), components no longer have a name, but a bunch of freaking styling classes.</p> <p>How to deal with that ?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/KaKi_87\"> /u/KaKi_87 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g6sx5n/how_to_scrape_a_dom_only_containing_utility/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g6sx5n/how_to_scrape_a_dom_only_containing_utility/\">[comments]</a></span>", "id": 1350605, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g6sx5n/how_to_scrape_a_dom_only_containing_utility", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "How to scrape a DOM only containing utility classes ?", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-18T21:01:22+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve looked at the network calls and HTML but haven&#39;t found much data to extract, such as polygons or postal codes. I only spent 10-15 minutes on it and didn&#39;t dig too deep, but from what I saw, it seems tricky to handle in bulk.</p> <p>Does anyone have experience with this and could offer some clues or advice?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/tietheshoe\"> /u/tietheshoe </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g6sn17/how_hard_it_is_to_scrape_google_maps/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g6sn17/how_hard_it_is_to_scrape_google_maps/\">[comments]</a></span>", "id": 1350606, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g6sn17/how_hard_it_is_to_scrape_google_maps", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "How hard it is to scrape google maps?", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-18T20:14:05+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I want to scrape this website <a href=\"http://free-proxy.cz/en/\">http://free-proxy.cz/en/</a> im able to scrape the first page only but when i try to extract the following page it returns an error. I used the response.css(&#39;div.paginator a[href*=&quot;/main/&quot;]::attr(href)&#39;).get(). to get it, but it returns nothing ... what should I do in this case?</p> <p>btw i&#39;m new to scrapy so idk a lot of thing</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/H_3ll\"> /u/H_3ll </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g6rkrp/why_i_cant_scrape_this_website_next_page_link/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g6rkrp/why_i_cant_scrape_this_website_next_page_link/\">[comments]</a></span>", "id": 1350821, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g6rkrp/why_i_cant_scrape_this_website_next_page_link", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "why I can't scrape this website next page link", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-18T19:33:52+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Looking to scrape a couple different sites like, <a href=\"https://all.kingsroadmerch.com/category/854/music\">https://all.kingsroadmerch.com/category/854/music</a></p> <p>KingsRoadMerch operates probably a couple hundred sites, all more or less the same site, just different products. Ideally I&#39;d find some sort of .json file I can scrape data from. Basically I want to know when something new comes into stock and possibly quantities, though, in/out of stock is the main focus.</p> <p>I&#39;ve been able to figure out most other records labels and their means of hiding that data, but KRM continues to elude me. Any help would be appreciated. I&#39;m using some self-hosted tools like huginn or changedetection to monitor sites.</p> <p>PS I&#39;m a photographer who geeks out on records and I know really jack shit about most of this stuff, kinda just learning as I go.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/fish", "id": 1350022, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g6qnno/help_scraping_a_collection_of_sites", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "help scraping a collection of sites", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-18T18:08:37+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>mhm</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/piesany\"> /u/piesany </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g6ooc0/are_some_websites_html_unscrapable_or_is_it_a/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g6ooc0/are_some_websites_html_unscrapable_or_is_it_a/\">[comments]</a></span>", "id": 1349715, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g6ooc0/are_some_websites_html_unscrapable_or_is_it_a", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Are some websites\u2019 HTML unscrapable or is it a skill issue?", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-18T17:55:45+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I know the scraping and crawling landscape is pretty mature, both in OSS and paid SaaS services. But I am curious what is the best OSS/locally-runnable crawling AND scraping library is?</p> <p>In terms of scraping, I am lovely Jina AI, so I have that piece kind of set. But I am having trouble finding a crawling library that can handle sites with lots of JS / links, and get a list of all the links on the page which I can then throw to Jina AI to scrape. </p> <p>I am trying Firecrawl too, and while the results are good, I prefer not to subscribe to a SaaS service. If I can run this on my server, I&#39;d rather do that. </p> <p>I&#39;ve used crawl4ai, but they appear to not do the crawling (or I am using it wrong..) </p> <p>Or is it easier to just use a paid service Apify or Firecrawl? Or are there equally good libraries for this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/WhosAfraidOf_138\"> /u/WhosAfraidOf_138", "id": 1349716, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g6od7n/best_oss_python_crawling_and_scraping_library", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Best OSS Python crawling and scraping library?", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-18T17:12:00+00:00", "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1g6ncho/hcaptcha_problem_on_shopify/\"> <img src=\"https://b.thumbs.redditmedia.com/-ohOcDpo9RUv0Rmj8UPbGxk2Zr8KhUgBRRt5FWkgztk.jpg\" alt=\"Hcaptcha problem on Shopify\" title=\"Hcaptcha problem on Shopify\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hi, anyone else getting this Hcaptcha error on shopify sites when logging in? It keep on saying that the answer is incorrect even though I have solved it manually. I have also tried using API of capsolver and capmonster but both of them cannot solve the challenge. I am having trouble automating on Shopify because of this unsolvable captcha. </p> <p><a href=\"https://preview.redd.it/gqtrezx8rjvd1.jpg?width=633&amp;format=pjpg&amp;auto=webp&amp;s=709e7b24ca0245991402d118d25c1ae3780286d5\">hcap error</a></p> <p><a href=\"https://preview.redd.it/vg1h2t2hrjvd1.jpg?width=514&amp;format=pjpg&amp;auto=webp&amp;s=94034c0512b1f45b101452bbec5da057ac14ae87\">hcap</a></p> </div><!--", "id": 1350822, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g6ncho/hcaptcha_problem_on_shopify", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 86, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": "https://b.thumbs.redditmedia.com/-ohOcDpo9RUv0Rmj8UPbGxk2Zr8KhUgBRRt5FWkgztk.jpg", "title": "Hcaptcha problem on Shopify", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-18T16:19:54+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey fellow scrapers! I&#39;m a beginner in the world of web scraping, and I&#39;ve been exploring various tools and solutions for a specific project I&#39;m working on for my business.I&#39;ve searched extensively and experimented with countless scrapers, but I&#39;m still looking for the right fit to scrape Zillow or Redfin, specifically for land sales data. Here\u2019s what I\u2019m hoping to achieve:</p> <ol> <li>Scrape data on land sales and sold properties</li> <li>Use AI to perform basic due diligence on the scraped data</li> <li>Integrate the solution with <a href=\"http://Make.com\">Make.com</a> for further automation</li> </ol> <p>Here\u2019s what I\u2019m looking to accomplish:</p> <ul> <li>Collect data on land listings (both active and sold) from Zillow or Redfin</li> <li>Extract key information like price, acreage, location, and sale date</li> <li>Integrate with an AI tool to analyze the data and provide insights</li> <li>Use <a href=\"http://Make.com\">Make.com<", "id": 1349306, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g6m496/beginner_seeking_advice_zillowredfin_land_sales", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Beginner Seeking Advice: Zillow/Redfin Land Sales Scraper", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-18T15:37:52+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Trying to scrape <a href=\"http://accords-library.com\"><code>accords-library.com</code></a> before it gets shutdown. Tried cyowcopy and Httrack but neither of them scrapped the images in e.g. path: <a href=\"https://accords-library.com/library/dod3-official-score-book/reader?page=0\">https://accords-library.com/library/dod3-official-score-book/reader?page=0</a> . They only scrapped the very top path and pretty much nothing below it. </p> <p>The images are represented like this in the website:</p> <p><code>&lt;img class=&quot;max-h-[calc(100vh-4rem)]&quot; src=&quot;https://img.accords-library.com/large/7_548059b5b8.webp&quot; loading=&quot;lazy&quot; height=&quot;2048&quot; width=&quot;1486&quot; style=&quot;max-height: calc(-7rem + 100vh); width: auto;&quot;&gt;</code></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/NoSemikolon24\"> /u/NoSemikolon24 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comm", "id": 1348773, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g6l0z9/looking_for_a_scraper_capable_of_handling_images", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Looking for a scraper capable of handling images in .webp format", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-18T14:31:03+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I used LSD to scrape and then ollama and python to spoof. Check it out!</p> <p><a href=\"https://www.youtube.com/watch?v=Mn6eV0HnawM&amp;ab_channel=AndreaRusso\">https://www.youtube.com/watch?v=Mn6eV0HnawM&amp;ab_channel=AndreaRusso</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Cool_Effective_1185\"> /u/Cool_Effective_1185 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g6jfut/scraping_election_headlines/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g6jfut/scraping_election_headlines/\">[comments]</a></span>", "id": 1350823, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g6jfut/scraping_election_headlines", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Scraping election headlines", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-18T11:34:28+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I have several hundred sites that need to be scraped routinely, once a week perhaps. The data should be simple to extract once it is identified and the purpose is to build a data lake using cloud storage to train an LLM.</p> <p>Usually I work with specific URLs for specific data so its easy to build custom scripts. This is obviously not possible. I prefer to use Python wherever possible and am okay with using local LLMs (LLama) in my code (with varying results).</p> <p>Before I start down this path and begin building and learning by trial and error does anyone know of any good libraries or tutorials for this sort of project (the spider part of the project that is, not training the LLM).</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ok-Ship812\"> /u/Ok-Ship812 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g6fvvd/i_need_to_build_more_of_a_web_spider_than_a/\">[link]</a></span> &#32; <span", "id": 1347240, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g6fvvd/i_need_to_build_more_of_a_web_spider_than_a", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "I need to build more of a web spider than a scraper, where to begin.", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-18T11:12:03+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>How would I scrap this table from <strong>embednotion.com</strong>: <a href=\"https://csr-tools.com/csr-tool-uebersicht/\">https://csr-tools.com/csr-tool-uebersicht/</a></p> <p>I&#39;m stuck.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/stvaccount\"> /u/stvaccount </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g6fijd/how_would_i_scrap_this_notion_table/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g6fijd/how_would_i_scrap_this_notion_table/\">[comments]</a></span>", "id": 1347241, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g6fijd/how_would_i_scrap_this_notion_table", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "How would I scrap this notion table?", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-18T09:54:39+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Is it a low trusted ip? Would I need to use a proxy or it should be fine without it?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/iamTEOTU\"> /u/iamTEOTU </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g6ed43/aws_ec2_instance_ip_for_scraping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g6ed43/aws_ec2_instance_ip_for_scraping/\">[comments]</a></span>", "id": 1347242, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g6ed43/aws_ec2_instance_ip_for_scraping", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "AWS EC2 instance ip for scraping.", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-18T01:59:52+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone,</p> <p>I\u2019ve got some experience scraping websites using Beautiful Soup, but I haven\u2019t tackled eCommerce sites before, and I\u2019m looking for advice. There\u2019s a Bratz doll releasing soon that I <em>really</em> want, and I\u2019m thinking about building a bot to buy it as soon as it drops.</p> <p>The website has CAPTCHA and a specific release date/time for the doll. I\u2019m wondering what tools or approaches people would recommend for this, especially given the CAPTCHA. Any tips or insights on how to navigate this would be super appreciated!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AlwaysOnlineGirly\"> /u/AlwaysOnlineGirly </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g67d80/help_with_web_scraper_for_buying_a_product/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g67d80/help_with_web_scraper_for_buying_a_product/\">[comments]</a></span>", "id": 1345863, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g67d80/help_with_web_scraper_for_buying_a_product", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Help with Web Scraper for Buying a Product", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-18T00:59:04+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, </p> <p>just stared to use playwright and I like how I can save my auth to a .json file and login past 2FA super easy so i stared to build alot of my code basied off only playwright; however, a lot of videos I see online are talking about scrapy-playwright (basically scrapy but using playwright to handle rendering and other stuff). I am trying to get pretty serious into learning how to scrape, should I swtch all of my code to scrapy-playwright or am I fine with stright playwright. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/RandomFactChecker_\"> /u/RandomFactChecker_ </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g668hd/playwright_or_scrapyplaywright/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1g668hd/playwright_or_scrapyplaywright/\">[comments]</a></span>", "id": 1345482, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1g668hd/playwright_or_scrapyplaywright", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "playwright or scrapy-playwright", "vote": 0}]