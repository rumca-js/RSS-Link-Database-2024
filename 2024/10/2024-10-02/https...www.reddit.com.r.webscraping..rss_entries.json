[{"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-02T22:47:27+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m pretty new to this so apologies if my question is very newbish/ignorant</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Geyball\"> /u/Geyball </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fut90l/how_is_wayback_able_to_webscrapewebcrawl_without/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fut90l/how_is_wayback_able_to_webscrapewebcrawl_without/\">[comments]</a></span>", "id": 1257175, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fut90l/how_is_wayback_able_to_webscrapewebcrawl_without", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "How is wayback able to webscrape/webcrawl without getting detected?", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-02T22:01:37+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I am wondering if there is any LLM based web scrapper that can remember multiple pages and gather data based on prompt?</p> <p>I believe this should be available!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Accomplished_Ad_655\"> /u/Accomplished_Ad_655 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fusczo/llm_based_web_scrapping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fusczo/llm_based_web_scrapping/\">[comments]</a></span>", "id": 1256930, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fusczo/llm_based_web_scrapping", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "LLM based web scrapping", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-02T20:30:29+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I have tried my heart out with requests, selenuim, different user agents, slowing down the crawl, etc., etc. </p> <p>I cannot figure out how to crawl/scrape chewy.com. Can anyone figure it out? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/opchopper10\"> /u/opchopper10 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fuq8cc/crawlscrape_chewycom/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fuq8cc/crawlscrape_chewycom/\">[comments]</a></span>", "id": 1256569, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fuq8cc/crawlscrape_chewycom", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Crawl/Scrape Chewy.com", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-02T20:23:23+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve tried using Claude/Chatgpt to build a python bot to do it, but couldn&#39;t make it work. </p> <p>IDK if there is an API endpoint for this.</p> <p>Here&#39;s the link</p> <p><a href=\"https://www.reddit.com/best/communities/1/\">https://www.reddit.com/best/communities/1/</a></p> <p>to </p> <p><a href=\"https://www.reddit.com/best/communities/85/\">https://www.reddit.com/best/communities/85/</a></p> <p>So is just 85 pages.</p> <p>The output is to be saved on topsubreddits.csv in the same dir. </p> <p>Looking simple like this:</p> <p>Rank,subreddit,category,members</p> <p>1,<a href=\"/r/funny\">r/funny</a>,funny/humor,64M</p> <p>Anyone?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/keyehi\"> /u/keyehi </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fuq2e3/scraping_the_full_list_of_subreddits_with_over/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments", "id": 1256568, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fuq2e3/scraping_the_full_list_of_subreddits_with_over", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Scraping the full list of subreddits with over 10k members", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-02T19:56:14+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>How to use authentication socks5 proxy on separate file like I have proxy. json with my proxy and username and password then I have another code where I use to excute tasks and I want to use socks5 proxy.. So that it fetchs the proxy from proxy. json </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/uncletee96\"> /u/uncletee96 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fupfa2/how_to_use_socks5_proxy_with_authentication_in/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fupfa2/how_to_use_socks5_proxy_with_authentication_in/\">[comments]</a></span>", "id": 1256217, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fupfa2/how_to_use_socks5_proxy_with_authentication_in", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "How to use socks5 proxy with authentication in puppeteer", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-02T16:24:03+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Picture this: you\u2019re halfway through coding a feature when you hit a wall. Naturally, you turn to the documentation for help. But instead of a quick solution, you\u2019re met with a doc site that feels like it hasn&#39;t been updated since the age of dial-up. There\u2019s no search bar and what should\u2019ve taken five minutes ends up burning half your day (or a good hour of going back and forth).</p> <p>Meanwhile, I\u2019ve tried using LLMs to speed up the process, but even they don\u2019t always have the latest updates. So there I am, shuffling through doc pages like a madman trying to piece together a solution.</p> <p>After dealing with this mess for way too long, I did what any of us would do\u2014complained about it first, then built something to fix it. That\u2019s how DocTao was born. It scrapes the most up-to-date docs from the source, keeps them all in one place, and has an AI chat feature that helps you interact with the docs more efficiently and integrate what you&#39;ve fo", "id": 1254898, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fukatj/when_youve_spent_more_time_finding_docs_than", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "When You\u2019ve Spent More Time Finding Docs Than Writing Code", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-02T15:42:11+00:00", "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/siegerts\"> /u/siegerts </a> <br/> <span><a href=\"https://www.xiegerts.com/post/scrapy-extension-save-crawlstats-postgres/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fuj9rk/saving_scrapy_crawl_stats_to_postgresql_with_a/\">[comments]</a></span>", "id": 1254470, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fuj9rk/saving_scrapy_crawl_stats_to_postgresql_with_a", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Saving Scrapy Crawl Stats to PostgreSQL with a Custom Extension and SQLAlchemy", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-02T07:56:49+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello,<br/> Are there people here who manage to fully scrape a city or country ? I\u2019ve tried with several GitHub repo, but even on those where I can get past 120 results, I\u2019m still limited. Do any of you have good resources for this please ?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Sad_Depth_4846\"> /u/Sad_Depth_4846 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fuaxhz/google_map_scraping_over_limits/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fuaxhz/google_map_scraping_over_limits/\">[comments]</a></span>", "id": 1252675, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fuaxhz/google_map_scraping_over_limits", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Google Map Scraping over limits", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-10-02T01:39:48+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi there, </p> <p>Not sure if this is the right platform but here goes.</p> <p>I am pretty novice when it comes to web scraping and am looking to see if anyone has created a chrome extension that does web scraping. If so, would love to connect for some feedback.</p> <p>Thank you!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/bec777\"> /u/bec777 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fu4xu0/need_advice_web_scraping_technique/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fu4xu0/need_advice_web_scraping_technique/\">[comments]</a></span>", "id": 1250919, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fu4xu0/need_advice_web_scraping_technique", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Need Advice - Web Scraping Technique", "vote": 0}]