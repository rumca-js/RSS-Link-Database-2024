# Source:The Linux Foundation, URL:https://www.youtube.com/feeds/videos.xml?channel_id=UCfX55Sx5hEFjoC3cNs6mCUQ, language:en

## Contributing to KernelCI for Better Testing and Collaboration - Arisu Tachibana, Cybertrust Japan Co
 - [https://www.youtube.com/watch?v=vNMNJAdm-fo](https://www.youtube.com/watch?v=vNMNJAdm-fo)
 - RSS feed: $source
 - date published: 2024-10-31T00:21:35+00:00

Contributing to KernelCI for Better Testing and Collaboration - Arisu Tachibana, Cybertrust Japan Co., Ltd.

Many products and services are dependent on the Linux Kernel. Because of this the Linux Kernel has to be tested on many different hardware to ensure the stability and reliability of these products or services, this is why KernelCI needs more collaboration both from users and companies. The Linux Kernel upstream community has requested more contributions from companies and users, in particular on the testing ecosystem, such as adding and reporting test results. By understanding corporate usage, the community can more easily provide support and collaborate effectively. KernelCI is one of the current main Kernel testing frameworks and is helping ensure the quality, stability and long-term maintenance of the Linux kernel. As a member of the KernelCI Technical Steering Committee (TSC), I will give details on KernelCI developments and directions. I will talk about current KernelCI n

## Democratizing Diffusion Models with Diffusers - Sayak Paul, Hugging Face
 - [https://www.youtube.com/watch?v=xm1qt8k0bvE](https://www.youtube.com/watch?v=xm1qt8k0bvE)
 - RSS feed: $source
 - date published: 2024-10-31T00:21:35+00:00

Democratizing Diffusion Models with Diffusers - Sayak Paul, Hugging Face

The talk “Democratizing Diffusion Models with Diffusers” will explore the diverse applications of the open-source Python library Diffusers in the image and video generation space. The talk will showcase how Diffusers, based on diffusion models, enables fast and high-quality image and video generation, making it accessible to a wide range of users. The presentation will cover various use cases, including image inpainting, image editing, and scene composition, demonstrating the capabilities of Diffusers in enabling users to create and edit photo-realistic images with minimum effort. The audience will gain insights into the potential of Diffusers in revolutionizing the way images and videos are generated and edited, making it a must-attend session for anyone interested in the latest advancements in this field.

## How Can Your OSPO Maximize Open Source Business Value for the Organization? - Masae Shida, Broadcom
 - [https://www.youtube.com/watch?v=trlJva2bqOI](https://www.youtube.com/watch?v=trlJva2bqOI)
 - RSS feed: $source
 - date published: 2024-10-31T00:21:35+00:00

How Can Your OSPO Maximize Open Source Business Value for the Organization? - Masae Shida, Broadcom

A long-term open source strategy alignment with the organization's business goals is one of the key roles of OSPO. The full potential of open source is best realized when a technical approach is paired with an effective business model and successful community engagement. The commercialization journey of products built with or on open source is substantially different to those based on proprietary software, thus it is critical for technology enterprise leaders to build a strong business strategy around the portfolio. How does open source add unique value for your product? Have you considered competitive technologies? How do you balance the commercial and open source offerings to ensure ROI? How do you collaborate with the community to understand what they actually value? Open source can become a powerful tool for achieving goals but also can be a threat to the business. We must be expl

## Improving Bpftrace Reliability - Daniel Xu, Meta
 - [https://www.youtube.com/watch?v=p__NosE-82o](https://www.youtube.com/watch?v=p__NosE-82o)
 - RSS feed: $source
 - date published: 2024-10-31T00:21:35+00:00

Improving Bpftrace Reliability - Daniel Xu, Meta

bpftrace is a popular and powerful dynamic tracer for Linux systems. In the vast majority of uses cases, bpftrace does its job quickly, efficiently, and accurately. However with the rapid growth of users, use cases, and features, the bpftrace community has started to feel (technical) growing pains. In particular, we've started to uncover various reliability issues. In this talk, we will cover what is already done as well as what is currently broken and how we will systematically fix and prevent these issues from re-occuring. Because bpftrace sits at the intersection of operating systems, compilers, and observability, we have the fortunate advantage of being able to absorb techniques and tricks from these fairly different disciplines. We hope that some of the knowledge we share will be both interesting as well practical to attendees. Audience participation is highly welcome. In particular, we are quite interested in receiving feedback 

## Step by Step, What Should We Do for the Kernel Ecosystem? - Hirotaka Motai, Cybertrust Japan
 - [https://www.youtube.com/watch?v=vnJ4olzYFxs](https://www.youtube.com/watch?v=vnJ4olzYFxs)
 - RSS feed: $source
 - date published: 2024-10-31T00:21:35+00:00

Step by Step, What Should We Do for the Kernel Ecosystem? - Hirotaka Motai, Cybertrust Japan

The announcement that the kernel LTS period would be two years came as a shock to embedded Linux developers (especially in Japan). However, it was also the moment that they had been relying on the kernel maintainers.Hirotaka wondered what we could do for the maintainers who worked so hard to maintain the kernel LTS, and started "Linux Kernel LTS Study Group" in Japan.A number of issues came up, including those related to kernel testing, the product development period and LTS period, and upgrading kernel versions. In this session, he will share the summary of discussions with in-house kernel developers working in Japanese companies and some examples of Open Source projects that can help you solve them, and encourage what other in-house kernel developers or just user can do as a first step for the kernel community.

## A Next-generation IoT Platform for Edge AI Apps Leveraging Se...- Munehiro Shimomura & Kenji Shimizu
 - [https://www.youtube.com/watch?v=MPHxh78qPAI](https://www.youtube.com/watch?v=MPHxh78qPAI)
 - RSS feed: $source
 - date published: 2024-10-31T00:21:33+00:00

A Next-generation IoT Platform for Edge AI Apps Leveraging Sensors and Wasm - Munehiro Shimomura, Sony Semiconductor Solutions Corporation & Kenji Shimizu, Midokura

In this session, we will introduce the construction of a comprehensive platform that uses Edge AI and sensors to cover everything from devices to the cloud. The platform enables advanced cooperation between sensors and AI control, and emphasizes seamless and dynamic replacement of AI models by using WebAssembly (Wasm). Furthermore, through open sourcing, we aim to expand the ecosystem and form a technical community. Through technical details and real-world scenarios, we will provide insights that participants can apply to their own projects.

## Exploring CXL Memory: Configuration and Emulation - Yasunori Goto, Fsas Technologies Inc.
 - [https://www.youtube.com/watch?v=AOjnprXKE6g](https://www.youtube.com/watch?v=AOjnprXKE6g)
 - RSS feed: $source
 - date published: 2024-10-31T00:21:33+00:00

Exploring CXL Memory: Configuration and Emulation - Yasunori Goto, Fsas Technologies Inc.

CXL memory offers the promise of increased memory capacity, which addressing the limitations of conventional DDR DRAM, and also features a memory pool that allows users to dynamically adjust memory allocation based on workload needs. The Linux community has been rapidly developing many CXL features. Additionally, users can try a CXL memory environment with QEMU emulation without actual CXL hardware. This allows users to experiment with CXL memory features in an emulated environment. However, there are some difficulties and considerations when using CXL memory. For example, you cannot use CXL (2.0 or later) memory devices without configuring them using the "cxl create-region" command. Moreover, if you want to utilize memory interleave to achieve optimal performance, you need to understand the hardware topology, including the CXL switch, and reconfigure the region for CXL volatile memory at every

## Optimize Your AI Cloud Infrastructure: A Hardware Perspective - Liang Yan, CoreWeave
 - [https://www.youtube.com/watch?v=jdz8o2qBV8I](https://www.youtube.com/watch?v=jdz8o2qBV8I)
 - RSS feed: $source
 - date published: 2024-10-31T00:21:33+00:00

Optimize Your AI Cloud Infrastructure: A Hardware Perspective - Liang Yan, CoreWeave

GPU Cloud has become a ubiquitous component of contemporary AI infrastructure, especially for distributed machine learning scenarios. While conversations around AI infrastructure optimization typically revolve around the application layer, such as machine learning tasks and distributed job schedulers, delving into the underhood of the GPU cloud is essential. Numerous factors, including POD Scheduler, Device Plugin, GPU/NUMA topology, ROCE/NCCL Stack, and more, can significantly impact performance.

This session will thoroughly explore the tuning of various machine models(CNN/RNN/Transformer) from MLPerf using an H100 Cluster as a reference. We will analyze the correlation between model performance and device operator configuration in nodes by presenting first-hand experimental results to unveil the hidden potential within an AI Cloud.

## Unlocking Local LLMs with Quantization - Marc Sun, Hugging Face
 - [https://www.youtube.com/watch?v=U5XabQQJka4](https://www.youtube.com/watch?v=U5XabQQJka4)
 - RSS feed: $source
 - date published: 2024-10-31T00:21:33+00:00

Unlocking Local LLMs with Quantization - Marc Sun, Hugging Face

This talk will share the story of quantization, its rise in popularity, and its current status in the open-source community. We'll begin by reviewing key quantization papers, such as QLoRA by Tim Dettmers and GPTQ by Elias Frantar. Next, we'll demonstrate how quantization can be applied at various stages of model development, including pre-training, fine-tuning, and inference. Specifically, we'll share our experience in pre-training a 1.58-bit model, show how fine-tuning is achievable using PEFT + QLoRA, and discuss optimizing inference performance with torch.compile or custom kernels. Finally, we'll highlight efforts within the community to make quantized models more accessible, including how transformers incorporate state-of-the-art quantization schemes and how to run GGUF models from llama.cpp.

## Data Prep Kit: A Comprehensive Cloud-Native Toolkit for Scalable Da... - Daiki Tsuzuku & Takuya Goto
 - [https://www.youtube.com/watch?v=WJ147TGULwo](https://www.youtube.com/watch?v=WJ147TGULwo)
 - RSS feed: $source
 - date published: 2024-10-31T00:21:32+00:00

Data Prep Kit: A Comprehensive Cloud-Native Toolkit for Scalable Data Preparation in GenAI App - Daiki Tsuzuku & Takuya Goto, IBM

Every conversation on AI starts with models and ends with data. Data preparation is emerging as a very important phase of the GenAI journey, as high quantity and quality text and code corpora for GenAI model training have shown to play a crucial role in producing high performing Large Language Models (LLMs). The data preparation phase in the Generative AI lifecycle aims to clean, filter, and transform the datasets of text and code that are acquired from various sources into a tokenized form that is suitable for the training of LLMs, be it pre-training, or constructing LLM apps via fine-tuning or instruct tuning. The latter poses unique challenges, as each use case may necessitate tailored data preparation approaches. Given the enduring and evolving demand for data preparation techniques in LLM applications, we are introducing Data Prep Kit as an open-sour

## Discover Valkey: The Path to Now - Hayato Tustsumi, AWS
 - [https://www.youtube.com/watch?v=IIMmsYe9mVc](https://www.youtube.com/watch?v=IIMmsYe9mVc)
 - RSS feed: $source
 - date published: 2024-10-31T00:21:32+00:00

Discover Valkey: The Path to Now - Hayato Tustsumi, AWS

Explore the origins of Valkey, its current state, and the key innovations in the latest major release. Gain valuable insights into future plans for Valkey and discover just how easy it is to migrate existing Redis installations to Valkey.

## eBPF BoF - Shung-Hsi Yu, SUSE & Yutaro Hayakawa, Isovalent
 - [https://www.youtube.com/watch?v=91bffA7NuRk](https://www.youtube.com/watch?v=91bffA7NuRk)
 - RSS feed: $source
 - date published: 2024-10-31T00:21:32+00:00

eBPF BoF - Shung-Hsi Yu, SUSE & Yutaro Hayakawa, Isovalent

Since its introduction 10 years ago, eBPF has steadily gain grounds in networking, tracing, observability, and security applications. But a great technology cannot not thrive on the technical part alone, the people part matters, too. This session hopes to bring eBPF user, developers, and enthusiasts together to exchange novel ideas, discuss best practices, share pain points, and most importantly, collaborate and grow together as a community.

## Exploring Distributed Caching for Faster GPU Training with NVMe, GDS, and RDMA - Hope Wang & Bin Fan
 - [https://www.youtube.com/watch?v=mk1a4ReAyZ8](https://www.youtube.com/watch?v=mk1a4ReAyZ8)
 - RSS feed: $source
 - date published: 2024-10-31T00:21:32+00:00

Exploring Distributed Caching for Faster GPU Training with NVMe, GDS, and RDMA - Hope Wang & Bin Fan, Alluxio

As GPUs become increasingly powerful, the separation between compute and storage often results in underutilized GPUs waiting for data. Meanwhile, modern high-performance hardware like NVMe storage and RDMA networks (InfiniBand or specialized NICs) are becoming more widespread. To fully leverage these resources, it’s crucial to build a balanced architecture that avoids GPU underutilization.

In this talk, we will explore various strategies to address this challenge by effectively utilizing these advanced hardware components. Specifically, we will present experimental results from building a Kubernetes-native distributed caching layer, utilizing NVMe storage and high-speed RDMA networks to optimize data access for PyTorch training.

## Middle-Platform Empowerment: Growing and Sustaining Open Source Projects...- Xiaoya Xia & Peggy Dong
 - [https://www.youtube.com/watch?v=idQy-0VCFaA](https://www.youtube.com/watch?v=idQy-0VCFaA)
 - RSS feed: $source
 - date published: 2024-10-31T00:21:32+00:00

Middle-Platform Empowerment: Growing and Sustaining Open Source Projects at Ant Group - Xiaoya Xia & Peggy Dong, Ant Group

This session introduces Ant Group OSPO's approach to growing and sustaining open source projects through governance and tooling services. We employ systematic strategies to discover and nurture open source talent, providing comprehensive lifecycle support from project initiation to incubation and maturation. These governance practices ensure that projects are well-managed, leading to sustainable development and long-term success.On the other hand, we leverage digital and tooling-based open source infrastructure to create dynamic ecosystems. This includes digital growth dashboards that offer relational insights and analytics, as well as contribution incentive mechanisms that promote deeper community engagement. Join us to uncover: 1. How our governance service foundation lays the groundwork for robust open source project development. 2. Strategies for effective t

## Recent TPM Security Enhancements to the Linux Kernel - James Bottomley, Microsoft
 - [https://www.youtube.com/watch?v=WK7NERQXh4I](https://www.youtube.com/watch?v=WK7NERQXh4I)
 - RSS feed: $source
 - date published: 2024-10-31T00:21:32+00:00

Recent TPM Security Enhancements to the Linux Kernel - James Bottomley, Microsoft

Recent security updates to Linux, such as the new Systemd Unified Kernel Image[1] rely on the discrete or firmware integrated TPM (Trusted Platform Module) to verify boot and release secrets securely. However, there are many known attacks against the TPM chip itself. We will discuss the newly upstreamed Linux Kernel TPM security patches[2], which not only provide a basis for securely communicating with the TPM but also provide a novel defences against a wide variety of TPM based attacks by using a unique (to Linux) null key scheme. This talk will cover what TPM based attacks are (including interposer attacks), how the Trusted Computing Group expects you to tell you're talking to a real TPM and how you can communicate with it securely and use its policy statements to govern key use and release. We will then move on to how the new Linux Kernel patches extend this and can be leveraged to validate the TPM 

