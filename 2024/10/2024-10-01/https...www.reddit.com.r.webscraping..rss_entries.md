# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## Connecting Google Sheets and SerpApi on Make.com
 - [https://www.reddit.com/r/webscraping/comments/1ftxcs2/connecting_google_sheets_and_serpapi_on_makecom](https://www.reddit.com/r/webscraping/comments/1ftxcs2/connecting_google_sheets_and_serpapi_on_makecom)
 - RSS feed: $source
 - date published: 2024-10-01T19:53:19+00:00

<table> <tr><td> <a href="https://www.reddit.com/r/webscraping/comments/1ftxcs2/connecting_google_sheets_and_serpapi_on_makecom/"> <img src="https://external-preview.redd.it/SyLCjN8JEU_b9a_hqdIMi22eKeF4Mdx4pXOFzE8bjts.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=19bb1c2c168f20329fb69a2b17b973a1950f19f7" alt="Connecting Google Sheets and SerpApi on Make.com" title="Connecting Google Sheets and SerpApi on Make.com" /> </a> </td><td> &#32; submitted by &#32; <a href="https://www.reddit.com/user/laurusbaurus"> /u/laurusbaurus </a> <br/> <span><a href="https://serpapi.com/blog/connecting-google-sheets-and-serpapi-on-make-com/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1ftxcs2/connecting_google_sheets_and_serpapi_on_makecom/">[comments]</a></span> </td></tr></table>

## Seeking Advice on Implementing a Secure Data Scraping Solution
 - [https://www.reddit.com/r/webscraping/comments/1ftx52m/seeking_advice_on_implementing_a_secure_data](https://www.reddit.com/r/webscraping/comments/1ftx52m/seeking_advice_on_implementing_a_secure_data)
 - RSS feed: $source
 - date published: 2024-10-01T19:44:31+00:00

<!-- SC_OFF --><div class="md"><p>Hello everyone,</p> <p>We&#39;re a healthcare company working on a feature that involves securely accessing data from insurance portals based on user consent. We need to retrieve health-related data, such as claims and copay information, after users provide their credentials and permission.</p> <p>We have tried both Selenium-based scraping and reverse engineering the internal APIs of these portals but ran into issues with consistency and security. What would be the best approach to tackle this problem? Are there any reliable tools or best practices you would recommend for securely scraping or reading data from these types of portals?</p> <p>Appreciate your insights!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/iEmerald"> /u/iEmerald </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1ftx52m/seeking_advice_on_implementing_a_secure_data/">[link]</a></span> &#32; <span><a href="https://www.re

## Importance of User-Agent | 3 Essential Methods for Web Scrapers
 - [https://www.reddit.com/r/webscraping/comments/1ftwjy8/importance_of_useragent_3_essential_methods_for](https://www.reddit.com/r/webscraping/comments/1ftwjy8/importance_of_useragent_3_essential_methods_for)
 - RSS feed: $source
 - date published: 2024-10-01T19:20:22+00:00

<!-- SC_OFF --><div class="md"><p>As a Python developer and web scraper, you know that getting the right data is crucial. But have you ever hit a wall when trying to access certain websites? The secret weapon you might be overlooking is right in the request itself: headers.</p> <h1>Why Headers Matter</h1> <p>Headers are like your digital ID card. They tell websites who you are, what you’re using to browse, and what you’re looking for. Without the right headers, you might as well be knocking on a website’s door without introducing yourself – and we all know how that usually goes.</p> <p>Look the above code. Here I used the get request without headers so that the output is 403. Hence I failed to scrape data from indeed.com.</p> <p>But after that I used suitable headers in my python request. The I find the expected result 200.</p> <h1>The Consequences of Neglecting Headers</h1> <ol> <li>Blocked requests</li> <li>Inaccurate or incomplete data</li> <li>Inconsistent results</li> </ol> <p>Le

## webscraping for a dummy
 - [https://www.reddit.com/r/webscraping/comments/1ftvmng/webscraping_for_a_dummy](https://www.reddit.com/r/webscraping/comments/1ftvmng/webscraping_for_a_dummy)
 - RSS feed: $source
 - date published: 2024-10-01T18:43:24+00:00

<!-- SC_OFF --><div class="md"><p>Hi, i want to collect a list of articles, which i have approximate name of, from a certain public website.... these articles are public domain and can be copy pasted.... i want to create a text file for each article nammed with its specfic name in the list</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Odd-Currency-9672"> /u/Odd-Currency-9672 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1ftvmng/webscraping_for_a_dummy/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1ftvmng/webscraping_for_a_dummy/">[comments]</a></span>

## IWTL how to scrape a subreddit to only get post titles and content
 - [https://www.reddit.com/r/webscraping/comments/1fttg6l/iwtl_how_to_scrape_a_subreddit_to_only_get_post](https://www.reddit.com/r/webscraping/comments/1fttg6l/iwtl_how_to_scrape_a_subreddit_to_only_get_post)
 - RSS feed: $source
 - date published: 2024-10-01T17:14:26+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;m building a school project which would need the above data. I am an absolute beginner to webscraping, just learnt about bs4 and requests a couple days back. I thought I&#39;d start learning scrapy, but then got distracted by people saying PRAW is what I need and not scrapy, and still some others saying Selenium is where it&#39;s at, and all of this amidst the API changes and I&#39;m a bit lost.</p> <p>I&#39;d appreciate any guidance at all!</p> <p>PS: I tried simply modifying my basic BeautifulSoup code and it scraped the top 3 posts lmao...I&#39;m not sure if there&#39;s a way to do what I want by just using BeautifulSoup and requests either.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/BuildingWalls4Ever"> /u/BuildingWalls4Ever </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fttg6l/iwtl_how_to_scrape_a_subreddit_to_only_get_post/">[link]</a></span> &#32; <span><a href="https:/

## UFC Stats Scraping
 - [https://www.reddit.com/r/webscraping/comments/1ftsiy6/ufc_stats_scraping](https://www.reddit.com/r/webscraping/comments/1ftsiy6/ufc_stats_scraping)
 - RSS feed: $source
 - date published: 2024-10-01T16:37:08+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;m looking to make a ufc elo engine and for that i want to collect a bunch of stats from the start of the ufc (or as far back as their own website stats go). I&#39;ve seen people scrape it before but looking into for myself i noticed that somewhat expectedly the TOS contains a no scraping clause. This is my first time experimenting with webscraping so I&#39;m not sure how far boundaries can be pushed. Are people who&#39;ve done it before me in trouble? Is it safe to do it despite the TOS?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/ima9gager"> /u/ima9gager </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1ftsiy6/ufc_stats_scraping/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1ftsiy6/ufc_stats_scraping/">[comments]</a></span>

## Scrape comic entries from senscritique.com
 - [https://www.reddit.com/r/webscraping/comments/1ftlul3/scrape_comic_entries_from_senscritiquecom](https://www.reddit.com/r/webscraping/comments/1ftlul3/scrape_comic_entries_from_senscritiquecom)
 - RSS feed: $source
 - date published: 2024-10-01T11:33:16+00:00

<!-- SC_OFF --><div class="md"><p>Hi, </p> <p>For a personal project, I want to scrape the comic entries from :<br/> <a href="https://www.senscritique.com/search?page=1&amp;universe=comicBook&amp;year=2020-2021">https://www.senscritique.com/search?page=1&amp;universe=comicBook&amp;year=2020-2021</a></p> <p>Data are loaded via a POST request to <em><a href="https://apollo.senscritique.com/">https://apollo.senscritique.com/</a>.</em><br/> When I send directly my request, I have a <em>requests.exceptions.ConnectionError: (&#39;Connection aborted.&#39;, RemoteDisconnected(&#39;Remote end closed connection without response&#39;))</em></p> <p>Looks like<br/> I try with Python requests and scrapy modules.<br/> How can I get the entries? Can someone help me to understand how to do? </p> <p>FYI: I found a workaround by scraping the users and their followers. After, I scrape the entries for their library. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Me

## How can websites prevent scraping?
 - [https://www.reddit.com/r/webscraping/comments/1ftkr8h/how_can_websites_prevent_scraping](https://www.reddit.com/r/webscraping/comments/1ftkr8h/how_can_websites_prevent_scraping)
 - RSS feed: $source
 - date published: 2024-10-01T10:24:16+00:00

<!-- SC_OFF --><div class="md"><p>I’m building an analytics dashboard with novel data and would like to know what the best practices are for making a data dashboard impossible / hard to scrape. </p> <p>What tools and techniques can you use to prevent and detect it? </p> <p>The data would come in a feed and tables in json api calls. </p> <p>Thanks</p> <p>Edit: </p> <p>Users would be logged in and have authentication and would be expected to browse and consume a reasonable amount of data. What I’m looking for is the ability to detect and prevent scraping beyond normal usage. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/sentsignals"> /u/sentsignals </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1ftkr8h/how_can_websites_prevent_scraping/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1ftkr8h/how_can_websites_prevent_scraping/">[comments]</a></span>

## I completed my first dedicated web scraping project for a client
 - [https://www.reddit.com/r/webscraping/comments/1ftjzqq/i_completed_my_first_dedicated_web_scraping](https://www.reddit.com/r/webscraping/comments/1ftjzqq/i_completed_my_first_dedicated_web_scraping)
 - RSS feed: $source
 - date published: 2024-10-01T09:30:02+00:00

<!-- SC_OFF --><div class="md"><p>This was my first project fully focused on web scraping :)</p> <p>My client needed crawlers to extract real estate projects from 6 private developer portals in France. Each platform had outdated systems, no APIs, and slow servers.I built separate crawlers using HTTP requests, mimicking user behavior with headers and cookies, plus adding delays to avoid detection.</p> <p>For some, I found APIs through the console, and for the others, I used XPath to extract data. In the end, I scraped over 500 real estate programs, giving my client a strong edge in the market.</p> <p>Anyone else worked on similar projects? How did you approach it?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Fragrant_Awareness33"> /u/Fragrant_Awareness33 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1ftjzqq/i_completed_my_first_dedicated_web_scraping/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/web

## How to scrape many websites with different formats?
 - [https://www.reddit.com/r/webscraping/comments/1ftjrli/how_to_scrape_many_websites_with_different_formats](https://www.reddit.com/r/webscraping/comments/1ftjrli/how_to_scrape_many_websites_with_different_formats)
 - RSS feed: $source
 - date published: 2024-10-01T09:13:10+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;m working on a website that allows people to discover coffee beans from around the world independent of the roasters. For this I obviously have to scrape many different websites with many different formats. A lot ofthem use shopify, which makes it aready easier a bit. However, writing the scraper for a specific website still takes me around 1-2h with automatic data cleanup. I already did some experiments with AI tools like <a href="https://scrapegraphai.com/">https://scrapegraphai.com/</a> but then I have the problem of hallucination and it&#39;s way easier to spend the 1-2h to write the scraper that works 100%. I&#39;m missing somehing or isnt&#39;t there a better way to have a general approach?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Sufficient_Tree4275"> /u/Sufficient_Tree4275 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1ftjrli/how_to_scrape_many_websites_with_differen

## How to scrape the products from this webpage
 - [https://www.reddit.com/r/webscraping/comments/1ftfy9x/how_to_scrape_the_products_from_this_webpage](https://www.reddit.com/r/webscraping/comments/1ftfy9x/how_to_scrape_the_products_from_this_webpage)
 - RSS feed: $source
 - date published: 2024-10-01T04:42:22+00:00

<table> <tr><td> <a href="https://www.reddit.com/r/webscraping/comments/1ftfy9x/how_to_scrape_the_products_from_this_webpage/"> <img src="https://preview.redd.it/ncdtaeqtq2sd1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2c831dd5fdae322a39f8479c99293d10bdd6a89d" alt="How to scrape the products from this webpage" title="How to scrape the products from this webpage" /> </a> </td><td> <!-- SC_OFF --><div class="md"><p>Hi, this is my first time webscraping.</p> <p>I’m trying to get the products in <a href="https://d-tb.org/category/jZwndY?filters%5Bcategory_id%5D=72143221">https://d-tb.org/category/jZwndY?filters%5Bcategory_id%5D=72143221</a></p> <p>There are a total of 1000 products, initially only 15 products are shown, and more when clicking in the “load more” button.</p> <p>I tried finding the API from the network tap( while filtering for XHR), and i found the url but when i copy it and search for it i get the page shown in the image. What does it mean? And do I have to do to get

## Monthly Self-Promotion - October 2024
 - [https://www.reddit.com/r/webscraping/comments/1fte590/monthly_selfpromotion_october_2024](https://www.reddit.com/r/webscraping/comments/1fte590/monthly_selfpromotion_october_2024)
 - RSS feed: $source
 - date published: 2024-10-01T03:00:48+00:00

<!-- SC_OFF --><div class="md"><p>Hello and howdy, digital miners of !</p> <p>The moment you&#39;ve all been waiting for has arrived - it&#39;s our once-a-month, no-holds-barred, show-and-tell thread!</p> <ul> <li>Are you bursting with pride over that supercharged, brand-new scraper SaaS or shiny proxy service you&#39;ve just unleashed on the world?</li> <li>Maybe you&#39;ve got a ground-breaking product in need of some intrepid testers?</li> <li>Got a secret discount code burning a hole in your pocket that you&#39;re just itching to share with our talented tribe of data extractors?</li> <li>Looking to make sure your post doesn&#39;t fall foul of the community rules and get ousted by the spam filter?</li> </ul> <p>Well, this is your time to shine and shout from the digital rooftops - Welcome to your haven!</p> <p>Just a friendly reminder, we do like to keep all our self-promotion in one handy place, so any separate posts will be kindly redirected here. Now, let&#39;s get this party st

## Any idea to scrap an interactive leaflet map?
 - [https://www.reddit.com/r/webscraping/comments/1ftdzkb/any_idea_to_scrap_an_interactive_leaflet_map](https://www.reddit.com/r/webscraping/comments/1ftdzkb/any_idea_to_scrap_an_interactive_leaflet_map)
 - RSS feed: $source
 - date published: 2024-10-01T02:52:20+00:00

<!-- SC_OFF --><div class="md"><p>Hey!</p> <p>Im trying to scrape this web: <a href="https://estadisticas.renaper.gob.ar/app_myn/">https://estadisticas.renaper.gob.ar/app_myn/</a> , that contains an interactive Leaflet map.</p> <p>Specifically the &quot;Tasa bruta de natalidad&quot; category at the &quot;Nivel Departamental&quot; section. I need to scrap the value that appears in a new window when the cursor is over the region, for every available year.</p> <p>I tried several ways to do it but I had a lot of problems trying to interact with the API.</p> <p>Any help would be awesome.</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Sufficient_Hat_1203"> /u/Sufficient_Hat_1203 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1ftdzkb/any_idea_to_scrap_an_interactive_leaflet_map/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1ftdzkb/any_idea_to_scrap_an_interactive_leaflet_m

