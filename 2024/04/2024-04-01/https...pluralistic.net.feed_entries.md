# Source:Pluralistic: Daily links from Cory Doctorow, URL:https://pluralistic.net/feed, language:en-US

## Pluralistic: Humans are not perfectly vigilant (01 Apr 2024)
 - [https://pluralistic.net/2024/04/01/human-in-the-loop](https://pluralistic.net/2024/04/01/human-in-the-loop)
 - RSS feed: https://pluralistic.net/feed
 - date published: 2024-04-01T14:29:36+00:00

Today's links Humans are not perfectly vigilant: And that's bad news for AI. Hey look at this: Delights to delectate. This day in history: 2004, 2009, 2014, 2019, 2023 Upcoming appearances: Where to find me. Recent appearances: Where I've been. Latest books: You keep readin' em, I'll keep writin' 'em. Upcoming books: Like I said, I'll keep writin' 'em. Colophon: All the rest. Humans are not perfectly vigilant (permalink) Here's a fun AI story: a security researcher noticed that large companies' AI-authored source-code repeatedly referenced a nonexistent library (an AI "hallucination"), so he created a (defanged) malicious library with that name and uploaded it, and thousands of developers automatically downloaded and incorporated it as they compiled the code: https://www.theregister.com/2024/03/28/ai_bots_hallucinate_software_packages/ These "hallucinations" are a stubbornly persistent feature of large language models, because these models only give the illusion of understanding; in r

