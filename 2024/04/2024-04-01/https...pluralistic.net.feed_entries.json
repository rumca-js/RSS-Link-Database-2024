[{"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-04-01T14:29:36+00:00", "description": "Today's links Humans are not perfectly vigilant: And that's bad news for AI. Hey look at this: Delights to delectate. This day in history: 2004, 2009, 2014, 2019, 2023 Upcoming appearances: Where to find me. Recent appearances: Where I've been. Latest books: You keep readin' em, I'll keep writin' 'em. Upcoming books: Like I said, I'll keep writin' 'em. Colophon: All the rest. Humans are not perfectly vigilant (permalink) Here's a fun AI story: a security researcher noticed that large companies' AI-authored source-code repeatedly referenced a nonexistent library (an AI \"hallucination\"), so he created a (defanged) malicious library with that name and uploaded it, and thousands of developers automatically downloaded and incorporated it as they compiled the code: https://www.theregister.com/2024/03/28/ai_bots_hallucinate_software_packages/ These \"hallucinations\" are a stubbornly persistent feature of large language models, because these models only give the illusion of understanding; in r", "language": "en-US", "link": "https://pluralistic.net/2024/04/01/human-in-the-loop", "manual_status_code": 0, "page_rating": 100, "page_rating_contents": 100, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://pluralistic.net/feed", "source_obj__id": 253, "status_code": 0, "tags": [], "thumbnail": null, "title": "Pluralistic: Humans are not perfectly vigilant (01 Apr 2024)", "user": null, "vote": 0}]