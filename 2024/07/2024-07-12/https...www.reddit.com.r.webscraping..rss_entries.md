# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## [seek advice] Bypass cloudflare Scraper Protection
 - [https://www.reddit.com/r/webscraping/comments/1e1puo5/seek_advice_bypass_cloudflare_scraper_protection](https://www.reddit.com/r/webscraping/comments/1e1puo5/seek_advice_bypass_cloudflare_scraper_protection)
 - RSS feed: https://www.reddit.com/r/webscraping/.rss
 - date published: 2024-07-12T19:11:26+00:00

<table> <tr><td> <a href="https://www.reddit.com/r/webscraping/comments/1e1puo5/seek_advice_bypass_cloudflare_scraper_protection/"> <img alt="[seek advice] Bypass cloudflare Scraper Protection " src="https://a.thumbs.redditmedia.com/NYeWvblcVL0KuXPetEFRKxhy8cMeeprrlDFoeD85jr8.jpg" title="[seek advice] Bypass cloudflare Scraper Protection " /> </a> </td><td> <!-- SC_OFF --><div class="md"><p>python, using cloudScraper (github) and selenium.webdriver.<br /> I've tried setting tokens (cookies) and user-agent, but I just receive an error.</p> <p>Without the tokens, I got back the wait page, no matter how much delay did I input (&lt;title&gt;Just a moment...&lt;/title&gt;), meaning I need to address the verification stage properly.</p> <p>I'm not too familiar with web scrapping. This is a video game database, I wish to collect and parse for my and my friend's sake for fun. The website is - <a href="https://uniteapi.dev/p/WildAbsol">https://uniteapi.dev/p/WildAbsol</a> (I wish to have the u

## Scraping 6months worth of data, ~16,000,000 items side project help
 - [https://www.reddit.com/r/webscraping/comments/1e1okys/scraping_6months_worth_of_data_16000000_items](https://www.reddit.com/r/webscraping/comments/1e1okys/scraping_6months_worth_of_data_16000000_items)
 - RSS feed: https://www.reddit.com/r/webscraping/.rss
 - date published: 2024-07-12T18:17:27+00:00

<!-- SC_OFF --><div class="md"><p>Hi everyone,</p> <p>I could use some tips from you web scraping pros out there. I'm pretty familiar with programming but just got into web scraping a few days ago. I've got this project in mind where I want to scrape an auction site and build a database with the history of all items listed and sold + bidding history. Luckily, the site has this hidden API endpoint that spits out a bunch of info in JSON when I query an item ID. I'm thinking of eventually selling this data, or maybe even setting up an API if there's enough interest. Looks like I'll need to hit that API endpoint about 16 million times to get data for the past six months.</p> <p>I've got all the Scrapy code sorted out for rotating user agents, but now I'm at the point where I need to scale this thing without getting banned. From what I've researched, it sounds like I need to use a proxy. I tried some paid residential proxies and they work great, but they could end up costing me a fortune s

## ESL tutor looking to to scrape to find students.
 - [https://www.reddit.com/r/webscraping/comments/1e1n64s/esl_tutor_looking_to_to_scrape_to_find_students](https://www.reddit.com/r/webscraping/comments/1e1n64s/esl_tutor_looking_to_to_scrape_to_find_students)
 - RSS feed: https://www.reddit.com/r/webscraping/.rss
 - date published: 2024-07-12T17:19:37+00:00

<!-- SC_OFF --><div class="md"><p>Hi there I am a highly experienced ESL Tutor and I want to try my super beginner programming skills to scrape Facebook, Discord, and other platforms to find people who are looking for an English tutor.</p> <p>I have just started learning Python and Javascript and everyone says I should build a project. So this idea came to me.</p> <p>Is this possible? Can I do it with beginner skills? Any thoughts or suggestions much appreciated. </p> <p>TIA</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/douglas223"> /u/douglas223 </a> <br /> <span><a href="https://www.reddit.com/r/webscraping/comments/1e1n64s/esl_tutor_looking_to_to_scrape_to_find_students/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1e1n64s/esl_tutor_looking_to_to_scrape_to_find_students/">[comments]</a></span>

## Web scraping of HomeDepot
 - [https://www.reddit.com/r/webscraping/comments/1e1l0qx/web_scraping_of_homedepot](https://www.reddit.com/r/webscraping/comments/1e1l0qx/web_scraping_of_homedepot)
 - RSS feed: https://www.reddit.com/r/webscraping/.rss
 - date published: 2024-07-12T15:51:19+00:00

<!-- SC_OFF --><div class="md"><p>I am trying to scrape HomeDepot website. The code is attached below. Although the code is correct. I copied the curl command and converted it to code using online tool. The result code is below but it is giving me this error.</p> <pre><code> headers = { 'accept': '*/*', 'accept-language': 'en-GB,en-US;q=0.9,en;q=0.8', 'content-type': 'application/json', 'origin': 'https://www.homedepot.com', 'priority': 'u=1, i', 'referer': 'https://www.homedepot.com/', 'sec-ch-ua': '&quot;Not/A)Brand&quot;;v=&quot;8&quot;, &quot;Chromium&quot;;v=&quot;126&quot;, &quot;Google Chrome&quot;;v=&quot;126&quot;', 'sec-ch-ua-mobile': '?0', 'sec-ch-ua-platform': '&quot;macOS&quot;', 'sec-fetch-dest': 'empty', 'sec-fetch-mode': 'cors', 'sec-fetch-site': 'same-site', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36', 'x-api-cookies': '{&quot;x-user-id&quot;:&quot;6242ffe3-4b7e-3181-82b1-5500c76

## Basic Twitter(X) Scraping with Python, is it still possible?
 - [https://www.reddit.com/r/webscraping/comments/1e1ibmz/basic_twitterx_scraping_with_python_is_it_still](https://www.reddit.com/r/webscraping/comments/1e1ibmz/basic_twitterx_scraping_with_python_is_it_still)
 - RSS feed: https://www.reddit.com/r/webscraping/.rss
 - date published: 2024-07-12T13:57:00+00:00

<!-- SC_OFF --><div class="md"><p>There's so much info out there, much of which seems to be out of date and I'm not sure what is possible and what isn't.</p> <p>I just want to save all the tweets from a specific date for a list of users. Would use Python and probaly run a script once per day that updates with new tweets.</p> <p>Paying for the API is well out of reach. Is it still possible to scrape this without a Twitter account?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Spedley2142"> /u/Spedley2142 </a> <br /> <span><a href="https://www.reddit.com/r/webscraping/comments/1e1ibmz/basic_twitterx_scraping_with_python_is_it_still/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1e1ibmz/basic_twitterx_scraping_with_python_is_it_still/">[comments]</a></span>

## Proxy sharing for Website using Captcha not working? Botting
 - [https://www.reddit.com/r/webscraping/comments/1e1g9gb/proxy_sharing_for_website_using_captcha_not](https://www.reddit.com/r/webscraping/comments/1e1g9gb/proxy_sharing_for_website_using_captcha_not)
 - RSS feed: https://www.reddit.com/r/webscraping/.rss
 - date published: 2024-07-12T12:19:36+00:00

<!-- SC_OFF --><div class="md"><p>It’s possible to get through a small anime website for votings, but when I try it on another one it doesn’t seem to working? Is there something I can change? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/MyMan_290484"> /u/MyMan_290484 </a> <br /> <span><a href="https://www.reddit.com/r/webscraping/comments/1e1g9gb/proxy_sharing_for_website_using_captcha_not/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1e1g9gb/proxy_sharing_for_website_using_captcha_not/">[comments]</a></span>

## Nodriver with docker
 - [https://www.reddit.com/r/webscraping/comments/1e14iqx/nodriver_with_docker](https://www.reddit.com/r/webscraping/comments/1e14iqx/nodriver_with_docker)
 - RSS feed: https://www.reddit.com/r/webscraping/.rss
 - date published: 2024-07-12T00:48:02+00:00

<!-- SC_OFF --><div class="md"><p>Has anyone successfully worked on starting up nodriver crawling solution with a docker file?</p> <p>Also, running nodriver on Ubuntu (as root or not) leads to the exception: &quot;Failed to connect to browser. Need to pass no_sandbox=True&quot;. Even after passing the sandbox argument, I see the same exception. Anyone with a solution for this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/happyotaku35"> /u/happyotaku35 </a> <br /> <span><a href="https://www.reddit.com/r/webscraping/comments/1e14iqx/nodriver_with_docker/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1e14iqx/nodriver_with_docker/">[comments]</a></span>

