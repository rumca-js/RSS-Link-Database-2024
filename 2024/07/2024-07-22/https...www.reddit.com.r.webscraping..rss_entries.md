# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## Download videos linked from text
 - [https://www.reddit.com/r/webscraping/comments/1e9o2ez/download_videos_linked_from_text](https://www.reddit.com/r/webscraping/comments/1e9o2ez/download_videos_linked_from_text)
 - RSS feed: https://www.reddit.com/r/webscraping/.rss
 - date published: 2024-07-22T20:10:40+00:00

<!-- SC_OFF --><div class="md"><p>I have a site with 3 levels deep and on each level there are text links to download mp4 files. These are not viewable videos on the page using a video player. Any quick way to download those files?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Virtual_Section_5248"> /u/Virtual_Section_5248 </a> <br /> <span><a href="https://www.reddit.com/r/webscraping/comments/1e9o2ez/download_videos_linked_from_text/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1e9o2ez/download_videos_linked_from_text/">[comments]</a></span>

## Redfin Scrape
 - [https://www.reddit.com/r/webscraping/comments/1e9mwdx/redfin_scrape](https://www.reddit.com/r/webscraping/comments/1e9mwdx/redfin_scrape)
 - RSS feed: https://www.reddit.com/r/webscraping/.rss
 - date published: 2024-07-22T19:23:49+00:00

<!-- SC_OFF --><div class="md"><p>I‚Äôm trying to extract data from Redfin for research of my local market. I found the importxml function for sheets and it worked great, until I had too many fields and got loading errors on data fields so now I‚Äôm trying to find another way to extract this data. I found the Web Scraper extension for Chrome but am struggling to figure out how to use it. There are great tutorials but I feel like they‚Äôre showing simple ways of gathering data. What I‚Äôm looking for aren‚Äôt links or data in tables on the site. I have 77 zip codes that I‚Äôm trying to pull the data on for the following for each zip code: - number of houses currently for sale - median sales price - year over year sales price change - median days on market - quantity sold in past year - active foreclosures </p> <p>Does anyone have tips or instructions on how to scrape the data?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/red_lrker_0612"> /u/red_lrker_0612 

## Needing to get zip code PO box status from USPS.com
 - [https://www.reddit.com/r/webscraping/comments/1e9her2/needing_to_get_zip_code_po_box_status_from_uspscom](https://www.reddit.com/r/webscraping/comments/1e9her2/needing_to_get_zip_code_po_box_status_from_uspscom)
 - RSS feed: https://www.reddit.com/r/webscraping/.rss
 - date published: 2024-07-22T15:40:55+00:00

<!-- SC_OFF --><div class="md"><p>Hello!</p> <p>I am needing to establish which US zip codes are exclusively used for PO boxes. I need this data to come from USPS.com and have already tried looking for CSVs and APIs that show zip code types, but none do.</p> <p>Here is my manual method:</p> <ol> <li><p>Copy and paste a zip code from my excel spreadsheet into USPS zip code search function</p></li> <li><p>Copy and paste the city and state it gives me into the USPS city search function. This gives me all zip codes located within the city including PO box status.</p></li> <li><p>Input in Excel if the zip only is for a PO box.</p></li> </ol> <p>Can I get some direction regarding finding a way to set up a webscraper? </p> <p>I am going through 20k zip codes at a rate of one zip code every 20 seconds if I have to do this manually.</p> <p>I am a total noob at this and Python. I most query with SQL, but I am willing to learn the process if it gets me what I need.</p> </div><!-- SC_ON --> &#32;

## How big is the web scraping market ?
 - [https://www.reddit.com/r/webscraping/comments/1e99iaf/how_big_is_the_web_scraping_market](https://www.reddit.com/r/webscraping/comments/1e99iaf/how_big_is_the_web_scraping_market)
 - RSS feed: https://www.reddit.com/r/webscraping/.rss
 - date published: 2024-07-22T08:56:07+00:00

<!-- SC_OFF --><div class="md"><p>With the booming of AI with data recently, I was wondering how big is the current web scraping market. I got these number from searching the internet :</p> <p><strong>1. Market Size</strong></p> <ul> <li><strong>Global Market Size (2023):</strong> Approximately USD 1.2 billion</li> <li><strong>Expected CAGR (2023-2028):</strong> 23.5%.</li> <li><strong>Projected Market Size (2028):</strong> Around USD 3.4 billion.</li> </ul> <p><strong>2.Potential Key Growth Drivers:</strong></p> <ul> <li>Increasing reliance on data-driven decision-making across industries.</li> <li>Adoption of AI and machine learning for enhanced data analysis and insights.</li> <li>Rising demand for real-time data extraction and updates.</li> <li>Expansion of digital platforms and online marketplaces.</li> </ul> <p><strong>3. Industry Adoption:</strong></p> <ul> <li><strong>Real Estate:</strong> Market analysis, property valuation, trend forecasting.</li> <li><strong>E-commerce:</st

## Webscaping a PDF
 - [https://www.reddit.com/r/webscraping/comments/1e96fq4/webscaping_a_pdf](https://www.reddit.com/r/webscraping/comments/1e96fq4/webscaping_a_pdf)
 - RSS feed: https://www.reddit.com/r/webscraping/.rss
 - date published: 2024-07-22T05:26:18+00:00

<!-- SC_OFF --><div class="md"><p>I am trying to scape this pdf of a book:</p> <p><a href="http://14.139.58.199:8080/jspui/static/pdfjs/web/viewer.html?file=/jspui/bitstream/123456789/294/1/G967.pdf">http://14.139.58.199:8080/jspui/static/pdfjs/web/viewer.html?file=/jspui/bitstream/123456789/294/1/G967.pdf</a> </p> <p>It is nested in a viewer with a custom frame, that has no way to download the PDF. I have tried every trick I know. But, no success. I wrote a Python script and all I managed to scrape was a 20 kB corrupted PDF. I inspected web elements with the Kiwi Web browser Android app, but could not find the necessary element to extract. I could really do with some assistance and advice. Cheers</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/b9hummingbird"> /u/b9hummingbird </a> <br /> <span><a href="https://www.reddit.com/r/webscraping/comments/1e96fq4/webscaping_a_pdf/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscrap

## Has anyone successfully scraped data from Expedia.com in a headless manner?
 - [https://www.reddit.com/r/webscraping/comments/1e948vc/has_anyone_successfully_scraped_data_from](https://www.reddit.com/r/webscraping/comments/1e948vc/has_anyone_successfully_scraped_data_from)
 - RSS feed: https://www.reddit.com/r/webscraping/.rss
 - date published: 2024-07-22T03:16:49+00:00

<!-- SC_OFF --><div class="md"><p>Hi everyone,</p> <p>I‚Äôm working on a project that involves scraping data from <a href="http://Expedia.com">Expedia.com</a>, and I‚Äôve run into an issue. I can successfully scrape data using Puppeteer when the headless mode is turned off. However, when I switch to headless mode, the items don't seem to render, and the scraping fails.</p> <p>Has anyone here managed to scrape data from <a href="http://Expedia.com">Expedia.com</a> in headless mode? If so, what library did you use? Also, if you have any tips or workarounds for this rendering issue, I‚Äôd really appreciate your help!</p> <p>Thanks in advance!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/internet_cowboy_"> /u/internet_cowboy_ </a> <br /> <span><a href="https://www.reddit.com/r/webscraping/comments/1e948vc/has_anyone_successfully_scraped_data_from/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1e948vc/has_anyone_su

## Weekly LinkedIn, X, Facebook, etc - 22 Jul 2024
 - [https://www.reddit.com/r/webscraping/comments/1e91nq8/weekly_linkedin_x_facebook_etc_22_jul_2024](https://www.reddit.com/r/webscraping/comments/1e91nq8/weekly_linkedin_x_facebook_etc_22_jul_2024)
 - RSS feed: https://www.reddit.com/r/webscraping/.rss
 - date published: 2024-07-22T01:01:09+00:00

<!-- SC_OFF --><div class="md"><p>Please direct all your questions about scraping from these popular data sources to this thread</p> <p>In line with the <a href="https://reddit.com/r/webscraping/about/sticky?num=1">monthly self-promotion thread</a>, links to paid services and tooling are okay to post here ü§ù</p> <p>If you are new to scraping, please checkout the <a href="https://webscraping.fyi/">beginners guide</a> üå±</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/AutoModerator"> /u/AutoModerator </a> <br /> <span><a href="https://www.reddit.com/r/webscraping/comments/1e91nq8/weekly_linkedin_x_facebook_etc_22_jul_2024/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1e91nq8/weekly_linkedin_x_facebook_etc_22_jul_2024/">[comments]</a></span>

