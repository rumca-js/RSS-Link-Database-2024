[{"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-16T23:10:39+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, </p> <p>Im looking for some ideas of wesbites to scrape to grow my portfolio.</p> <p>So far I've scraped a few real estate websites and holiday rental websites. </p> <p>Any ideas are welcome</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/CatapillarClay\"> /u/CatapillarClay </a> <br /> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1e52sx6/ideas_for_growing_websraping_portfolio/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1e52sx6/ideas_for_growing_websraping_portfolio/\">[comments]</a></span>", "id": 877524, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1e52sx6/ideas_for_growing_websraping_portfolio", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Ideas for growing Websraping portfolio", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-16T22:15:44+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I tried scrapfly, but looks like they only allow you to use websocket in browser mode.</p> <p>Now I am thinking the cheapest way is to use undetected-chromedriver + javascript page execution for starting a websocket connection. Also install the recaptcha webextension to automatically bypass the CF anti bot page.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Low_Promotion_2574\"> /u/Low_Promotion_2574 </a> <br /> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1e51jqa/is_there_a_ready_to_use_service_to_bypass_cf_anti/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1e51jqa/is_there_a_ready_to_use_service_to_bypass_cf_anti/\">[comments]</a></span>", "id": 877178, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1e51jqa/is_there_a_ready_to_use_service_to_bypass_cf_anti", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Is there a ready to use service to bypass CF anti bot page for websockets?", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-16T21:19:22+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Wanted to ask the community to get some insight on what everyone is doing.</p> <ol> <li><p>What libraries do you use for scraping (scrapy, beautiful soup, other..etc)</p></li> <li><p>How do you host and run your scraping scripts (EC2, Lambda, your own server.. etc)</p></li> <li><p>How do you store the data (SQL vs NoSQL, Mongo, PostgreSQL, Snowflake ..etc)</p></li> <li><p>How do you process the data and manipulate it (Cron jobs, Airflow, ..etc)</p></li> </ol> <p>Would be really interested in getting insight into what would be the ideal way for setting things up in order to get some help for my own projects. I understand each section is really dependent on the size of the data, as well as other factors dependent on use case, but without giving a hundred specifications thought I might ask it generally. </p> <p>Thank you!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/JuicyBieber\"> /u/JuicyBieber </a> <br /> <span>", "id": 876728, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1e507up/opinions_on_ideal_stack_and_data_pipeline", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Opinions on ideal stack and data pipeline structure for webscraping?", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-16T20:59:46+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi,</p> <p>I've been scratching my head about this for a few days now. </p> <p>Perhaps some of you have tips.</p> <p>I usually start with the &quot;product archive&quot; page which acts like an hub to the single product pages.</p> <p>Like this </p> <p><code>| /products</code><br /> <code>| - /product-1-fiat-500</code><br /> <code>| - /product-bmw-x3</code></p> <ul> <li>What I'm going to do is loop each detail page: <ul> <li>Minimize it (remove header, footer, ...)<br /></li> <li>Call openai and add the minimized markup + structured data prompt. <ul> <li><em>(</em><strong><em>Like:</em></strong> <em>&quot;Scrape this page: &lt;content&gt; and extract the data like the schema &lt;schema&gt;)</em></li> </ul></li> </ul></li> </ul> <p>Schema Example:</p> <p><code>{</code><br /> <code>title:</code><br /> <code>description:</code><br /> <code>price:</code><br /> <code>categories: [&quot;car&quot;, &quot;bike&quot;]</code><br /> <code>}</code></p> <ul> <li>Sa", "id": 876729, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1e4zqk0/advice_needed_how_to_deal_with_unstructured_data", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Advice needed: How to deal with unstructured data for a multi-page website using AI?", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-16T19:38:05+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all, I'm looking for ways to gather data on advertisement performance for ads in online ad libraries - Google ad library, meta ad library (only offers performance metrics for EU), LinkedIn ad library, etc... These large ad platforms don't offer the data outright, but I was wondering whether there was anywhere I could access this data or related information. If anyone has any ideas/experience about this I'd love to hear it!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/tiefedpiece\"> /u/tiefedpiece </a> <br /> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1e4xqbr/accessing_advertisement_performance_data_in/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1e4xqbr/accessing_advertisement_performance_data_in/\">[comments]</a></span>", "id": 876440, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1e4xqbr/accessing_advertisement_performance_data_in", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Accessing advertisement performance data in online ad libraries", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-16T18:33:52+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone, I am scraping a website and I cant seem to automate the pressing of a 'button' which has 'Create Order' on it, even though it is perfectly clickable manually. Here is the HTML element:</p> <p><code>&lt;a id=&quot;lb_new_order&quot; class=&quot;btn btn-success lb_new_order&quot; href=&quot;javascript:__doPostBack('lb_new_order','')&quot;&gt;Create Order&lt;/a&gt;</code></p> <p>However, I'm not sure why, but this is only findable AFTER I have keyword searched for 'Create Order' in 'Elements', or after expanding elements myself and finding it in the HTML code - this seems to be the only thing that makes it findable (not even manually clicking on the button makes it findable with a search). The search I am using in the browser console is this:</p> <p><code>[...document.querySelectorAll('a')]</code></p> <p><code>.filter(element =&gt;</code> </p> <p><code>element.innerText.includes('Create Order')</code></p> <p><code>)</code></p> <p>and as I sa", "id": 875981, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1e4w5f8/scraping_with_puppeteer_cant_find_element", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Scraping with puppeteer - can't find element", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-16T15:59:15+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>hello, how can I scrape my subscriptions I want the channel names and how many subscribers for this channel without using YouTube data API, I have used selenium but when it came to the log in step, and I entered my email google refused to continue the log in because it might be harmful so is there any other way</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/lil-shrimp1\"> /u/lil-shrimp1 </a> <br /> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1e4saiy/scraping_my_subscriptions/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1e4saiy/scraping_my_subscriptions/\">[comments]</a></span>", "id": 877525, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1e4saiy/scraping_my_subscriptions", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "scraping my subscriptions", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-16T15:10:54+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I am very new to programming and webscraping. Are there any methods to earn through web scraping? Are they legal? How much can I expect and I am a beginner so what resources should look for to learn.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/thanos2131\"> /u/thanos2131 </a> <br /> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1e4r3yr/earning_through_webscraping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1e4r3yr/earning_through_webscraping/\">[comments]</a></span>", "id": 874533, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1e4r3yr/earning_through_webscraping", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Earning through webscraping", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-16T13:59:45+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Need some help with mapping out the architecture for this.</p> <p>I am sending specific API requests with multiple tiktok accounts (100+ accounts), and the API requests require the accounts sessionID.</p> <p>Therefore, all of these Tiktok accounts need to all be constantly logged in (because everytime you login, the session ID changes.)</p> <p>Another thing to consider is these session IDs automatically change once every 2 months. So I need some architecture to scrape the session IDs every 2 months</p> <p>What's the best way to go about this?</p> <p>I've personally come up with 2 route to solutions.</p> <p>Solution 1 is for every API call, log into tiktok through a webdriver and get the session ID for that session then run the API call with that session ID. This means the session ID is refreshed and grabbed every time it runs.</p> <p>Solution 2 is use something like Ghost Browser which allows you to login to as many accounts as you like, and then logi", "id": 874028, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1e4pdhv/sending_api_requests_with_multiple_tiktok", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Sending API requests with multiple tiktok accounts (requiring multiple session IDs)", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-16T01:00:21+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I was able to scrape Google maps for 2k+ businesses that I compiled into a Google sheet. I have the URL, business name, and city. I later realized that I need the actual address and pictures (from Google maps or their website) would be nice. The scraper I used won\u2019t pull it. Is there a way I can leverage my existing list? I\u2019ve tried a few ideas with no luck. I have no coding experience but am willing to learn python if my laptop can handle it. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TheAce5\"> /u/TheAce5 </a> <br /> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1e4bljq/whats_the_easiest_way_to_pull_business_addresses/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1e4bljq/whats_the_easiest_way_to_pull_business_addresses/\">[comments]</a></span>", "id": 870445, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1e4bljq/whats_the_easiest_way_to_pull_business_addresses", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "What\u2019s the easiest way to pull business addresses and pictures?", "user": null, "vote": 0}]