[{"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-25T20:49:15+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I'm going to develop an app that enters the nearest address, captures 10-15 iFramed-space listings, screenshots the listings individually, and OCRs the img to txt for the hourly rate for listings. I'd like to deliver a nice Email with the screenshot of the listing and the average hourly rate. </p> <p>It's pretty straightforward and the original path was asking all of these vendors for an API. Well API-less, let's scrape. I've been browsing and browsing but I'm coming here looking for a solution. This is just a step above Selenium and ideally I do this in as few steps as possible without a multi-part pipeline (I could Selenium -&gt; Tesseract -&gt; AI but I like life simpler). </p> <p>I'm open to just about any product recommendation, YES please include names (Mods-please let me know names!). I'm open to any open source solution but I'm preferential towards something that's robust and repeatable. I'm using this data as part of a service and don't want ", "id": 930845, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1ec5lzu/scraping_recommendationscrape_screenshot_imagetxt", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Scraping Recommendation-Scrape, Screenshot, Image->TXT with AI", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-25T19:27:53+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I created an airbnb scraper using selenium and bs4, it works for each urls but the problem is after like 150 urls, airbnb blocks my ip, and when I try using proxies, airbnb doesn't allow the connection. Does anyone know any way to get around this? thanks</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/yoyotir\"> /u/yoyotir </a> <br /> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ec3mb7/how_to_stop_airbnb_from_detecting_me/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ec3mb7/how_to_stop_airbnb_from_detecting_me/\">[comments]</a></span>", "id": 930358, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1ec3mb7/how_to_stop_airbnb_from_detecting_me", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "How to stop airbnb from detecting me", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-25T18:08:20+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Has anyone managed / found a good way to deserialize responses from a GWT.rpc service? We're running into an issue with a number of sites that pull data from their server using GWT.rpc, but don't show all of the data on the page itself. We can see the data in the body of the response, but it the website doesn't show it in any HTML elements on the page itself. We're trying to deserialize the responses, but haven't found any solutions that work.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/vonadz\"> /u/vonadz </a> <br /> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ec1n84/scarping_gwtrpc_data/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ec1n84/scarping_gwtrpc_data/\">[comments]</a></span>", "id": 929829, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1ec1n84/scarping_gwtrpc_data", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Scarping GWT.rpc data", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-25T17:32:13+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi guys, over the years I've realised web scraping is one of the most maintenance-intensive job. </p> <p>Also, it's a very tiny area so eventually I went on to become SDE/cloud guy, etc. but I still like web scraping, probably because it was the first program I wrote or maybe because of the expertise.</p> <p>What are some &quot;sustainable&quot; businesses you think can be done around this? </p> <p>Please also highlight the trade secret of that business (e.g. IP rotation business requires a pool of IPs from a cloud company, steps to acquire it).</p> <p>This will create some ideas for everyone (and me ofc) in this niche who want build something. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PastPicture\"> /u/PastPicture </a> <br /> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ec0r8q/sustainable_business_in_this_niche_domain/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscr", "id": 929830, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1ec0r8q/sustainable_business_in_this_niche_domain", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Sustainable business in this niche domain", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-25T17:08:09+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I have been writing this bot for about a month and hooked it up to a web scraper that pulls job urls from LinkedIn to apply. Currently it only supports filling out forms and applying on Greenhouse and Lever applications but I've come at a bit of standstill due to the anti-bot detection on Greenhouse. Currently I use Playwright and a fork of <a href=\"https://github.com/iloveitaly/playwright_stealth.git\">Playwright Stealth</a> along with (free) proxies to not get flagged though the results are not perfect. According to <a href=\"https://bot.sannysoft.com\">sannysoft</a> I pass the checks but obviously according to <a href=\"https://fingerprint.com/products/bot-detection/\">fingerprint</a> I get flagged as puppeteer stealth. </p> <p>My main questions are as follows:</p> <p>How do I determine what or how a website determines who is a bot or not? </p> <p>The issue I have is that more often than not I am required to verify my email and paste the 2-factor code i", "id": 929331, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1ec05uo/job_autosubmit", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Job AutoSubmit", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-25T15:22:47+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>What is the best way to get financial data of a stock that is possibly more than 4 year? like from yfinance it's only the last 4. Searcing for something free. I'm using python. I tried to use the SEC's Edgar database to but I can't understand how it is structured. The data seems to be named in different ways between various actions and various data are missing, like tesla and google have no data for TotalRevenue. Also finding a way to get the id for stock on morningstar url with the stock tocker would be helpful, like aapl id=0P000000GY</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Quaggioo\"> /u/Quaggioo </a> <br /> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ebxlle/web_scraping_for_financial_data/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ebxlle/web_scraping_for_financial_data/\">[comments]</a></span>", "id": 929831, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1ebxlle/web_scraping_for_financial_data", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "web scraping for financial data", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-25T15:04:57+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p>I'm new to using Playwright and currently working with it alongside Python. I have a question regarding the <code>timeout</code> argument in the <code>page.locator</code> method. Is it possible to use the <code>timeout</code> argument directly within <code>page.locator</code>?</p> <p>If yes, could someone provide an example? If it's not possible, what alternatives do you suggest?</p> <p>Thanks in advance for your help!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Soft-Wish9738\"> /u/Soft-Wish9738 </a> <br /> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ebx5tm/question_about_using_timeout_argument_in/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ebx5tm/question_about_using_timeout_argument_in/\">[comments]</a></span>", "id": 929832, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1ebx5tm/question_about_using_timeout_argument_in", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Question About Using timeout Argument in Playwright's page.locator Method", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-25T13:58:23+00:00", "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1ebvko8/scrape_phone_number_shown_when_hovering/\"> <img alt=\"Scrape phone number shown when hovering\" src=\"https://b.thumbs.redditmedia.com/wYE5UJVUfS3L1hOFyCSd08ryC7tArbcUuf_WwvMRmsg.jpg\" title=\"Scrape phone number shown when hovering\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p>Do you have any ideas how I could scrape information that is just shown when hovering over a button?</p> <p>I would like to scrape phone numbers on Ocean.io. InstantDataScraper does not scrape it.</p> <p>I would like to use a very easy tool so not Python.</p> <p>Looking forward to your recommendations!</p> <p>Thanks! </p> <p><a href=\"https://preview.redd.it/otjh0aer7oed1.png?width=1576&amp;format=png&amp;auto=webp&amp;s=ad15b869c2bb8d7e05d6b72e7c984eaf7cb08bbf\">https://preview.redd.it/otjh0aer7oed1.png?width=1576&amp;format=png&amp;auto=webp&amp;s=ad15b869c2bb8d7e05d6b72e7c984eaf7cb08bbf</a></p> </div><!-- SC_O", "id": 928324, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1ebvko8/scrape_phone_number_shown_when_hovering", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 86, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": "https://b.thumbs.redditmedia.com/wYE5UJVUfS3L1hOFyCSd08ryC7tArbcUuf_WwvMRmsg.jpg", "title": "Scrape phone number shown when hovering", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-25T12:38:17+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi there,</p> <p>Note: this is a purely technical question, ignore legal implications.</p> <p>If I have an aggregator marketplace (aggregates deals from downstream websites), are there any end to end (e2e) solutions that:</p> <ul> <li><p>Payments are made on the UI of the aggregator marketplace</p></li> <li><p>The e2e solution is able to forward the payment (by means of a Web Automation Framework i.e. Puppeteer, Selenium) to the downstream website.</p></li> <li><p>If the downstream website requires a capcha or a payment authorisation that is handled by the e2e solution.</p></li> </ul> <p>Thanks for your help.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Odd-Wolverine-6234\"> /u/Odd-Wolverine-6234 </a> <br /> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ebttvh/payment_automation/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ebttvh/payment_automation/\">[c", "id": 929833, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1ebttvh/payment_automation", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Payment Automation", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-25T12:27:38+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi,<br /> I see some companies scraping restaurant reviews from talabat (which is ok) but they are showing the full name of the reviewer, which is not available on the website or mobile app itself. How do you think they are achieving this? I already checked and verified that Talabat does not have a review api.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Lecture_Tight\"> /u/Lecture_Tight </a> <br /> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ebtm73/talabat_how_to_get_full_name/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ebtm73/talabat_how_to_get_full_name/\">[comments]</a></span>", "id": 927842, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1ebtm73/talabat_how_to_get_full_name", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Talabat - how to get full name", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-25T10:08:57+00:00", "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Maleficent_Mess6445\"> /u/Maleficent_Mess6445 </a> <br /> <span><a href=\"/r/u_Maleficent_Mess6445/comments/1ebr19t/i_want_to_provide_my_codes_to_other_people_like/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ebr7jk/i_want_to_provide_my_codes_to_other_people_like/\">[comments]</a></span>", "id": 926940, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1ebr7jk/i_want_to_provide_my_codes_to_other_people_like", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "I want to provide my codes to other people like WooCommerce and WordPress owners and other software enthusiasts for a fee. I got these built through freelancers and by myself after putting many hours in testing etc. I only intend to charge minimum price.", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-25T09:05:56+00:00", "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1ebqa8a/scraping_li_and_button/\"> <img alt=\"Scraping /li and /button ?\" src=\"https://b.thumbs.redditmedia.com/eDoVAbDSaH8hdoWqsZR195kX6nM2biCaiPq76HdCg7g.jpg\" title=\"Scraping /li and /button ?\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hi<br /> I am trying to scrape <a href=\"https://www.sivasdescalzo.com/ae/p/s-s-chase-t-shirt-i026391-00rxx\">this website</a> and specifically the sizes (S etc) but the issue is, when I read the html, /html/body/div[2]/div[2]/main/div/div[1]/div/div/div[2]/div/div[1]/div[3]/div/ol exists, while the length of /html/body/div[2]/div[2]/main/div/div[1]/div/div/div[2]/div/div[1]/div[3]/div/ol/li is 0.</p> <p>And so I am no able to read the buttons. I don't need to click them, I just need to read the text inside of them.</p> <p><a href=\"https://preview.redd.it/ycn03v4q0ned1.png?width=539&amp;format=png&amp;auto=webp&amp;s=e576709039fcd16e4618b2eaee0c308f12d25499\">https://preview.", "id": 926262, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1ebqa8a/scraping_li_and_button", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 86, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": "https://b.thumbs.redditmedia.com/eDoVAbDSaH8hdoWqsZR195kX6nM2biCaiPq76HdCg7g.jpg", "title": "Scraping /li and /button ?", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-25T08:31:07+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Has this been done?<br /> So, most AI scrappers are AI in name only, or offer prefilled fields like 'job', 'list', and so forth. I find scrappers really annoying in having to go to the page and manually select what you need, plus this doesn't self-heal if the page changes. Now, what about this: you tell the AI what it needs to find, maybe showing it a picture of the page or simply in plain text describe it, you give it the url and then it access it, generates relevant code for the next time and uses it every time you try to pull that data. If there's something wrong, the AI should regenerate the code by comparing the output with the target everytime it runs (there can always be mismatchs, so a force code regen should always be an option).<br /> So, is this a thing? Does it exist?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Impossible-Study-169\"> /u/Impossible-Study-169 </a> <br /> <span><a href=\"https://www.r", "id": 925852, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1ebps7x/even_better_ai_scrapping", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Even better AI scrapping", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-25T07:30:11+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I'm having trouble scraping the website leroymerlin<a href=\"http://obramat.es\">.es</a> to get all the URLs. I've tried using Scrapy and Requests, but I keep getting a 403 error. I also tried using Selenium with undetected chromedriver, but I'm stuck with different captchas.</p> <p>Does anyone know which library I should use? How can I avoid the captcha if I'm already using proxies?</p> <p>What I'm trying is to get all the hrefs from the URL. Once I have them, I want to visit each one to gather more hrefs, storing them in a list without duplicates to avoid visiting the same page twice.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Strict-Funny6225\"> /u/Strict-Funny6225 </a> <br /> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ebownh/scraping_throws_captcha/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ebownh/scraping_throws_captcha/\">[comments]</a></span>", "id": 926263, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1ebownh/scraping_throws_captcha", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Scraping throws captcha", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-25T01:49:46+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>When looking at a stock chart online, oftentimes you can slide the cursor along the chart to see the fine-grained data in a little pop-up that follows the cursor. No network requests are made during the cursor-slide action, so the data must be stored in the browser somewhere. Upon perusing all the network requests, there is no pricing json data that gets sent over. Neither is there data when inspecting the page source. I would assume the pricing data is mapped to the position at which it gets displayed, so where might that data be? </p> <p>Unless, they are using some sort of data-to-cursor-position scaling function that allows them to generate what the price would be at that cursor position without having to actually send the data over. Maybe both my hypotheses are missing how they actually pull this off.</p> <p>I\u2019ve always been curious how these sites handle this, not even from a scraping perspective, but have yet to find any information on the topic", "id": 925020, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1ebiyd3/the_data_must_be_here_right", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "The data must be here, right?", "user": null, "vote": 0}]