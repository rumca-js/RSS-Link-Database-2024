[{"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-21T22:12:17+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I am new at web scraping, but am working on a project to do some scraping from a governmental website for some of their administrative rules. I am using Scrapy. Although, my issue arose as I was just trying to figure out how I wanted to parse it. </p> <p>I used Scrapy Shell and realized that when I pass the URL to Scrapy Shell the response I get is a redirected page that says (in addition to more) &quot;our cyber-security service, which provides protection for our customers and systems, has identified a problem that prevents us from completing your request.&quot; There is a link for &quot;Possible Causes and Remedies,&quot; of which there are three: (1) blacklisted IP, (2) anonymous or hidden proxy server, and (3) unsupported web browser. I am assuming it is #2 that is causing the problem, but don't really know, thus I am here.</p> <p>The site I am attempting to scrape is: <a href=\"https://secure.sos.state.or.us/oard/displayDivisionRules.action?select", "id": 905204, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1e8y3ao/blocked_web_page_using_scrapy", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Blocked Web Page using Scrapy", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-21T20:47:38+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>very new to this concept of web scraping. have access to claude/gpt/phyton/vscode could someone point me the right direction; I'd like to scrape profiles that have a specific set of keywords on their profile. I have been able to use the 'advanced search' and scrape through easy scraper's chrome extension; but i think i get limited out. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/robertovertical\"> /u/robertovertical </a> <br /> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1e8w79c/twitterx_key_words_in_profiles/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1e8w79c/twitterx_key_words_in_profiles/\">[comments]</a></span>", "id": 904978, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1e8w79c/twitterx_key_words_in_profiles", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Twitter/X key words in profiles", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-21T19:17:16+00:00", "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1e8u4bd/captchacode_collecting_without_a_va/\"> <img alt=\"Captcha/Code Collecting without a VA? \" src=\"https://b.thumbs.redditmedia.com/aJ3gc8YY2yDIc3J7l0dz2Idwyp58jmQ1XgQYUKLtmvs.jpg\" title=\"Captcha/Code Collecting without a VA? \" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I use sites that have Captcha puzzles. At the end of the puzzle a code is displayed that needs to be put in a spreadsheet software. There is 5m cooldown between each completed puzzle meaning 12 codes can be collected in a 60m window.</p> <p>I've seen people on freelance sites offer .15c per code to do this for you. There are also outsource websites where you can hire VA's from the Philippines and the price is comparable. (They do this by remoting into your PC with software like TeamViewer)</p> <p>I'm curious if there's another way to automate this? I've heard extensions and sites like NopeCHA are instant bans waiting to happen. The anti", "id": 904519, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1e8u4bd/captchacode_collecting_without_a_va", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 86, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": "https://b.thumbs.redditmedia.com/aJ3gc8YY2yDIc3J7l0dz2Idwyp58jmQ1XgQYUKLtmvs.jpg", "title": "Captcha/Code Collecting without a VA?", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-21T18:20:35+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I would like to know if it is possible to get the analytics data via API from TikTok. For business account owners, Tiktok has their built-in analytics dashboard here at <a href=\"https://www.tiktok.com/business-suite/insight/overview\">https://www.tiktok.com/business-suite/insight/overview</a> and I am looking up how I can get that data directly via API. </p> <p>As far as I have read here <a href=\"https://www.getphyllo.com/post/tiktok-api-integration-101-for-the-developers-of-the-creator-economy\">~TikTok API Integration: Complete Guide for Developers | Phyllo~</a>, the process involves creating an app, submitting review for approval from TikTok. Since I only want to get data from my own account, I don't want to go through those steps. If anyone has done it before, I would like some guidance. Thank you.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/zephael-lejeli\"> /u/zephael-lejeli </a> <br /> <span><a href=\"http", "id": 904245, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1e8st0n/need_help_getting_analytics_data_from_tiktok", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Need Help Getting Analytics Data from TikTok Business Suite", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-21T16:06:14+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello everyone, i am working on a research project that involves automatically scraping GitHub\u2019s public repositories to retrieve the Readme files and tags. </p> <p>I am using a standard token, that allows for 5000 API requests each hour. </p> <p>The script works fine, until i start receiving 401 error messages all of a sudden: the credentials i am using during the whole process are always the same, and i am checking to make sure i never hit the API limit (so that i don\u2019t get any 403 error codes). </p> <p>I am not sure what is causing this: i am not using concurrent processes, as to not overload the API, and i am not hitting the rate limit. The token i am using is not being invalidated by GitHub, but still i am getting kicked out. </p> <p>I am using python, using libraries such as beautifulsoup4 and request to make the calls.</p> <p>Do you have any idea why this might happen?</p> <p>Thank you for your attention!</p> </div><!-- SC_ON --> &#32; submitted", "id": 903823, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1e8pq38/help_scraping_public_info_from_github", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Help scraping public info from GitHub", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-21T15:17:29+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Im scraping online recipes to display on a mobile app (only publicly available recipes). These include images, so it'll be pretty obvious where the recipes came from to anyone who knows the original site.</p> <p>Should I include a link within the mobile app to the original site? I'm pretty sure it's not a requirement... (unless it is, please let me know), I'm just mindful of the potential of people thinking it's a bit of a shady thing to and could come back at me. I often see Instagram comments of people upset artists aren't getting credited in posts.</p> <p>On the other hand, I'd rather not actively link people out of the mobile app if I can help it.</p> <p>PS, in the the future I intended to monetise the app with additional features, but all recipes will be viewable by all users, regarding if they're paid users.</p> <p>TIA!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Stock-Low-5593\"> /u/Stock-Low-5593 </a> ", "id": 903824, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1e8om82/should_i_include_a_link_to_original_site", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Should I include a link to original site?", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-21T13:43:44+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I need help to complete this project - <a href=\"https://www.freelancer.com/projects/web-scraping/Website-Data-Mining-Web-Scraping/details\">https://www.freelancer.com/projects/web-scraping/Website-Data-Mining-Web-Scraping/details</a></p> <p>I already have some code - <a href=\"https://github.com/Anurag-Baundwal/school-data-scraper-2\">https://github.com/Anurag-Baundwal/school-data-scraper-2</a></p> <p>It scrapes data from urls present in the excel sheet linked by the client. There are 4 different columns for urls - for majors, for coaches, for rosters, and for logos.</p> <p>It uses slightly different methods for scraping the 4 kinds of data.</p> <ol> <li>Traditional webscraping techniques - used for scraping logos since they all come from wikipedia pages, and wikipedia pages have pretty much the same format. Also used for scraping majors, because the html content on all the urls for the majors has pretty much the same tabular format. This is because most", "id": 903393, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1e8mn6i/need_help_to_complete_a_large_webscraping_project", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Need help to complete a large webscraping project", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-21T12:44:17+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Firstly,yes I'm aware about the do's and don'ts but I have to \ud83d\udc40.</p> <p>I'm looking into a proxy and this and that, but what do you guys reccomend doing it? I know selenium is a big no no. Is there a framework or a certain toolset you can reccomend me? I am thinking about using python as I'm most comfortable with it, and I looked up some GitHub repos and researched a bit but I thought maybe I should ask you guys as a lot of you have more experience with this.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/cocatrice\"> /u/cocatrice </a> <br /> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1e8lhma/questions_about_scraping_sales_nav/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1e8lhma/questions_about_scraping_sales_nav/\">[comments]</a></span>", "id": 903127, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1e8lhma/questions_about_scraping_sales_nav", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Questions about scraping sales nav", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-21T10:27:28+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I FAILED scraping PROFILE PICTURE FROM THIS WEBSITE:</p> <p><a href=\"https://www.football.org.il/en/players/player/?player_id=113625\">https://www.football.org.il/en/players/player/?player_id=113625</a></p> <p>The pictures are being saved not as .png but as unusual **&quot;ImageServer/GetImage.ashx&quot;**</p> <p>I tried using:**Selenium Script**, import **BeautifulSoup** and **Postman** for my code to scrape but it seems its not working and fetched (I receive error).</p> <p>this is the url picture:</p> <p><a href=\"https://www.football.org.il/ImageServer/GetImage.ashx?type=2&amp;id=561538&amp;width=240&amp;height=305\">https://www.football.org.il/ImageServer/GetImage.ashx?type=2&amp;id=561538&amp;width=240&amp;height=305</a></p> <p>I want to create a python function that gets URL profile player and return his URL PROFILE PICTURE</p> <p>thank you.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Maleficent-Scale-632\"", "id": 902906, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1e8j9zb/scraping_image_challenge_help", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Scraping image Challenge! . HELP!", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-07-21T02:54:53+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m trying to scrape subtitles from a YouTube video using Symfony BrowserKit and it works on local server, but when I deploy the code to my VPS, the subtitles data is not available in the HTML text and I see \u201cSign in to confirm you\u2019re not a bot\u201d message when displaying the site. Is there any way to bypass this issue?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/piniek435\"> /u/piniek435 </a> <br /> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1e8cjjo/trying_to_scrape_subtitles_from_youtube_video_but/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1e8cjjo/trying_to_scrape_subtitles_from_youtube_video_but/\">[comments]</a></span>", "id": 901886, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1e8cjjo/trying_to_scrape_subtitles_from_youtube_video_but", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Trying to scrape subtitles from YouTube video but I get \"Sign in to confirm you're not a bot\" error", "user": null, "vote": 0}]