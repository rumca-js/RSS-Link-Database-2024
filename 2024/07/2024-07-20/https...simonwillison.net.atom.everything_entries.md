# Source:Simon Willison's Weblog, URL:https://simonwillison.net/atom/everything, language:en-us

## Smaller, Cheaper, Faster, Sober
 - [https://simonwillison.net/2024/Jul/20/smaller-cheaper-faster-sober/#atom-everything](https://simonwillison.net/2024/Jul/20/smaller-cheaper-faster-sober/#atom-everything)
 - RSS feed: https://simonwillison.net/atom/everything
 - date published: 2024-07-20T16:39:34+00:00

<p><a href="https://www.dbreunig.com/2024/07/20/smaller-cheaper-faster-sober.html">Smaller, Cheaper, Faster, Sober</a></p>
Drew Breunig highlights the interesting pattern at the moment where the best models are all converging on GPT-4 class capabilities, while competing on speed and price—becoming smaller and faster. This holds for both the proprietary and the openly licensed models.</p>

<p>Will we see a sizable leap in capabilities when GPT-5 class models start to emerge? It’s hard to say for sure—anyone in a position to know that likely works for an AI lab with a multi-billion dollar valuation that hinges on the answer to that equation, so they’re not reliable sources of information until the models themselves are revealed.


    <p>Tags: <a href="https://simonwillison.net/tags/drew-breunig">drew-breunig</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-a

## Quoting Benedict Evans
 - [https://simonwillison.net/2024/Jul/20/benedict-evans/#atom-everything](https://simonwillison.net/2024/Jul/20/benedict-evans/#atom-everything)
 - RSS feed: https://simonwillison.net/atom/everything
 - date published: 2024-07-20T15:28:17+00:00

<blockquote cite="https://www.ben-evans.com/benedictevans/2024/7/9/the-ai-summer"><p>Stepping back, though, the very speed with which ChatGPT went from a science project to 100m users might have been a trap (a little as NLP was for Alexa). LLMs <em>look</em> like they work, and they look generalised, and they <em>look</em> like a product - the science of them delivers a chatbot and a chatbot looks like a product. You type something in and you get magic back! But the magic might not be useful, in that form, and it might be wrong. It looks like product, but it isn’t. [...]</p>
<p>LLMs <em>look</em> like better databases, and they <em>look</em> like search, but, as we’ve seen since, they’re ‘wrong’ enough, and the ‘wrong’ is hard enough to manage, that you can’t just give the user a raw prompt and a raw output - you need to build a lot of dedicated product around that, and even then it’s not clear how useful this is.</p></blockquote><p class="cite">&mdash; <a href="https://www.ben-evans.

## Mapping the landscape of gen-AI product user experience
 - [https://simonwillison.net/2024/Jul/20/landscape-of-gen-ai-product-ux/#atom-everything](https://simonwillison.net/2024/Jul/20/landscape-of-gen-ai-product-ux/#atom-everything)
 - RSS feed: https://simonwillison.net/atom/everything
 - date published: 2024-07-20T04:40:42+00:00

<p><a href="https://interconnected.org/home/2024/07/19/ai-landscape">Mapping the landscape of gen-AI product user experience</a></p>
Matt Webb attempts to map out the different user experience approaches to building on top of generative AI. I like the way he categorizes these potential experiences:</p>
<blockquote>
<ul>
<li><strong>Tools</strong>. Users control AI to generate something.</li>
<li><strong>Copilots</strong>. The AI works alongside the user in an app in multiple ways.</li>
<li><strong>Agents</strong>. The AI has some autonomy over how it approaches a task.</li>
<li><strong>Chat</strong>. The user talks to the AI as a peer in real-time.</li>
</ul>
</blockquote>


    <p>Tags: <a href="https://simonwillison.net/tags/matt-webb">matt-webb</a>, <a href="https://simonwillison.net/tags/ux">ux</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a></p>

