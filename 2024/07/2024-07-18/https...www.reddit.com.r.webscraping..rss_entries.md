# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## Scraping protected websockets
 - [https://www.reddit.com/r/webscraping/comments/1e6onh6/scraping_protected_websockets](https://www.reddit.com/r/webscraping/comments/1e6onh6/scraping_protected_websockets)
 - RSS feed: https://www.reddit.com/r/webscraping/.rss
 - date published: 2024-07-18T22:56:37+00:00

<!-- SC_OFF --><div class="md"><p>Hi, </p> <p>I'm trying to webscrape 2 websockets that seem to be protected:</p> <p><strong>1. Dexscreener websocket</strong> (link: wss://io.dexscreener.com/dex/screener/pairs/h24/1?rankBy[key]=trendingScoreH6&amp;rankBy[order]=desc&amp;filters[chainIds][0]=solana)</p> <ul> <li><strong>This one is protected by Cloudflare</strong></li> <li>I've tried using python requests to connect directly to the websocket URI above, using the same request headers as Firefox / Chrome (including user agents, origin, etc), but I get HTTP 403. However, if I connect using Postman using the same request headers as Firefox / Chrome, it works.</li> <li>Does anyone know why?</li> </ul> <p><strong>2. PredictIt websocket</strong> (link: wss://hub.predictit.org/signalr/connect?transport=webSockets&amp;clientProtocol=1.5&amp;bearer=XXX&amp;connectionData=%5B%7B%22name%22%3A%22markethub%22%7D%5D&amp;tid=3)</p> <ul> <li>This doesn't seem protected by Cloudflare</li> <li>I've tried

## Usage of scraped data from official Audi Dealers (Europe)
 - [https://www.reddit.com/r/webscraping/comments/1e6ilzf/usage_of_scraped_data_from_official_audi_dealers](https://www.reddit.com/r/webscraping/comments/1e6ilzf/usage_of_scraped_data_from_official_audi_dealers)
 - RSS feed: https://www.reddit.com/r/webscraping/.rss
 - date published: 2024-07-18T18:39:02+00:00

<!-- SC_OFF --><div class="md"><p>I want to scrape data from <a href="http://audi.de">audi.de</a> (used cars), and use the data on my website not altered just want to have some used cars with official warranties from Audi that I could offer to my clients to import them to my country, I was wondering has anybody tried contacting audi, vw or any similar dealer to get their approval of using the data? Or maybe any insight you could give on this topic, I will be waiting for your answers, thank you! :) </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Kecas"> /u/Kecas </a> <br /> <span><a href="https://www.reddit.com/r/webscraping/comments/1e6ilzf/usage_of_scraped_data_from_official_audi_dealers/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1e6ilzf/usage_of_scraped_data_from_official_audi_dealers/">[comments]</a></span>

## Web scrapping tool needed
 - [https://www.reddit.com/r/webscraping/comments/1e6huw1/web_scrapping_tool_needed](https://www.reddit.com/r/webscraping/comments/1e6huw1/web_scrapping_tool_needed)
 - RSS feed: https://www.reddit.com/r/webscraping/.rss
 - date published: 2024-07-18T18:08:41+00:00

<!-- SC_OFF --><div class="md"><p>Hey, I tried searching in the group before. couldnt find what I need.</p> <p>I am looking for a web scraper tool that offers me the possibility to repeatedly scrape contact info from a website. There is a list of professionals on a page, where in order to access their info, you have to click on individual name, and then copy the data.</p> <p>So as I see it with my non-programming or whatever brain:<br /> General list page &gt; Specific profile page &gt; copy data &gt; go back &gt; repeat.</p> <p>So I want scraped to do something like this, and ideally then go to next page. So, one I already try, either cannot comprehend the specific profile page and take data from initial list, or fail to go back repeatedly or cannot do the next page clicking.</p> <p>Soo, any ideas?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Elxerxi"> /u/Elxerxi </a> <br /> <span><a href="https://www.reddit.com/r/webscraping/comments/1e6huw1

## nodriver ERR_HTTP2_PROTOCOL_ERROR when running headlessly
 - [https://www.reddit.com/r/webscraping/comments/1e6bdti/nodriver_err_http2_protocol_error_when_running](https://www.reddit.com/r/webscraping/comments/1e6bdti/nodriver_err_http2_protocol_error_when_running)
 - RSS feed: https://www.reddit.com/r/webscraping/.rss
 - date published: 2024-07-18T13:25:42+00:00

<!-- SC_OFF --><div class="md"><p>Hi all,</p> <p>I am playing around with a view to building something to check for ticket availability down the line. In an ideal world i'll use it in a headless way.</p> <p>I was up and running pretty sharpish with nodriver but when I use it headlessly, the site returns a ERR_HTTP2_PROTOCOL_ERROR. Headed, it runs fine.</p> <p>I assume I need to tinker with the header but am unclear what to change.</p> <p>Thanks</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/dav_man"> /u/dav_man </a> <br /> <span><a href="https://www.reddit.com/r/webscraping/comments/1e6bdti/nodriver_err_http2_protocol_error_when_running/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1e6bdti/nodriver_err_http2_protocol_error_when_running/">[comments]</a></span>

## How to scrape lazy loaded sites (Selenium doesn't work)?
 - [https://www.reddit.com/r/webscraping/comments/1e69td5/how_to_scrape_lazy_loaded_sites_selenium_doesnt](https://www.reddit.com/r/webscraping/comments/1e69td5/how_to_scrape_lazy_loaded_sites_selenium_doesnt)
 - RSS feed: https://www.reddit.com/r/webscraping/.rss
 - date published: 2024-07-18T12:09:17+00:00

<!-- SC_OFF --><div class="md"><p>I am trying to scrape this <a href="https://www.ounass.ae/men/designers/carhartt">site</a> but it seems to be lazy loaded. So I end up only being able to scrape the first displayed items. I tried to scroll with Selenium but still it doesn't work. Any leads?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Ayomne-435"> /u/Ayomne-435 </a> <br /> <span><a href="https://www.reddit.com/r/webscraping/comments/1e69td5/how_to_scrape_lazy_loaded_sites_selenium_doesnt/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1e69td5/how_to_scrape_lazy_loaded_sites_selenium_doesnt/">[comments]</a></span>

