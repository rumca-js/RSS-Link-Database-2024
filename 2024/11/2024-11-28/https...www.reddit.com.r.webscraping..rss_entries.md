# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## Suggest me a premade cookies collection script
 - [https://www.reddit.com/r/webscraping/comments/1h23j88/suggest_me_a_premade_cookies_collection_script](https://www.reddit.com/r/webscraping/comments/1h23j88/suggest_me_a_premade_cookies_collection_script)
 - RSS feed: $source
 - date published: 2024-11-28T19:18:57+00:00

<!-- SC_OFF --><div class="md"><p>Im in a situation where the website i try to automate and scrape detects me as a bot real quick even with many solutions implemented.</p> <p>The issue is i dont any cookies with the browser to mimic as a long term user or something.</p> <p>So I thought lets find out a script which radomly goes websites and play around for example liking you tube videos,playing it, and may be scrolling and everything.</p> <p>Any GitHub suggestions for a script like this? I could make one but i thought there could be pre made scripts for this, anyone please let me know if you have any idea, Thank you!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/LocalConversation850"> /u/LocalConversation850 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1h23j88/suggest_me_a_premade_cookies_collection_script/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1h23j88/suggest_me_a_prema

## Need help
 - [https://www.reddit.com/r/webscraping/comments/1h22o2k/need_help](https://www.reddit.com/r/webscraping/comments/1h22o2k/need_help)
 - RSS feed: $source
 - date published: 2024-11-28T18:40:04+00:00

<!-- SC_OFF --><div class="md"><p>New to programming don&#39;t like my bootcamp. So thought i&#39;d try something that interests me like bourbon. Use case trying to scrape a site to find out what is and isn&#39;t in stock over time. Here is what i have: </p> <pre><code>from bs4 import BeautifulSoup import requests def scrape_site(): try: # Fetch the webpage response = requests.get( &quot;https://www.buffalotracedistillery.com/visit-us/tasting-and-purchasing/product-availability.html&quot;) response.raise_for_status() # Raise HTTPError for bad responses (4xx and 5xx) # Parse the page content soup = BeautifulSoup(response.text, &quot;html.parser&quot;) whiskey_divs = soup.find_all(&#39;div&#39;, attrs={&#39;class&#39;: &#39;product-availability-text&#39;}) if not whiskey_divs: print(&quot;No whiskey availability information found.&quot;) return # Extract and print each whiskey&#39;s availability text for whiskey_div in whiskey_divs: print(whiskey_div.text.strip()) except requests.excep

## Easy Social Media Scraping Script [ X, Instagram, Tiktok, Youtube ]
 - [https://www.reddit.com/r/webscraping/comments/1h221ow/easy_social_media_scraping_script_x_instagram](https://www.reddit.com/r/webscraping/comments/1h221ow/easy_social_media_scraping_script_x_instagram)
 - RSS feed: $source
 - date published: 2024-11-28T18:11:49+00:00

<!-- SC_OFF --><div class="md"><p>Hi everyone,</p> <p>I’ve created a script for scraping public social media accounts for work purposes. I’ve wrapped it up, formatted it, and created a repository for anyone who wants to use it.</p> <p>It’s very simple to use, or you can easily copy the code and adapt it to suit your needs. Be sure to check out the README for more details!</p> <p>I’d love to hear your thoughts and any feedback you have.</p> <p>To summarize, the script uses Playwright for intercepting requests. For YouTube, it uses the API v3, which is easy to access with an API key.</p> <p><a href="https://github.com/luciomorocarnero/scraping_media">https://github.com/luciomorocarnero/scraping_media</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Lcrack753"> /u/Lcrack753 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1h221ow/easy_social_media_scraping_script_x_instagram/">[link]</a></span> &#32; <span><a href="https:/

## Scraped U.S. Phone numbers cell or landline?
 - [https://www.reddit.com/r/webscraping/comments/1h20646/scraped_us_phone_numbers_cell_or_landline](https://www.reddit.com/r/webscraping/comments/1h20646/scraped_us_phone_numbers_cell_or_landline)
 - RSS feed: $source
 - date published: 2024-11-28T16:48:52+00:00

<!-- SC_OFF --><div class="md"><p>I have 30k US phone numbers in a database I scrapped.</p> <p>Is there a way or program that works on US numbers that will tell me if they are cell numbers or landlines??</p> <p>Thanks in advance. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Flaky-Ad6625"> /u/Flaky-Ad6625 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1h20646/scraped_us_phone_numbers_cell_or_landline/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1h20646/scraped_us_phone_numbers_cell_or_landline/">[comments]</a></span>

## Where can i find telegram scraping tool
 - [https://www.reddit.com/r/webscraping/comments/1h1xqmz/where_can_i_find_telegram_scraping_tool](https://www.reddit.com/r/webscraping/comments/1h1xqmz/where_can_i_find_telegram_scraping_tool)
 - RSS feed: $source
 - date published: 2024-11-28T14:58:32+00:00

<!-- SC_OFF --><div class="md"><p>I want add members from one to another group</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/DisastrousClient9995"> /u/DisastrousClient9995 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1h1xqmz/where_can_i_find_telegram_scraping_tool/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1h1xqmz/where_can_i_find_telegram_scraping_tool/">[comments]</a></span>

## curl returns 200, nodejs client does not
 - [https://www.reddit.com/r/webscraping/comments/1h1wdsi/curl_returns_200_nodejs_client_does_not](https://www.reddit.com/r/webscraping/comments/1h1wdsi/curl_returns_200_nodejs_client_does_not)
 - RSS feed: $source
 - date published: 2024-11-28T13:51:15+00:00

<!-- SC_OFF --><div class="md"><p>Following request returns a <code>200</code> status code with the desired content</p> <p><code> curl -H &quot;User-agent: hello&quot; https://www.ah.nl/zoeken?query=b </code></p> <p>The very same request returns <code>403</code> with any Nodejs client that I have tried (e.g. native, fetch, got etc.)</p> <p><strong>Example</strong> <code> const result = await fetch(&quot;https://www.ah.nl/zoeken?query=b&quot;, { headers: { &quot;User-agent&quot;: &quot;hello&quot;, }, method: &quot;GET&quot;, }); </code></p> <p>I feel like I have tried a million different things, but I cannot get the Nodejs request to work</p> <p><strong>Can anybody help me out here?</strong></p> <p>PS: I need to set the <code>User-agent</code> to something in curl, because otherwise curl will set it with its own headers and that will cause the request to be rejected.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/amberlamps1"> /u/amberlamps1 </

## Should I keep building my own Scraper or use existing ones?
 - [https://www.reddit.com/r/webscraping/comments/1h1vauo/should_i_keep_building_my_own_scraper_or_use](https://www.reddit.com/r/webscraping/comments/1h1vauo/should_i_keep_building_my_own_scraper_or_use)
 - RSS feed: $source
 - date published: 2024-11-28T12:52:38+00:00

<!-- SC_OFF --><div class="md"><p>Hi everyone,</p> <p>So I have been building my own scraper with the use of puppeteer for a personal project and I recently saw a thread in this subreddit about scraper frameworks.</p> <p>Now I am kinda in a crossroad and I not sure if I should continue building my scraper and implement the missing things or grab one of these scrapers that exist while they are actively being maintained.</p> <p>What would you suggest?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Enigma_0001"> /u/Enigma_0001 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1h1vauo/should_i_keep_building_my_own_scraper_or_use/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1h1vauo/should_i_keep_building_my_own_scraper_or_use/">[comments]</a></span>

## Are there any Open source/self hosted captcha solvers?
 - [https://www.reddit.com/r/webscraping/comments/1h1umpm/are_there_any_open_sourceself_hosted_captcha](https://www.reddit.com/r/webscraping/comments/1h1umpm/are_there_any_open_sourceself_hosted_captcha)
 - RSS feed: $source
 - date published: 2024-11-28T12:12:26+00:00

<table> <tr><td> <a href="https://www.reddit.com/r/webscraping/comments/1h1umpm/are_there_any_open_sourceself_hosted_captcha/"> <img src="https://b.thumbs.redditmedia.com/ezd9llsqOGIvecKJMdWZ-rLl6suUuaJxynyvPwqK7GQ.jpg" alt="Are there any Open source/self hosted captcha solvers?" title="Are there any Open source/self hosted captcha solvers?" /> </a> </td><td> <!-- SC_OFF --><div class="md"><p>I need a solution to solve simple captchas like this. What is the best open source/ free way to do it.</p> <p>A good github project would be fine.</p> <p><a href="https://preview.redd.it/r9y7wqdlvm3e1.jpg?width=190&amp;format=pjpg&amp;auto=webp&amp;s=555c1adc0514620b3312b89d1e4c0e6b6f3fd147">https://preview.redd.it/r9y7wqdlvm3e1.jpg?width=190&amp;format=pjpg&amp;auto=webp&amp;s=555c1adc0514620b3312b89d1e4c0e6b6f3fd147</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/BakedNietzsche"> /u/BakedNietzsche </a> <br/> <span><a href="https://www.reddit.com/r/web

## Scraping Easyjet using fetch api method
 - [https://www.reddit.com/r/webscraping/comments/1h1p9k5/scraping_easyjet_using_fetch_api_method](https://www.reddit.com/r/webscraping/comments/1h1p9k5/scraping_easyjet_using_fetch_api_method)
 - RSS feed: $source
 - date published: 2024-11-28T05:56:12+00:00

<!-- SC_OFF --><div class="md"><p>Hi, all. </p> <p>I want to scrape this website: <a href="https://www.easyjet.com/en/">https://www.easyjet.com/en/</a></p> <p>I am trying to collect the flight details based on the inputs. departure, arrival, departure and arrival date. There is a fetch Api for this which is showing after you click &quot;show flights&quot; button. But the api is not working in postman or in my local as it is just showing timeout error during request python as it never stop. I think I have to give some updated variable value in the header then only this might work but I have no idea how to do this</p> <p>I was trying to use playwright, but I want to try this Api method as it is fast</p> <p>Please suggest some idea or help to resolve this. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Minimum-Earth9509"> /u/Minimum-Earth9509 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1h1p9k5/scraping_easyjet_using_fe

