[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_published": "2024-11-25T20:04:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>We are looking to hire a freelancer for some projects that require playwright based browser automation and python sessions based automation. It would involve automating complex tasks such as authentication, payments etc.</p> <p>Experience with handling Cloudflare sites and having used Botasaurus would be a bonus. Please DM me in case you are interested and require more details.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/piyushnh\"> /u/piyushnh </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1gzscfp/hiring_python_developer_with_playwright_and/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1gzscfp/hiring_python_developer_with_playwright_and/\">[comments]</a></span>",
        "id": 1584023,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1gzscfp/hiring_python_developer_with_playwright_and",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Hiring: Python developer with Playwright and Botasaurus Experience",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_published": "2024-11-25T18:48:25+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, does anybody know an effective way of scraping data from SEC def14a filings using the edgar API? I haven&#39;t had much success. I want to scrape executive compensation from various filings. Thanks.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/rezidual_\"> /u/rezidual_ </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1gzqgf6/scraping_data_from_def_14a_filings/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1gzqgf6/scraping_data_from_def_14a_filings/\">[comments]</a></span>",
        "id": 1584024,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1gzqgf6/scraping_data_from_def_14a_filings",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping data from DEF 14A filings",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_published": "2024-11-25T18:16:47+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1gzpndu/scraping_realtorcom_estimates/\"> <img src=\"https://external-preview.redd.it/CR1o82xuTOQcWCO3w3nKo-rXG2xgTRKyAn-ki4hrUvI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b6f9dd51064ad082e8489a1350f0fd15415bee9c\" alt=\"Scraping Realtor.com Estimates\" title=\"Scraping Realtor.com Estimates\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hi all, I&#39;ve been beating my head against a wall on this problem. I&#39;ve built a wicked fast python scraper that can find properties based on city and state queries. Fantastic! Now I want to get the data for the charts in the screenshot below: </p> <p><a href=\"https://preview.redd.it/5rf3ekbk933e1.png?width=1902&amp;format=png&amp;auto=webp&amp;s=8eec223d25d56aab0dfd89f072d178959624ae7d\">https://preview.redd.it/5rf3ekbk933e1.png?width=1902&amp;format=png&amp;auto=webp&amp;s=8eec223d25d56aab0dfd89f072d178959624ae7d</a></p> <p>I added a screenshot for the data I want. ",
        "id": 1584909,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1gzpndu/scraping_realtorcom_estimates",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/CR1o82xuTOQcWCO3w3nKo-rXG2xgTRKyAn-ki4hrUvI.jpg?width=640&crop=smart&auto=webp&s=b6f9dd51064ad082e8489a1350f0fd15415bee9c",
        "title": "Scraping Realtor.com Estimates",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_published": "2024-11-25T15:01:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Welcome to the weekly discussion thread! Whether you&#39;re a seasoned web scraper or just starting out, this is the perfect place to discuss topics that might not warrant a dedicated post, such as:</p> <ul> <li>Techniques for extracting data from popular sites like LinkedIn, Facebook, etc.</li> <li>Industry news, trends, and insights on the web scraping job market</li> <li>Challenges and strategies in marketing and monetizing your scraping projects</li> </ul> <p>Like our monthly <a href=\"https://reddit.com/r/webscraping/about/sticky?num=1\">self-promotion</a> thread, mentions of paid services and tools are permitted \ud83e\udd1d. If you&#39;re new to web scraping, be sure to check out the <a href=\"https://webscraping.fyi\">beginners guide</a> \ud83c\udf31</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AutoModerator\"> /u/AutoModerator </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1gzksia/weekly_discussion_25_",
        "id": 1582290,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1gzksia/weekly_discussion_25_nov_2024",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Weekly Discussion - 25 Nov 2024",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_published": "2024-11-25T13:35:49+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey,</p> <p>I would like to create a statistic, which shows that certain skills are commonly required for certain job types. For that I would like to make use of Indeed&#39;s jobs, but sadly they introduced some heavy bot protection recently. I&#39;m unable to get past it.</p> <p>I tried to use Playwright with the puppeteer-extra-plugin-stealth plugin, but without luck. Anyone got an idea on how to get some data from them?</p> <pre><code>import { chromium } from &quot;playwright-extra&quot;; import StealthPlugin from &quot;puppeteer-extra-plugin-stealth&quot;; chromium .use(StealthPlugin()) .launch({ headless: true }) .then(async (browser) =&gt; { const page = await browser.newPage(); await page.goto(&quot;https://indeed.com/jobs&quot;); await page.waitForTimeout(5000); await page.screenshot({ path: &quot;stealth.png&quot;, fullPage: true }); await browser.close(); }); </code></pre> <p>I&#39;m also failing the challenge at <a href=\"https://arh.antoin",
        "id": 1581866,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1gziydl/scraping_jobs_from_indeed",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping jobs from Indeed",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_published": "2024-11-25T08:42:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Im working on a smaller scale and will be looking to scrape 100-1000 search results per day. Just the first ~5 or so links per search. What search engine do I go for scraping? Which wouldnt require a proxy or a VPN.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/CaptTechno\"> /u/CaptTechno </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1gzega8/the_most_scrapable_search_engine/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1gzega8/the_most_scrapable_search_engine/\">[comments]</a></span>",
        "id": 1580446,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1gzega8/the_most_scrapable_search_engine",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "The most scrapable search engine?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_published": "2024-11-25T05:29:29+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am trying to search the content of all of the profiles on a matrimonial website. It&#39;s an extremely basic website and there&#39;s not search function. </p> <p>I&#39;m trying to find the best way to get all of the profiles (maybe two to three thousand) into a searchable form. I was wondering if there is any tool that I could use so that when I click a profile instead of opening a new tab, it just downloads the html to a folder for me. Once I click on all of the links, then I would just search the folder for keywords.</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/semaf0r0\"> /u/semaf0r0 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1gzbniz/is_there_a_tool_for_downloading_plaintext_file_of/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1gzbniz/is_there_a_tool_for_downloading_plaintext_file_of/\">[comments]</a></span>",
        "id": 1579737,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1gzbniz/is_there_a_tool_for_downloading_plaintext_file_of",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is there a tool for downloading plaintext file of a web page?",
        "vote": 0
    }
]