[{"age": null, "album": "", "author": null, "bookmarked": false, "comments": [], "date_published": "2024-11-21T20:55:23+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey!</p> <p>I have a lot of experiences doing webscrappers. However, there&#39;s some websites that don&#39;t really expose an API on the network tab. Sometimes, all I can see is the doc type, with all the data loaded in the HTML.</p> <p>This is a major blocker, because then I have to parse an HTML. So I was wondering... Does anyone knows other ways to find the API calls being made for this doc? Maybe by finding the JS that makes the call somewhere else?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/SearchinglyWonderful\"> /u/SearchinglyWonderful </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1gwq239/scrape_underlying_api_through_a_doc/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1gwq239/scrape_underlying_api_through_a_doc/\">[comments]</a></span>", "id": 1561957, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1gwq239/scrape_underlying_api_through_a_doc", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Scrape underlying API through a Doc", "vote": 0}, {"age": null, "album": "", "author": null, "bookmarked": false, "comments": [], "date_published": "2024-11-21T17:25:21+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello. Good day everyone.</p> <p>I am trying to reverse engineer a major website&#39;s API using pure HTTP requests. I chose Python&#39;s requests module as my go-to technology to work with because I&#39;m familiar with Python. But I am wondering how good is Python&#39;s requests at being undetected and mimicking a browser..? If it&#39;s a no go, could you maybe suggest a technology that is light on bandwidth, uses only HTTP requests without loading a browser&#39;s driver, and stealthy.</p> <p>Thanks</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/_iamhamza_\"> /u/_iamhamza_ </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1gwks5g/how_good_is_pythons_requests_at_being_undetected/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1gwks5g/how_good_is_pythons_requests_at_being_undetected/\">[comments]</a></span>", "id": 1560069, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1gwks5g/how_good_is_pythons_requests_at_being_undetected", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "How good is Python's requests at being undetected?", "vote": 0}, {"age": null, "album": "", "author": null, "bookmarked": false, "comments": [], "date_published": "2024-11-21T14:17:45+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>In Switzerland we have two monopoly supermarkets and it sucks (Migros and COOP) and other cheaper supermarket brands (ALDI, LIDL for example) that are trying to enter the market but with difficulty. I&#39;m trying to build a project to compare the product prices of common goods of these mastodons with the concurrence to make the price difference transparent for the public.</p> <p>It was easy to webscrap the first site of migros (<a href=\"https://www.migros.ch/\">https://www.migros.ch/</a>), but with the second one, (<a href=\"https://www.coop.ch/\">https://www.coop.ch/</a>), I&#39;m facing a captcha blocker that I can&#39;t overcome... Is there anyone who has already implemented a good and possibly free solution for this problem ? I&#39;ve already tried with &quot;playwright_stealth&quot; but without success. Thanks for your help.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Maleficent-Leader-22\"> /u/Maleficent-", "id": 1561958, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1gwhb71/webscraping_coopch_with_captcha_issue", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Webscraping \"coop.ch\" with Captcha (issue)", "vote": 0}, {"age": null, "album": "", "author": null, "bookmarked": false, "comments": [], "date_published": "2024-11-21T13:40:49+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello everyone</p> <p>Im relatively new to this scraping world and i wanted to know 2 things mainly:</p> <p>- What is the best option to scrape +500 urls including ones with javascript ? (Actually Im using a combination of node + puppeteer and python + BeautifulSoup)</p> <p>- Would be possible and realistic to have a raspberry pi scraping all that websites ( I dont know if it will be too slow or maybe not powerful enough)</p> <p>Thank you very much :))</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/InternationalOwl8131\"> /u/InternationalOwl8131 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1gwgir6/scraping_advise/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1gwgir6/scraping_advise/\">[comments]</a></span>", "id": 1559066, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1gwgir6/scraping_advise", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Scraping advise", "vote": 0}, {"age": null, "album": "", "author": null, "bookmarked": false, "comments": [], "date_published": "2024-11-21T08:58:19+00:00", "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1gwbzkf/trying_to_detect_a_change_on_the_sample_page_in/\"> <img src=\"https://external-preview.redd.it/msO1Nh31YZYg_yu7fxxOjzYlPGS5OMYHCfDX8pml19Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1aec23f7ebba09e75d78ab5e01400e5901d0be5a\" alt=\"Trying to detect a change on the sample page in the popup window\" title=\"Trying to detect a change on the sample page in the popup window\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Is it possible to get to the popup window via a scraper on a website of this type? For example: <a href=\"https://www.euro.com.pl/lodowki-do-zabudowy/siemens-ki42l2fe1-iq100.bhtml\">https://www.euro.com.pl/lodowki-do-zabudowy/siemens-ki42l2fe1-iq100.bhtml</a></p> <p>After clicking on Status: good, a new window opens with which you can interact. I&#39;m currently using changedetection.io. Is this the right tool or should I use something else?</p> <p><a href=\"https://preview.redd.it/bru6iz4iy", "id": 1556743, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1gwbzkf/trying_to_detect_a_change_on_the_sample_page_in", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 86, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": "https://external-preview.redd.it/msO1Nh31YZYg_yu7fxxOjzYlPGS5OMYHCfDX8pml19Y.jpg?width=320&crop=smart&auto=webp&s=1aec23f7ebba09e75d78ab5e01400e5901d0be5a", "title": "Trying to detect a change on the sample page in the popup window", "vote": 0}, {"age": null, "album": "", "author": null, "bookmarked": false, "comments": [], "date_published": "2024-11-21T08:12:29+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey guys,</p> <p>I\u2019m trying to scrape data from BizBuySell, but I keep running into issues. Here\u2019s what I\u2019ve tried so far:</p> <ol> <li>Used rotating proxies with the <code>curl_cffi</code> library, but it keeps failing with cURL errors most of the time.</li> <li>Tried Selenium with a browser and proxies, but I\u2019m getting similar errors.</li> </ol> <p>Here\u2019s the sample URL I\u2019m working with:<br/> <a href=\"https://www.bizbuysell.com/Business-Opportunity/pizza-place-established-profitable-next-door-to-wal-mart/2285377/\">https://www.bizbuysell.com/Business-Opportunity/pizza-place-established-profitable-next-door-to-wal-mart/2285377</a></p> <p>Has anyone here had success with scraping this site? Any tips or advice would be super helpful. Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Alarming-Lawfulness1\"> /u/Alarming-Lawfulness1 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1gwbe1x/", "id": 1557370, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1gwbe1x/need_help_scraping_bizbuysell", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Need help scraping BizBuySell", "vote": 0}, {"age": null, "album": "", "author": null, "bookmarked": false, "comments": [], "date_published": "2024-11-21T03:10:00+00:00", "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1gw6fbw/i_built_a_search_engine_specifically_for_ai_tools/\"> <img src=\"https://external-preview.redd.it/ZmdiemY5MW04NjJlMZJaBWUXqr4NaHc-CNvKnlBmCGB1RJKmQQ3YIXloIL4k.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8c60196e9a06560991569603e99818c77572cfe4\" alt=\"I built a search engine specifically for AI tools and projects. It's free, but I don't know why I'm posting this to **webscraping** \ud83e\udd2b\" title=\"I built a search engine specifically for AI tools and projects. It's free, but I don't know why I'm posting this to **webscraping** \ud83e\udd2b\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/dhj9817\"> /u/dhj9817 </a> <br/> <span><a href=\"https://v.redd.it/wuuyq91m862e1\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1gw6fbw/i_built_a_search_engine_specifically_for_ai_tools/\">[comments]</a></span> </td></tr></table>", "id": 1555703, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1gw6fbw/i_built_a_search_engine_specifically_for_ai_tools", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 86, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": "https://external-preview.redd.it/ZmdiemY5MW04NjJlMZJaBWUXqr4NaHc-CNvKnlBmCGB1RJKmQQ3YIXloIL4k.png?width=640&crop=smart&auto=webp&s=8c60196e9a06560991569603e99818c77572cfe4", "title": "I built a search engine specifically for AI tools and projects. It's free, but I don't know why I'm posting this to **webscraping** \ud83e\udd2b", "vote": 0}, {"age": null, "album": "", "author": null, "bookmarked": false, "comments": [], "date_published": "2024-11-21T02:58:56+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Context: page is been shutting down <a href=\"https://www.reddit.com/r/webscraping/comments/1gl2uik/old_and_obscure_manga_hosting_site_is_shutting/\">https://www.reddit.com/r/webscraping/comments/1gl2uik/old_and_obscure_manga_hosting_site_is_shutting/</a></p> <p>This project will help to make a backup of the data<br/> You need to have Golang <a href=\"https://go.dev/dl/\">https://go.dev/dl/</a><br/> and jsut run the project </p> <p><a href=\"https://github.com/johnbalvin/mangaz\">https://github.com/johnbalvin/mangaz</a></p> <p>Data will be saved into two folders, one for the images and the other one for the meatadata,<br/> Send me a dm in case you need help running the project, I&#39;ll be helping for free</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/JohnBalvin\"> /u/JohnBalvin </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1gw67cu/mangaz_web_scraper_made_in_go/\">[link]</a></span> &#32; <spa", "id": 1555489, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1gw67cu/mangaz_web_scraper_made_in_go", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "mangaz web scraper made in Go", "vote": 0}, {"age": null, "album": "", "author": null, "bookmarked": false, "comments": [], "date_published": "2024-11-21T01:08:14+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Need to collect small amount of data, just a couple thousands requests, so don&#39;t need proxy, IP, multiple instances etc. Just a very slow single instance, doing 1 req every 5 sec or so, slowly doing the job in a couple of days.</p> <p>But the `puppeteer-extra-plugin-stealth` doesn&#39;t work (it&#39;s immediately detected as bot and blocked by site). Wonder if there&#39;s simple tool that is: <strong>stealth</strong> and also has <strong>file download</strong> and <strong>request interception</strong> support? Ideally JS/TS, not Python.</p> <p>P.S.</p> <p>Also, I just wonder if there&#39;s any way to use the real Chrome/Firefox browser directly? Like maybe as a Plugin by injecting JS into page that would control it and clearing cookie and all the other data every 10 requests + node.js proxy to use for request introspection? Or something like that.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/h234sd\"> /u/h", "id": 1555230, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1gw3vth/100_stealth_for_small_scale", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "100% Stealth for Small Scale?", "vote": 0}]