[{"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-11-19T21:25:28+00:00", "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1gv8fd8/i_scraped_50000_remote_jobs_into_a_googlesheet/\"> <img src=\"https://external-preview.redd.it/--VqND4HOOPxHyFKFKmJA1VHOLnp8MtZIsTZfTj_26k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f59cad34067f02ee6d2470e76bbc96d9b6b230fa\" alt=\"I scraped 50,000+ remote jobs into a googlesheet - it's free. you're welcome. upvote so everyone sees it &lt;3\" title=\"I scraped 50,000+ remote jobs into a googlesheet - it's free. you're welcome. upvote so everyone sees it &lt;3\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/marvythemantis\"> /u/marvythemantis </a> <br/> <span><a href=\"https://docs.google.com/spreadsheets/d/1uHZQuAFMBOvGLBtJdZA-GXzNk_Ug3EgBgCk7d1Vbrg8/edit?usp=sharing\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1gv8fd8/i_scraped_50000_remote_jobs_into_a_googlesheet/\">[comments]</a></span> </td></tr></table>", "id": 1546595, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1gv8fd8/i_scraped_50000_remote_jobs_into_a_googlesheet", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 86, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": "https://external-preview.redd.it/--VqND4HOOPxHyFKFKmJA1VHOLnp8MtZIsTZfTj_26k.jpg?width=640&crop=smart&auto=webp&s=f59cad34067f02ee6d2470e76bbc96d9b6b230fa", "title": "I scraped 50,000+ remote jobs into a googlesheet - it's free. you're welcome. upvote so everyone sees it <3", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-11-19T18:09:02+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m new to web scraping and currently working on a reinforcement learning project aimed at predicting outcomes using PGA Tour data. My plan is to collect stats for players over multiple seasons, but I\u2019m running into some issues.<br/> I wrote the following script using <strong>Selenium</strong> to scrape player stats from the PGA Tour website. It seems to work fine when scraping data for a single player or a small gorup when I try to include multiple players in runs into problems.<br/> The script fails to load the dropdown, select the season, or retrieve the table data, which makes it unreliable for large datasets.<br/> Heres the script ive been working on. </p> <pre><code>from selenium import webdriver from selenium.webdriver.common.by import By from selenium.webdriver.support.ui import WebDriverWait from selenium.webdriver.support import expected_conditions as EC import pandas as pd import time driver = webdriver.Chrome() driver.set_window_size(1920", "id": 1546248, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1gv3ov2/scraping_pga_tour_data", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Scraping PGA Tour Data", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-11-19T16:35:44+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Anyone know of a chrome extension or python script that reliably solves HCaptcha for completely free?</p> <p>The site I am scraping has a custom button that, once clicked, a pop up HCaptcha appears. The HCaptcha is configured at the hardest difficulty it seems, and requires two puzzles each time to pass. </p> <p>In Python, I made a script that uses Pixtral VLM API to: - Skip puzzles until you get one of those 3x3 puzzles (because you can simply click or not click the images rather than click on a certain coordinate) - Determine what\u2019s in the reference image - goes through each of the 9 images and determines if they are the same as the reference / solve the prompt. </p> <p>Even with pre-processing the image to minimize the effect of the pattern overlay on the challenge image, I\u2019m only solving them about 10% of the time. Even then, it takes it like 2 minutes per solve. </p> <p>Also, I\u2019ve tried rotating residential proxies, user agents, timeouts, etc. t", "id": 1544845, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1gv1dpt/hcaptcha_bypass_effective_and_free", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "HCaptcha bypass? (Effective and free)", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-11-19T15:13:15+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m working on a web scraping project using a residential proxy pool and python requests. While I can successfully scrape a few hundred API URLs, I start getting RemoteDisconnected errors on subsequent requests. I\u2019ve verified that I\u2019m getting unique IPs with every request, so that\u2019s not the issue. I&#39;ve tried multiple proxy providers and am running into the same issue. </p> <p>I suspect the target website might be detecting that all proxies are from the same provider, even though the IPs are different, and they&#39;re blocking everything. I\u2019ve tried implementing delays and rotating user agents, but still running into issues.</p> <p>Has anyone dealt with this before? Are there specific proxy services or configurations that work better for avoiding detection? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/for_dinnerz\"> /u/for_dinnerz </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1guz", "id": 1544326, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1guzeki/target_website_detecting_that_proxies_are", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Target website detecting that proxies are originating from same place", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-11-19T05:07:19+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I was wondering what tools are being used for you guys. I\u2019m currently using apollo.io. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/FontesB\"> /u/FontesB </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1gupnw6/do_you_use_data_enrichment_and_your_strategies/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1gupnw6/do_you_use_data_enrichment_and_your_strategies/\">[comments]</a></span>", "id": 1540906, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1gupnw6/do_you_use_data_enrichment_and_your_strategies", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Do you use data enrichment and your strategies?", "vote": 0}]