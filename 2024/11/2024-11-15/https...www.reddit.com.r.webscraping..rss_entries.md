# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## Looking to make a AI webscaper
 - [https://www.reddit.com/r/webscraping/comments/1gs7df2/looking_to_make_a_ai_webscaper](https://www.reddit.com/r/webscraping/comments/1gs7df2/looking_to_make_a_ai_webscaper)
 - RSS feed: $source
 - date published: 2024-11-15T21:35:04+00:00

<!-- SC_OFF --><div class="md"><p>So im looking to create a software that can scrape leads for me. Only issue is on page 13 i get stopped by captcha. Does anyone know how to get around that?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Big-Water8493"> /u/Big-Water8493 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1gs7df2/looking_to_make_a_ai_webscaper/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1gs7df2/looking_to_make_a_ai_webscaper/">[comments]</a></span>

## Yahoo Finance webscraping Help
 - [https://www.reddit.com/r/webscraping/comments/1gs5zjp/yahoo_finance_webscraping_help](https://www.reddit.com/r/webscraping/comments/1gs5zjp/yahoo_finance_webscraping_help)
 - RSS feed: $source
 - date published: 2024-11-15T20:33:56+00:00

<table> <tr><td> <a href="https://www.reddit.com/r/webscraping/comments/1gs5zjp/yahoo_finance_webscraping_help/"> <img src="https://b.thumbs.redditmedia.com/JxXaHS7Iu_2MB9v9a2KKouE24FJsWEJBRO0YOslLo5w.jpg" alt="Yahoo Finance webscraping Help" title="Yahoo Finance webscraping Help" /> </a> </td><td> <!-- SC_OFF --><div class="md"><p>Hi everyone! I&#39;m currently working on making a function that webscrapes data from Yahoo Finance. I&#39;m pretty new to webscraping so I&#39;m not sure how to deal with the problem I am having and any help is appreciated! Here&#39;s a screenshot of my code: </p> <p><a href="https://preview.redd.it/dievuob4l41e1.png?width=1035&amp;format=png&amp;auto=webp&amp;s=7b0f8aab7ce6799e436675b4ee95d272d769a395">https://preview.redd.it/dievuob4l41e1.png?width=1035&amp;format=png&amp;auto=webp&amp;s=7b0f8aab7ce6799e436675b4ee95d272d769a395</a></p> <p><a href="https://preview.redd.it/ngnwwphil41e1.png?width=1059&amp;format=png&amp;auto=webp&amp;s=cf91d2aa7f1138a5348

## Anyone try Anthropic's Computer Use to Scrape?
 - [https://www.reddit.com/r/webscraping/comments/1grzxw9/anyone_try_anthropics_computer_use_to_scrape](https://www.reddit.com/r/webscraping/comments/1grzxw9/anyone_try_anthropics_computer_use_to_scrape)
 - RSS feed: $source
 - date published: 2024-11-15T16:15:15+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;ve tired it and it&#39;s buggy but I see the potential:</p> <p>- Demo: <a href="https://www.youtube.com/watch?v=ODaHJzOyVCQ">https://www.youtube.com/watch?v=ODaHJzOyVCQ</a></p> <p>- Docs: <a href="https://docs.anthropic.com/en/docs/build-with-claude/computer-use">https://docs.anthropic.com/en/docs/build-with-claude/computer-use</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/yellowgolfball"> /u/yellowgolfball </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1grzxw9/anyone_try_anthropics_computer_use_to_scrape/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1grzxw9/anyone_try_anthropics_computer_use_to_scrape/">[comments]</a></span>

## URL path manipulation?
 - [https://www.reddit.com/r/webscraping/comments/1grxpwy/url_path_manipulation](https://www.reddit.com/r/webscraping/comments/1grxpwy/url_path_manipulation)
 - RSS feed: $source
 - date published: 2024-11-15T14:36:01+00:00

<!-- SC_OFF --><div class="md"><p>Hi! Apologies in advance since I am new to this. </p> <p>I need help to understand if I can actually do something like the title. So basically, I know a few variables/parameters of the ticketing website, like event location, event id, event name. I want to manipulate the URL path in order to bypass the redirect of the website and to bypass the queue.</p> <p>For example: </p> <p>when I access ticket.com/event, this goes to a queue. i want to change the URL to ticket.com/event?name=value&amp;location=value etc or something in order to force it to stop redirecting.</p> <p>Is it possible?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/iliveformyships"> /u/iliveformyships </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1grxpwy/url_path_manipulation/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1grxpwy/url_path_manipulation/">[comments]</a></span>

## Best way to scrape and classify data about products/services
 - [https://www.reddit.com/r/webscraping/comments/1grvryu/best_way_to_scrape_and_classify_data_about](https://www.reddit.com/r/webscraping/comments/1grvryu/best_way_to_scrape_and_classify_data_about)
 - RSS feed: $source
 - date published: 2024-11-15T12:58:34+00:00

<!-- SC_OFF --><div class="md"><p>Hey folks,</p> <p>I am building a tool where the user can put any product or service webpage URL and I plan to give the user a JSON response which will contain things like headlines, subheadlines, emotions, offers, value props, images etc from the landing page. </p> <p>I also need this tool to intelligently follow any links related to that specific product present on the page.</p> <p>I realise it will take scraping and LLM calls to do this. Which tool can I use which won’t miss information and can scrape reliably? </p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/kool9890"> /u/kool9890 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1grvryu/best_way_to_scrape_and_classify_data_about/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1grvryu/best_way_to_scrape_and_classify_data_about/">[comments]</a></span>

## Would use of proxies be mandatory here?
 - [https://www.reddit.com/r/webscraping/comments/1grqjfs/would_use_of_proxies_be_mandatory_here](https://www.reddit.com/r/webscraping/comments/1grqjfs/would_use_of_proxies_be_mandatory_here)
 - RSS feed: $source
 - date published: 2024-11-15T06:50:51+00:00

<!-- SC_OFF --><div class="md"><p>I’m fairly new to webscraping so I apologize in advance if this is a dumb question.</p> <p>For a project I’m working on, I need to be able to scrape thousands of eBay sold listings (there is no api that suits my needs, I checked pretty extensively as that would’ve been the ideal option)</p> <p>If I make a request once every 10 seconds but have my program running 24/7, I would be able to access a little under 10,000 pages per 24hr</p> <p>Since I’m spacing out my requests 10 seconds apart, would that still need the use of proxies? I’m trying to minimize my use of proxies to help save on cost</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/DogtorPepper"> /u/DogtorPepper </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1grqjfs/would_use_of_proxies_be_mandatory_here/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1grqjfs/would_use_of_proxies_be_mandatory_h

## Simply looking to screenshot browser errors (bad ssl etc) with Selenium
 - [https://www.reddit.com/r/webscraping/comments/1groca1/simply_looking_to_screenshot_browser_errors_bad](https://www.reddit.com/r/webscraping/comments/1groca1/simply_looking_to_screenshot_browser_errors_bad)
 - RSS feed: $source
 - date published: 2024-11-15T04:32:11+00:00

<!-- SC_OFF --><div class="md"><p>Hello. This might be an odd use case, but I want to use Python-Selenium to screenshot browser SSL errors in Chrome and FF. </p> <p>For example the browser-generated text page `Your connection is not private...net::ERR_CERT_DATE_INVALID` you would see if you opened <a href="https://expired.badssl.com/">https://expired.badssl.com/</a><br/> I want to screenshot THAT.</p> <p>Just to explain more: I understand that browser-generated errors (such as those for SSL issues) are not really pages, and they originate from the browser UI layer not the page renderer. The browser UI layer would only be accessible if you disabled Headless mode (in Headless, errors render as a white/blank image). I remember all this, but not any special Options that needed to be given when creating the driver object. A couple of years ago I got this working, but it was brutal web searching to find an example due to the commonality of the terms.</p> </div><!-- SC_ON --> &#32; submitte

## Can I webscrape a clothing company to check price drop of item, how ?
 - [https://www.reddit.com/r/webscraping/comments/1grmetw/can_i_webscrape_a_clothing_company_to_check_price](https://www.reddit.com/r/webscraping/comments/1grmetw/can_i_webscrape_a_clothing_company_to_check_price)
 - RSS feed: $source
 - date published: 2024-11-15T02:45:45+00:00

<!-- SC_OFF --><div class="md"><p>If i can, and I manage to do it, I want to be able to do it for other websites as well to see some clothes price drops cause the prices now are horrendous.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/_snapdowncity"> /u/_snapdowncity </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1grmetw/can_i_webscrape_a_clothing_company_to_check_price/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1grmetw/can_i_webscrape_a_clothing_company_to_check_price/">[comments]</a></span>

## Scrape insta follower count without logging in using *.csv url list
 - [https://www.reddit.com/r/webscraping/comments/1grkqs0/scrape_insta_follower_count_without_logging_in](https://www.reddit.com/r/webscraping/comments/1grkqs0/scrape_insta_follower_count_without_logging_in)
 - RSS feed: $source
 - date published: 2024-11-15T01:19:06+00:00

<!-- SC_OFF --><div class="md"><p>Hi there,</p> <p>Laughably perhaps I&#39;ve been using chatgpt in an attempt to run this. </p> <p>Sadly, i&#39;ve hit a brick wall. I have a list of profiles whose follower counts i&#39;d like to track over time - the list is rather lengthy. Given the number, chatgpt suggested rotating proxies (and you can likely tell by the way i refer to them how out of my depth I am), using mars proxies. </p> <p>In any case, all the attempts that it has suggested have failed thus far. </p> <p>Has anyone had any success with something similar?</p> <p>Appreciate your time and any advice.</p> <p>Thanks.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/MintPolo"> /u/MintPolo </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1grkqs0/scrape_insta_follower_count_without_logging_in/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1grkqs0/scrape_insta_follower_count_without_lo

## Scraping US postage costs from eBay from a UK-based computer.
 - [https://www.reddit.com/r/webscraping/comments/1grk6ba/scraping_us_postage_costs_from_ebay_from_a](https://www.reddit.com/r/webscraping/comments/1grk6ba/scraping_us_postage_costs_from_ebay_from_a)
 - RSS feed: $source
 - date published: 2024-11-15T00:50:30+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;ve got a website for finding deals on Pokemon cards on eBay.</p> <p>I scrape the listings by loading the results page for each set (e.g. for fusion strike it searches &#39;pokemon tcg fusion strike&#39;) and then saving all the results that match my criteria.</p> <p>I find that the postage costs for US listings always show as the cost for UK international shipping, no matter what I do.</p> <p>I&#39;ve tried a paid proxy, both datacenter and static residential, but it still gives me international postage prices.</p> <p>If I load the pages in my own browser in a private window while my proxy is enabled, it&#39;ll show the US postage prices in my browser, but the scraper is still getting the UK postage prices.</p> <p>I&#39;ve tried using the same headers that my browser is sending, but it still gives US postage prices.</p> <p>Any advice would be appreciated. Thanks.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/

