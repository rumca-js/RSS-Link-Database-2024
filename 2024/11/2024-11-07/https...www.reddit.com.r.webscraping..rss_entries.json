[{"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-11-07T22:39:55+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey all,</p> <p>I am new to webscraping, not new to webdev. I have been trying to complete a project to replicate a google flights price checker for a specific airlines website. I have slowly worked my way through various anti-scraping measures they have put in place, using puppeteer with a simulated real browser package and a bunch of http interception / masking configs, stealth plugins, residential proxies, and trying to mimic human behavior for all of my parameters on inputs. </p> <p>As of now, I can search a flight successfully from the homepage about 50% of the time without getting errored out due to bot detection. I am trying to figure out if I can get this to be consistent and was looking for insight on common detection methods they use or if anybody has advice on tools to aid me in this project.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AStanfordRunner\"> /u/AStanfordRunner </a> <br/> <span><a href=", "id": 1474729, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1gm3bn7/advice_for_scraping_from_airline_sites", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Advice for scraping from airline sites", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-11-07T22:37:59+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey all,</p> <p>I am new to webscraping, not new to webdev. I have been trying to complete a project to replicate a google flights price checker for a specific airlines website. I have slowly worked my way through various anti-scraping measures they have put in place, using puppeteer with a simulated real browser package and a bunch of http interception / masking configs, stealth plugins, residential proxies, and trying to mimic human behavior for all of my parameters on inputs. </p> <p>As of now, I can search a flight successfully from the homepage about 50% of the time without getting errored out due to bot detection. I am trying to figure out if I can get this to be consistent and was looking for insight on common detection methods they use or if anybody has advice on tools to aid me in this project.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Many-General2688\"> /u/Many-General2688 </a> <br/> <span><a hre", "id": 1474730, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1gm3a3p/advice_for_web_scraping_airline_sites", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Advice for web scraping airline sites", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-11-07T21:02:58+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello Redditors! It\u2019s Marcos.</p> <p>I\u2019m thrilled to introduce <a href=\"https://airtop.ai\">Airtop</a>, an AI-powered browser controlled by an API that is designed to automate web tasks at scale. Perfect for teams building AI agents that need to interact with websites requiring authentication like MFA or have human-in-the-loop scenarios. Airtop simplifies the process of navigating and controlling sites using natural language commands.</p> <p><strong>Key Features:</strong></p> <ul> <li><strong>Web Automation for AI:</strong> Control any website, scrape data, or automate tasks with ease.</li> <li><strong>Handles Complex Authentication:</strong> From MFA to OAuth, Airtop handles it all.</li> <li><strong>Scalable Cloud Browsers:</strong> Whether you need one browser or thousands, Airtop has you covered.</li> <li><strong>Compliant</strong>: Airtop ensures your data is handled with the highest security, availability, and privacy standards, giving you peace ", "id": 1474217, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1gm11x8/weve_built_a_browser_api_for_web_automation", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "We've built a browser API for web automation powered by AI", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-11-07T20:36:00+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Not long ago, I read through a lot of threads on &quot;project ideas&quot; and &quot;your favorite project&quot;... truth is, they weren&#39;t very inspiring. As a data analyst/engineer, I&#39;m drawn to understanding reality through numbers, but I found these suggestions lacking real spark. So here are some tips from my perspective:</p> <p>When you think about what information to gather, most of us tend to think of e-commerce, price tracking, etc. \u2014 but have you thought about why and what specifically you want from this data? Ask yourself:</p> <ul> <li>What are your main interests?</li> <li>What insights are you hoping to gain?</li> <li>What would you genuinely want to know or uncover?</li> </ul> <p>Here are a few project ideas I&#39;ve come up with recently:</p> <ul> <li>I follow several YouTubers who discuss literature, history, politics\u2026 some even have their own online bookstores. So, I thought, why not scrape book titles, authors, prices, and ca", "id": 1473871, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1gm0f3b/ideas_for_projects_ideas", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Ideas for Projects Ideas", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-11-07T17:04:07+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I am working on a project where I need to scrape data from government LLC websites. like below:</p> <p><a href=\"https://esos.nv.gov/EntitySearch/OnlineEntitySearch\">https://esos.nv.gov/EntitySearch/OnlineEntitySearch</a></p> <p><a href=\"https://ecorp.sos.ga.gov/BusinessSearch\">https://ecorp.sos.ga.gov/BusinessSearch</a></p> <p>I have bunch of such websites. Client is non-technical so I have to figure out a way how he will input the keyword and based on that keyword I will scrape data from every website and store results somewhere in the database. Almost all websites are build with ASP .Net so that is another issue for me. Making one scraper is okay but how can I manage scraping of this size. I should be able to add new websites as needed and also need some interface like API where my client can input keyword to scrape. I have proxies and captcha solver API. Needed a way or boilerplate how can i proceed with this project. I explored about distributed ", "id": 1472530, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1glvc6x/large_scale_distributed_scraping_help", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Large scale distributed scraping help.", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-11-07T15:44:13+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>For example, I&#39;m studying accounting and I&#39;m using a quiz app. On this quiz app, I can setup a pretest with 100 questions. For each question is a different webpage. After I take the quiz, I want to retrieve the question text and answer so I can study and learn it later.</p> <p>Is there anyway to tell if I would get blocked if I attempted to webscrape beforehand? For example, I could probably scrape the websites of local mom-and-pop business without issue but if I tried to scrape the websites we all know and love to try and scrape I&#39;d get blocked instantly. Is there a way to tell if a website is locked down with bot detection, etc?</p> <p>The reason I&#39;m asking this is because I paid for this service and don&#39;t want to somehow lose access to this web app.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TotalDodd\"> /u/TotalDodd </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/commen", "id": 1472001, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1gltf0t/how_to_tell_if_id_get_blocked_beforehand", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "How to tell if I'd get blocked beforehand?", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-11-07T12:40:52+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello everyone</p> <p>I&#39;m trying to scrape 500+ websites with an average of 1.5mil total requests Once a day , about a 3rd of those will need JS rendering, didn&#39;t run anything at this scale before although its not that much or complicated either.</p> <p>skipping all the script details just looking for cloud setups best fitting this use case </p> <p>Im assuming a queue like SQS with lambdas for requests along with fargate (or are ec2 spots better) for the headless browser requests<br/> That or would you run this all on one powerful server? </p> <p>Appreciate y&#39;all!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Double-Passage-438\"> /u/Double-Passage-438 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1glphyr/recommend_a_cloud_setup/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1glphyr/recommend_a_cloud_setup/\">[comments]</a></span>", "id": 1470959, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1glphyr/recommend_a_cloud_setup", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Recommend a Cloud Setup", "vote": 0}]