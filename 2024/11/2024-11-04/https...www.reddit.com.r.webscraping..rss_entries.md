# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## Selenium vs. Playwright
 - [https://www.reddit.com/r/webscraping/comments/1gjlno7/selenium_vs_playwright](https://www.reddit.com/r/webscraping/comments/1gjlno7/selenium_vs_playwright)
 - RSS feed: $source
 - date published: 2024-11-04T18:38:45+00:00

<!-- SC_OFF --><div class="md"><p>What are the advantages of each? Which is better for bypass bot detection?</p> <p>I remember coming across a version of Selenium that had some additional anti-bot defaults built in, but I forgot the name of the tool. Does anyone know what it&#39;s called?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/dca12345"> /u/dca12345 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1gjlno7/selenium_vs_playwright/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1gjlno7/selenium_vs_playwright/">[comments]</a></span>

## Weekly Discussion - 04 Nov 2024
 - [https://www.reddit.com/r/webscraping/comments/1gjgb0w/weekly_discussion_04_nov_2024](https://www.reddit.com/r/webscraping/comments/1gjgb0w/weekly_discussion_04_nov_2024)
 - RSS feed: $source
 - date published: 2024-11-04T15:01:29+00:00

<!-- SC_OFF --><div class="md"><p>Welcome to the weekly discussion thread! Whether you&#39;re a seasoned web scraper or just starting out, this is the perfect place to discuss topics that might not warrant a dedicated post, such as:</p> <ul> <li>Techniques for extracting data from popular sites like LinkedIn, Facebook, etc.</li> <li>Industry news, trends, and insights on the web scraping job market</li> <li>Challenges and strategies in marketing and monetizing your scraping projects</li> </ul> <p>Like our monthly <a href="https://reddit.com/r/webscraping/about/sticky?num=1">self-promotion</a> thread, mentions of paid services and tools are permitted ü§ù. If you&#39;re new to web scraping, be sure to check out the <a href="https://webscraping.fyi">beginners guide</a> üå±</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/AutoModerator"> /u/AutoModerator </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1gjgb0w/weekly_discussion_04_

## üöÄ The Infra to handle 10M Requests in 10 Minutes for $0.0116
 - [https://www.reddit.com/r/webscraping/comments/1gjf3u8/the_infra_to_handle_10m_requests_in_10_minutes](https://www.reddit.com/r/webscraping/comments/1gjf3u8/the_infra_to_handle_10m_requests_in_10_minutes)
 - RSS feed: $source
 - date published: 2024-11-04T14:09:35+00:00

<!-- SC_OFF --><div class="md"><p>Ready to scale like a pro without breaking the bank? Discover how to set up a lightning-fast infrastructure capable of handling <strong>10 million requests in just 10 minutes</strong>‚Äîall for a mere $0.0116! This guide covers everything you need, from Kubernetes and Terraform to Redis on Rackspace Spot. Perfect for web scraping pros and anyone pushing the limits of high-volume APIs on a budget!</p> <p>üëâ Dive into the full guide here: <a href="https://tonywang.io/blog/infra-10m-requests-10-minutes-0.0116">The Infra to handle 10M Requests in 10 Minutes for $0.0116</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/the_bigbang"> /u/the_bigbang </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1gjf3u8/the_infra_to_handle_10m_requests_in_10_minutes/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1gjf3u8/the_infra_to_handle_10m_requests_in_10_minutes/">[com

## a site-specific webscraper for account holders
 - [https://www.reddit.com/r/webscraping/comments/1gj98xg/a_sitespecific_webscraper_for_account_holders](https://www.reddit.com/r/webscraping/comments/1gj98xg/a_sitespecific_webscraper_for_account_holders)
 - RSS feed: $source
 - date published: 2024-11-04T08:00:14+00:00

<!-- SC_OFF --><div class="md"><p>I have a personal project trying to write an app that non-programmer users can use to download a Group Bookshelf&#39;s pages at human speed from Goodreads, since Amz/GR has a blind spot for Groups. Maybe there&#39;s something that might already do a &#39;bulk download&#39; like this?</p> <p>I have a program for myself but it only works when run locally with Python using <em>requests</em>. As soon as I try and broaden its usability, I run into oauth issues when I try to switch to a hosted Flask or JS, or can&#39;t use Python requests.</p> <p>The reason I&#39;d like to make it available for members (or at least moderators) in my groups to use is because we have anywhere from 3000 to 60,000 books on various Group Bookshelves. My program does more than downloading but this is the sticking point for usability.</p> <p>Any pointers on accomplishing this would be much appreciated...</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddi

## Help Needed: Extracting UPC from Instacart
 - [https://www.reddit.com/r/webscraping/comments/1gj5drf/help_needed_extracting_upc_from_instacart](https://www.reddit.com/r/webscraping/comments/1gj5drf/help_needed_extracting_upc_from_instacart)
 - RSS feed: $source
 - date published: 2024-11-04T03:40:43+00:00

<table> <tr><td> <a href="https://www.reddit.com/r/webscraping/comments/1gj5drf/help_needed_extracting_upc_from_instacart/"> <img src="https://a.thumbs.redditmedia.com/bALKyaaX9zClD-mBm9BsL2Ol4IZ9NuECodUebu3CzN8.jpg" alt="Help Needed: Extracting UPC from Instacart" title="Help Needed: Extracting UPC from Instacart" /> </a> </td><td> <!-- SC_OFF --><div class="md"><p><strong>Website URL</strong>: Instacart (Example url - <a href="https://www.instacart.ca/store/walmart-canada/s?k=Great+Value+Septic+Safe+Toilet+Paper">https://www.instacart.ca/store/walmart-canada/s?k=Great+Value+Septic+Safe+Toilet+Paper</a>)</p> <p><strong>Data Points</strong>: My goal is to extract:</p> <ul> <li><strong>Primary Target</strong>: <strong>UPC</strong> for each product</li> <li>Other easily available details: Product name, price, size/quantity, brand name, image URL, and stock status</li> </ul> <p><strong>Project Description</strong>:</p> <p>I&#39;m working on a project to gather product data, including th

