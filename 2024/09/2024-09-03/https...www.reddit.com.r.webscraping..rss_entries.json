[{"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-03T20:22:28+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I am very much a code noob but I am very tech savvy and 100% get the concept of coding and what it&#39;s trying to do, I just don&#39;t know how to speak it&#39;s language. I&#39;m trying to use ScraperAPI and I think I&#39;ve gotten everything setup, I&#39;m just not sure where to start scraping and don&#39;t know how to get the website to tell me the elements I need to put into the script so it can find it online when running and pull it. I feel like I&#39;m so close YET so far. I&#39;ve always wanted to dip my toes into coding and this project seems like the perfect starting point. I&#39;m using Python for the language and think I have a lot it in place, just need some confirmation and maybe direction on where to start scraping. Any and all help is so glady appreciated. Thank you!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ITakeLargeDabs\"> /u/ITakeLargeDabs </a> <br/> <span><a href=\"https://www.reddit.com", "id": 1076887, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1f8a95t/started_my_own_company_and_trying_to_use_data", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Started my own company and trying to use data scraping to build lists of prospects, so lost but also feel like I'm really close, PLEASE HELP!", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-03T15:10:19+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, I am by no means a professional web scraper, I have practiced a little on the older websites which are meant for scraping but now for my portfolio project I wanted to make a full stack web app, which essentially summarizes reviews a product from amazon using scraping, db, caching and ml pipeline, so far all of them are going great, until i got stuck on pagination, amazon has its own reviews webpage consisting of 10 reviews per page, i want a 100 for each time i run the code, so 10 pages, I have tried scrapy spider, it did not work, it would always load the first page but whenever i tried to move to the second page I get intercepted with a login page, now I have reverted back to using selenium and bs4 where in i navigate and extract page sources with selenium and parse them with bs4, but even here i am being throttled by getting redirected to the login page... all videos i have seen seem to be able to achieve this easily... I don&#39;t know what", "id": 1075612, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1f82cn6/a_student_trying_to_work_on_a_project_here_best", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "A student trying to work on a project here, best way to scrape amazon?", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-03T14:19:11+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I don&#39;t consider myself a starter but I was wondering something might be a starter question because I never had to face a situation like this, if I make a .exe file out of a playwright (python) file will the person running that .exe file need to have installed a webdriver on his/her computer? I&#39;m talking about the one that gets installed with &gt;playwright install. What about Selenium or other scraping tools? Do they have such dependencies?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/balaszDenmark\"> /u/balaszDenmark </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1f814nj/playwright_python_noob_question/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1f814nj/playwright_python_noob_question/\">[comments]</a></span>", "id": 1074229, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1f814nj/playwright_python_noob_question", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Playwright python noob question", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-03T13:27:08+00:00", "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/p3r3lin\"> /u/p3r3lin </a> <br/> <span><a href=\"https://blancas.io/blog/ai-web-scraper/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1f7zx4n/blog_post_using_gpt4o_for_web_scraping/\">[comments]</a></span>", "id": 1074230, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1f7zx4n/blog_post_using_gpt4o_for_web_scraping", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Blog Post: Using GPT-4o for web scraping", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-03T10:43:45+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, everyone. Hope you all are doing well.<br/> I am completely new to web scraping. Is there any way to extract all the email addresses from my Gmail Inbox apart from Google Takeout?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Commercial_Ebb1058\"> /u/Commercial_Ebb1058 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1f7wrg5/extracting_email_addresses_from_gmail_inbox/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1f7wrg5/extracting_email_addresses_from_gmail_inbox/\">[comments]</a></span>", "id": 1072980, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1f7wrg5/extracting_email_addresses_from_gmail_inbox", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Extracting email addresses from Gmail inbox", "user": null, "vote": 0}]