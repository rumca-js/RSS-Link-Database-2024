[{"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-02T19:09:47+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>As title says, I want to scrape a few websites where they\u2019re pretty protective of the information being scraped. Is there any way around this, or is just going ahead with scraping something I could do? </p> <p>Would a VPN help avoid a ban?</p> <p>Thanks</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/3leavclova\"> /u/3leavclova </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1f7f3gl/can_you_scrape_a_website_if_the_terms_of_service/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1f7f3gl/can_you_scrape_a_website_if_the_terms_of_service/\">[comments]</a></span>", "id": 1070549, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1f7f3gl/can_you_scrape_a_website_if_the_terms_of_service", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Can you scrape a website if the Terms of Service don\u2019t allow automated requests?", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-02T18:23:41+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I swear everytime I search for Playwright it shows me jobs for <strong>an actual playwright..</strong> Anyone have a semantic way searching around this? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Impressive_Safety_26\"> /u/Impressive_Safety_26 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1f7dxq3/how_do_you_find_playwrightjs_jobs_and_not_poetry/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1f7dxq3/how_do_you_find_playwrightjs_jobs_and_not_poetry/\">[comments]</a></span>", "id": 1070293, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1f7dxq3/how_do_you_find_playwrightjs_jobs_and_not_poetry", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "How do you find Playwright.js jobs and not poetry jobs", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-02T16:52:28+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey, i have plan to automate some website using puppeteer, the issue is i dont know what type of inputs coming next ( Input fields, drop downs, checkboxes, radio buttons), there might be only checkboxes or only input fields and dropdowns, even i dont how many would come. I can make sure one thing, that there will only those type of inputs.</p> <p>So how do i make puppeteer know what is there and fill it accordingly.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/LocalConversation850\"> /u/LocalConversation850 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1f7bmkm/i_dont_whats_gonna_come_up_with_the_view_how_do_i/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1f7bmkm/i_dont_whats_gonna_come_up_with_the_view_how_do_i/\">[comments]</a></span>", "id": 1069873, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1f7bmkm/i_dont_whats_gonna_come_up_with_the_view_how_do_i", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "I dont what\u2019s gonna come up with the view, how do i know and automate things", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-02T15:43:03+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve used Dux-Soup in the past to run automated lead generation on LinkedIn (it is a chrome plug-in that automatically visits profiles, scrapes the profile info, and optionally connects to the profile and/or send them a message).</p> <p>I&#39;d like to build my own custom tool for this. However as you probably know, scraping LinkedIn is quite difficult due to CSP restrictions. I&#39;m trying to understand what method tools like Dux-Soup use as it is very efficient at it. </p> <p>From my understanding it operates as a headless browser built with something like Puppeteer or Selenium? Is this the most effective method for bypassing LinkedIn&#39;s CSP restrictions?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/OptimalBarnacle7633\"> /u/OptimalBarnacle7633 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1f79wyt/most_effective_method_for_scraping_profiles_from/\">[link]</a></span> &#32; <spa", "id": 1069413, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1f79wyt/most_effective_method_for_scraping_profiles_from", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Most effective method for scraping profiles from LinkedIn Sales Navigator", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-02T15:07:18+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Can I get a list of Instagram account in a certain Industry (lets say dentists in US). If I want to scrape it manually how do I do that?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/False_Ad4246\"> /u/False_Ad4246 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1f791t5/scraping_instagram/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1f791t5/scraping_instagram/\">[comments]</a></span>", "id": 1068970, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1f791t5/scraping_instagram", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Scraping Instagram", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-02T15:01:07+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Welcome to the weekly discussion thread! Whether you&#39;re a seasoned web scraper or just starting out, this is the perfect place to discuss topics that might not warrant a dedicated post, such as:</p> <ul> <li>Techniques for extracting data from popular sites like LinkedIn, Facebook, etc.</li> <li>Industry news, trends, and insights on the web scraping job market</li> <li>Challenges and strategies in marketing and monetizing your scraping projects</li> </ul> <p>Like our monthly <a href=\"https://reddit.com/r/webscraping/about/sticky?num=1\">self-promotion</a> thread, mentions of paid services and tools are permitted \ud83e\udd1d. If you&#39;re new to web scraping, be sure to check out the <a href=\"https://webscraping.fyi\">beginners guide</a> \ud83c\udf31</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AutoModerator\"> /u/AutoModerator </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1f78w8c/weekly_discussion_02_s", "id": 1068969, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1f78w8c/weekly_discussion_02_sep_2024", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Weekly Discussion - 02 Sep 2024", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-02T12:28:43+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I am trying to get the data on <a href=\"https://digitalsky.dgca.gov.in/remote_pilots\">https://digitalsky.dgca.gov.in/remote_pilots</a>, in the network tab I found the get request to: <a href=\"https://digitalsky.dgca.gov.in/digital-sky/public/pilots/certified?pageNo=226&amp;size=50\">https://digitalsky.dgca.gov.in/digital-sky/public/pilots/certified?pageNo=226&amp;size=50</a> But when I try accessing the link through python (response = requests.get(url)) it gives a 400 error with the following error:</p> <p>\u2018\u2019\u2019{&#39;message&#39;: &#39;Bad Request&#39;, &#39;_links&#39;: {&#39;self&#39;: {&#39;href&#39;: &#39;/digital-sky/public/pilots/certified?pageNo=1&amp;size=50&#39;, &#39;templated&#39;: False}}, &#39;_embedded&#39;: {&#39;errors&#39;: [{&#39;message&#39;: &#39;Required Header [source] not specified&#39;, &#39;path&#39;: &#39;/source&#39;}]}}\u2019\u2019\u2019</p> <p>I tried the same process for another dataset on the same website (<a href=\"https://digitalsky.dgca", "id": 1067820, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1f75i9a/recreating_get_request_results_in_400_error", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Recreating get request results in 400 Error", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-02T10:54:30+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I am fascinated by how the Freebie Alerts App scrapes listing, specially from FB marketplace, and I was wondering if anyone has any idea on what languages or approaches it may be using to scrape FB marketplace listings. I would love to try to run something similar with custom searches with different settings. I started using python and playwright, but not sure if this may be a good starting approach.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Last_Choice6947\"> /u/Last_Choice6947 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1f73uj3/understanding_how_freebie_alerts_app_scrapes/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1f73uj3/understanding_how_freebie_alerts_app_scrapes/\">[comments]</a></span>", "id": 1067476, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1f73uj3/understanding_how_freebie_alerts_app_scrapes", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Understanding how Freebie Alerts App scrapes marketplace listings", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-02T08:12:36+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>[ Removed by Reddit on account of violating the <a href=\"/help/contentpolicy\">content policy</a>. ]</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Big_Sky5878\"> /u/Big_Sky5878 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1f71hcz/getting_correct_selector_using_puppeteer/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1f71hcz/getting_correct_selector_using_puppeteer/\">[comments]</a></span>", "id": 1066769, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1f71hcz/getting_correct_selector_using_puppeteer", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Getting correct selector using Puppeteer", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-02T07:13:34+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>[ Removed by Reddit on account of violating the <a href=\"/help/contentpolicy\">content policy</a>. ]</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Big_Sky5878\"> /u/Big_Sky5878 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1f70na5/getting_correct_selector_using_puppeteer/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1f70na5/getting_correct_selector_using_puppeteer/\">[comments]</a></span>", "id": 1066555, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1f70na5/getting_correct_selector_using_puppeteer", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Getting correct selector using Puppeteer", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-02T03:53:17+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I used to joke that no amount of web scraping protections can defend against an external camera pointed at the screen and a bunch of tiny servos typing keys and moving the mouse. I think I&#39;ve found the program equivalent.</p> <p>Recently, I&#39;ve web scraped a bunch of stuff using the pynput library; I literally just manually do what I want to do, then use pynput and pyautogui to record, and then replicate all of my keyboard inputs and mouse movements however many times I want. To scrape the data, I just set it to take automatic screenshots of certain pixels at certain points in time, and maybe use an ML library to extract the text. Obviously, this method isn&#39;t good for scraping large amounts of data, but here are the things I have been able to do:</p> <ul> <li>scrape pages where you&#39;re more interested in live updates e.g. stock prices or trades</li> <li>scrape google images</li> <li>replace the youtube API by recording and performing the", "id": 1066009, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1f6xf3n/am_i_onto_something", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Am I onto something", "user": null, "vote": 0}]