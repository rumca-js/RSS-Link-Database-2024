[{"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-14T22:44:55+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, </p> <p>I have build a scraping application that scrapes betting companies, compares their prices and display in a UI. </p> <p>Until now I don&#39;t store any results of the scraping process, just scrape them, make comparisons, display in a UI and repeat the circle (every 2-3 seconds)</p> <p>I want to start saving all the scraping results (json files) and I want to know the cheapest way to do it. </p> <p>The whole application is in a Droplet on Digital Ocean Platform.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/panagiotisgia\"> /u/panagiotisgia </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fgy35h/cheapest_way_to_store_json_files_after_scraping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fgy35h/cheapest_way_to_store_json_files_after_scraping/\">[comments]</a></span>", "id": 1146633, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fgy35h/cheapest_way_to_store_json_files_after_scraping", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Cheapest way to store JSON files after scraping", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-14T17:42:32+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello guys, I would kindly like to request your help. I am looking for innovative ways and maybe Buyer Personas for my <a href=\"https://apify.com/glitch_404/ultimate-news-scraper\">apify actor</a> that I developed with my friend.</p> <p>brief summary: news scraper to scrape up to 10K news articles from over 10 000 news sources in less than 13 minutes news from over 20 categories .e.g. Crypto news, World News, Latest News, Celebrities News, and a lot more. you can get news from websites like Fox News, BBC News, CNN News, Crypto and Cryptocurrencies.</p> <p>We are currently enrolled in the marketing discussion. We are well aware of the capabilities of our scraper and that nothing else on the apify platform can match it. It is a bold statement, but i invite everybody who is insterested to try it. We have a free plan.</p> <p>Anyways, I would appreciate your ideas on who might find this useful , and would like to spend 10-20 USD on it.</p> <p>Thanks in adva", "id": 1145730, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fgrngs/marketing_vectors_for_my_scraper_help", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Marketing Vectors for my scraper HELP", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-14T16:57:08+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Apologies as I am not aware of the correct terminology but I need to scrape a site that requires the user to be logged in via a crypto wallet first. </p> <p>I can see that I need some form or automation locally to grab copies of the site code and pass that to my scraper (probably scrapy) but am not sure of the best way to do this as I\u2019ve never done it before. </p> <p>Anyone walked this path already?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ok-Ship812\"> /u/Ok-Ship812 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fgqnq5/scraping_a_metamask_login_site/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fgqnq5/scraping_a_metamask_login_site/\">[comments]</a></span>", "id": 1145477, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fgqnq5/scraping_a_metamask_login_site", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Scraping a \u2018Metamask\u2019 login site", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-14T16:43:33+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, I created a Python Flask application that would access a list of urls and fetch data from the given sites a few times a day. This works fine on my machine but when the application is hosted using Vercel some requests will time out. There is a 40 second timeout and I\u2019m not fetching a lot of data so I assume specific domains are blocking it somehow.</p> <p>Could some sites be blocking Vercel servers ip? And is there any way around that? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Majestic-Location-\"> /u/Majestic-Location- </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fgqcqe/timeout_when_trying_to_access_from_hosted_project/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fgqcqe/timeout_when_trying_to_access_from_hosted_project/\">[comments]</a></span>", "id": 1145478, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fgqcqe/timeout_when_trying_to_access_from_hosted_project", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Timeout when trying to access from hosted project", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-14T14:30:05+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>People say rendering js is real slow but considering how easy it is to spawn up an army of containers just with 32 cores / 64GB.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ObjectivePapaya6743\"> /u/ObjectivePapaya6743 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fgnctf/how_slow_are_you_talking_about_when_scraping_with/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fgnctf/how_slow_are_you_talking_about_when_scraping_with/\">[comments]</a></span>", "id": 1145005, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fgnctf/how_slow_are_you_talking_about_when_scraping_with", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "How slow are you talking about when scraping with browser automation tools?", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-14T11:11:56+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello! I hope everyone is doing great.</p> <p>I&#39;m currently learning web scraping, and I heard that scraping mobile apps allows you to discover hidden APIs, which are often stable and don\u2019t change frequently. I\u2019m looking for a way to scrape mobile apps to find these APIs and test them for automation.</p> <p>For example, in a gym app where the owner posts images and videos, some videos may not be easily accessible. If I can get the API link to those videos, downloading them becomes much easier.</p> <p>Does anyone have any ideas on how to scrape mobile apps?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Opposite_Bowl_8781\"> /u/Opposite_Bowl_8781 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fgjqpe/need_help_for_the_andriod_app_scraping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fgjqpe/need_help_for_the_andriod_app_scraping/\">[comments]</a", "id": 1144264, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fgjqpe/need_help_for_the_andriod_app_scraping", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Need Help for the Andriod App Scraping", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-14T09:51:43+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi.</p> <p>Did someone made good experience with this?</p> <p><a href=\"https://github.com/ScrapeGraphAI/Scrapegraph-ai/tree/main\">https://github.com/ScrapeGraphAI/Scrapegraph-ai/tree/main</a></p> <p>I tested several Websites with Ollama 3.1 nothing worked. </p> <p>Is it the model or something related to the library that you need a special prompt too?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/HistorianSmooth7540\"> /u/HistorianSmooth7540 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fgim4a/scrapegraph_ai_experiences/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fgim4a/scrapegraph_ai_experiences/\">[comments]</a></span>", "id": 1143990, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fgim4a/scrapegraph_ai_experiences", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Scrapegraph AI - experiences?", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-14T02:49:29+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>As the title says, I\u2019m trying to scrape our favourite mapping service.</p> <p>Im not interested in using a vendor or other service, I want to do it myself because it\u2019s the core for my lead gen.</p> <p>In attempts to help others (and see if I\u2019m on the right track) here\u2019s my plan, I appreciate any thoughts or feedback:</p> <ul> <li><p>The url I\u2019m going to scrape is: <a href=\"https://www.google.com/maps/search/%7Bquery%7D/@%7Blat%7D,%7Blong%7D,16z\">https://www.google.com/maps/search/{query}/@{lat},{long},16z</a></p></li> <li><p>I have already developed a \u201cscraping map\u201d that has all the coordinates I want to hit, I plan to loop through them with a headless browser and capture the page\u2019s html. I\u2019ll scrape first and parse later.</p></li> <li><p>All the fun stuff like proxies and parallelization will be there so I\u2019m not worried about the architecture/viability. In theory this should work.</p></li> </ul> <p>My main concern: is there a better way to grab this ", "id": 1142918, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fgcgrm/scraping_gmaps_at_scale", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Scraping GMaps at Scale", "vote": 0}]