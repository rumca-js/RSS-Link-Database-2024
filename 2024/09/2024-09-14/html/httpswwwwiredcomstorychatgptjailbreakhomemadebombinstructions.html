<!DOCTYPE html><html><head>   <meta>     <title>Security News This Week: A Creative Trick Makes ChatGPT Spit Out Bomb-Making Instructions</title>   </meta>   <style>
.youtube_player_container {
    position: relative;
    width: 50%;
    padding-bottom: 26.25%;
    /* background-color: yellow; */
}
.youtube_player_frame {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    border: 0;
}
       </style></head><body><a href="index.html"><h2>Index</h2></a><a href="https://www.wired.com/story/chatgpt-jailbreak-homemade-bomb-instructions"><div><img style="width:400px;height=300px" src="https://media.wired.com/photos/66e49db3c547018981902ffc/master/pass/Security_ChatGPT_Bomb_GettyImages-1434753385.jpg" /></div><h1>[1143844] Security News This Week: A Creative Trick Makes ChatGPT Spit Out Bomb-Making Instructions</h1></a><div>https://www.wired.com/feed/rss</div><div>2024-09-14 09:30:00+00:00</div><div><pre>Plus: New evidence emerges about who may have helped 9/11 hijackers, UK police arrest a teen in connection with an attack on London’s transit system, and Poland’s spyware scandal enters a new phase.</pre></div></body></html>