[{"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-28T16:50:26+00:00", "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1frillh/spiderfoot_and_truepeoplesearch_integration/\"> <img src=\"https://b.thumbs.redditmedia.com/ZIjOXccYgSFIaIyXaIeXd7oqmSLc_libmR2Gqo4vm8c.jpg\" alt=\"Spiderfoot And TruePeopleSearch Integration! \" title=\"Spiderfoot And TruePeopleSearch Integration! \" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>I was interested in using Endato&#39;s API (API Maker Behind TPS) to be an active module in Spiderfoot. My coding knowledge is not too advanced but I am proficient in the use of LLM&#39;s. I was able to write my own module with the help of Claude and GPT by just converting both Spiderfoot&#39;s and Endato&#39;s API documentation into PDFS and then giving it to them so they could understand how it could work together. It works but I would like to be able to format the response that the API sends back to Spiderfoot&#39;s end, a little better. Anyone with knowledge or ideas, please share! I&#39;ve attached what the cu", "id": 1230800, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1frillh/spiderfoot_and_truepeoplesearch_integration", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 86, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": "https://b.thumbs.redditmedia.com/ZIjOXccYgSFIaIyXaIeXd7oqmSLc_libmR2Gqo4vm8c.jpg", "title": "Spiderfoot And TruePeopleSearch Integration!", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-28T15:38:47+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>So, I\u2019ve recently been diving into web scraping, and the results have been pretty eye-opening. I\u2019ve managed to automate scraping for emails, job titles, and other data directly from social media profiles, which has significantly boosted my outreach campaigns. Instead of manually hunting for details, the scraper handles it all and even validates emails before they land in my CRM.</p> <p>I know scraping can have its challenges with rate limits and terms of service, so I\u2019m curious\u2014what\u2019s been your experience with scraping on social media platforms? Have you found any tricks to increase efficiency without getting blocked? Would love to hear what\u2019s been working for you all!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Timofeir\"> /u/Timofeir </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1frh0g8/web_scraping_automation/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscra", "id": 1230521, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1frh0g8/web_scraping_automation", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Web scraping automation", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-28T14:57:13+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Im trying to warm up my own browser core with randomly accessed websites, what i want to know is what\u2019s the best way to accept cookies consent, since am accessing around 50 websites one by one i cant be rely on an specific selector or a popup to click the \u2018Accept\u2019 button.</p> <p>What would be the best way?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/LocalConversation850\"> /u/LocalConversation850 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1frg3nz/how_to_automate_accepting_cookies_content_from/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1frg3nz/how_to_automate_accepting_cookies_content_from/\">[comments]</a></span>", "id": 1230290, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1frg3nz/how_to_automate_accepting_cookies_content_from", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "How to automate accepting cookies content from different websites", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-28T13:48:41+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>So, I\u2019ve recently been diving into web scraping, and the results have been pretty eye-opening. I\u2019ve managed to automate scraping for emails, job titles, and other data directly from social media profiles, which has significantly boosted my outreach campaigns. Instead of manually hunting for details, the scraper handles it all and even validates emails before they land in my CRM.</p> <p>I know scraping can have its challenges with rate limits and terms of service, so I\u2019m curious\u2014what\u2019s been your experience with scraping on social media platforms? Have you found any tricks to increase efficiency without getting blocked? Would love to hear what\u2019s been working for you all!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Timofeir\"> /u/Timofeir </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1frep8k/web_scraping_automation/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscra", "id": 1230074, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1frep8k/web_scraping_automation", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "Web scraping automation", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-28T13:21:14+00:00", "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/antvas\"> /u/antvas </a> <br/> <span><a href=\"https://deviceandbrowserinfo.com/learning_zone/articles/getting-started-bot-detection\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fre62u/how_to_get_started_in_bot_detection_and_bot/\">[comments]</a></span>", "id": 1230075, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fre62u/how_to_get_started_in_bot_detection_and_bot", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source__id": 467, "source_url": "https://www.reddit.com/r/webscraping/.rss", "status_code": 0, "tags": [], "thumbnail": null, "title": "How to get started in bot detection and bot development?", "vote": 0}]