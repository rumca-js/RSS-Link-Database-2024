# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## Wget help - Open Directory
 - [https://www.reddit.com/r/webscraping/comments/1ft9flq/wget_help_open_directory](https://www.reddit.com/r/webscraping/comments/1ft9flq/wget_help_open_directory)
 - RSS feed: $source
 - date published: 2024-09-30T23:07:45+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;ve used wget a ton and thought this would be one of the easier things for it... I Was trying to scrape this OD for images: <a href="https://siliconpr0n.org/map/">https://siliconpr0n.org/map/</a></p> <p>But it for some reason downloads an HTML or TMP file for each directory (which are invisible?). </p> <p>I am using -A jpg,png -R html,tmp</p> <p>So it should only download images, but still the TMP files are downloaded and then removed by wget. How can I force it to only download images? Or do I just need to use a different tool?</p> <p>Here is what wget outputs for the first directory:</p> <p>2024-09-30 17:01:40 (1.10 GB/s) - &#39;siliconpr0n.org/map/1g10/index.html.tmp&#39; saved [943/943]</p> <p>Removing siliconpr0n.org/map/1g10/index.html.tmp since it should be rejected.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/plunki"> /u/plunki </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/commen

## What are the potential costs to a company subjected to AI training?
 - [https://www.reddit.com/r/webscraping/comments/1fszh05/what_are_the_potential_costs_to_a_company](https://www.reddit.com/r/webscraping/comments/1fszh05/what_are_the_potential_costs_to_a_company)
 - RSS feed: $source
 - date published: 2024-09-30T16:14:46+00:00

<!-- SC_OFF --><div class="md"><p>I believe I have seen discussions where companies have raised concerns about the impact of web scraping, especially in terms of cost. They mention factors like the need for application tuning, increased hardware usage, and bandwidth consumption.</p> <p>I also remember seeing a post where someone estimated the cost of having their site scraped by AI models, given their site has a lot of unique and valuable content.</p> <p>Unfortunately, I can&#39;t find these sources again. I know iFixit complained about the number of hits they got from Anthropic.</p> <p>I‚Äôm curious if anyone has come across any concrete numbers or examples of what the actual costs might be for a company in this situation? What could the potential expenses look like for a company with a high volume of interesting content that‚Äôs frequently targeted for AI scraping?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/kspr_u"> /u/kspr_u </a> <br/> <span>

## Weekly Discussion - 30 Sep 2024
 - [https://www.reddit.com/r/webscraping/comments/1fsxn7f/weekly_discussion_30_sep_2024](https://www.reddit.com/r/webscraping/comments/1fsxn7f/weekly_discussion_30_sep_2024)
 - RSS feed: $source
 - date published: 2024-09-30T15:01:03+00:00

<!-- SC_OFF --><div class="md"><p>Welcome to the weekly discussion thread! Whether you&#39;re a seasoned web scraper or just starting out, this is the perfect place to discuss topics that might not warrant a dedicated post, such as:</p> <ul> <li>Techniques for extracting data from popular sites like LinkedIn, Facebook, etc.</li> <li>Industry news, trends, and insights on the web scraping job market</li> <li>Challenges and strategies in marketing and monetizing your scraping projects</li> </ul> <p>Like our monthly <a href="https://reddit.com/r/webscraping/about/sticky?num=1">self-promotion</a> thread, mentions of paid services and tools are permitted ü§ù. If you&#39;re new to web scraping, be sure to check out the <a href="https://webscraping.fyi">beginners guide</a> üå±</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/AutoModerator"> /u/AutoModerator </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fsxn7f/weekly_discussion_30_s

## Help with Scraping Embedded API Data from Aliexpress with Python
 - [https://www.reddit.com/r/webscraping/comments/1fsxh8c/help_with_scraping_embedded_api_data_from](https://www.reddit.com/r/webscraping/comments/1fsxh8c/help_with_scraping_embedded_api_data_from)
 - RSS feed: $source
 - date published: 2024-09-30T14:54:01+00:00

<table> <tr><td> <a href="https://www.reddit.com/r/webscraping/comments/1fsxh8c/help_with_scraping_embedded_api_data_from/"> <img src="https://b.thumbs.redditmedia.com/c2uffJL8CMVEVK7qo9KQ-YS3RqEiTEdUY3AwVfmhYTA.jpg" alt="Help with Scraping Embedded API Data from Aliexpress with Python" title="Help with Scraping Embedded API Data from Aliexpress with Python" /> </a> </td><td> <!-- SC_OFF --><div class="md"><p>Hi, I am trying to scrape from Aliexpress and the API I am looking for is embedded in the script tag, and I have no idea how to retrieve the values of the keys embedded within it: I have attached a picture of the page source if that might help</p> <p><a href="https://preview.redd.it/uwkcyzzsmyrd1.png?width=945&amp;format=png&amp;auto=webp&amp;s=bd8af9df6bb6297589f0d77deb2c753bc3ee1ce1">https://preview.redd.it/uwkcyzzsmyrd1.png?width=945&amp;format=png&amp;auto=webp&amp;s=bd8af9df6bb6297589f0d77deb2c753bc3ee1ce1</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https:

## Data scraping help
 - [https://www.reddit.com/r/webscraping/comments/1fsua2w/data_scraping_help](https://www.reddit.com/r/webscraping/comments/1fsua2w/data_scraping_help)
 - RSS feed: $source
 - date published: 2024-09-30T12:27:12+00:00

<!-- SC_OFF --><div class="md"><p>Hi, I am hoping to scrape data from a subreddit within 2023 to 2024 (1 year data if possible)This is for a research study (undergraduate). Is there a way to do that? Thank you!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/backspace025"> /u/backspace025 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fsua2w/data_scraping_help/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1fsua2w/data_scraping_help/">[comments]</a></span>

## Help me with searchpeoplefree.com
 - [https://www.reddit.com/r/webscraping/comments/1fst9ti/help_me_with_searchpeoplefreecom](https://www.reddit.com/r/webscraping/comments/1fst9ti/help_me_with_searchpeoplefreecom)
 - RSS feed: $source
 - date published: 2024-09-30T11:31:21+00:00

<!-- SC_OFF --><div class="md"><p>Hi all. Can you please help me with the captcha issue? If I send 10 requests, it rate limits the ip. I tried rotating user agents, and I have 5 US ips. But they all are blocked. The website recently implemented high security measures. I had no issue with Cloudflare before on this site. But now it seems to completely block the ip&#39;s. There are many delays in between, but I keep failing since my knowledge is very limited. I am on nodejs puppeteer. If someone can help me with this I&#39;d highly appreciate it thanks. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/PurpleJellyJay"> /u/PurpleJellyJay </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fst9ti/help_me_with_searchpeoplefreecom/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1fst9ti/help_me_with_searchpeoplefreecom/">[comments]</a></span>

## Please help me bypass Cloudflare
 - [https://www.reddit.com/r/webscraping/comments/1fss8g3/please_help_me_bypass_cloudflare](https://www.reddit.com/r/webscraping/comments/1fss8g3/please_help_me_bypass_cloudflare)
 - RSS feed: $source
 - date published: 2024-09-30T10:24:30+00:00

<!-- SC_OFF --><div class="md"><p>Hi all. Can you help me bypass cloudflare for <a href="http://searchpeoplefree.com">searchpeoplefree.com</a> ?</p> <p>I have been trying everything but my knowledge is limited and any kind of help would highly be appreciated. </p> <p>I tried python&#39;s selenium (failed). I tried nodejs puppeteer, failed. It keeps giving me cloudflare captchas.</p> <p>Thanks.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/PurpleJellyJay"> /u/PurpleJellyJay </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fss8g3/please_help_me_bypass_cloudflare/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1fss8g3/please_help_me_bypass_cloudflare/">[comments]</a></span>

## Need help in parsing server-side rendered data.....
 - [https://www.reddit.com/r/webscraping/comments/1fsppjw/need_help_in_parsing_serverside_rendered_data](https://www.reddit.com/r/webscraping/comments/1fsppjw/need_help_in_parsing_serverside_rendered_data)
 - RSS feed: $source
 - date published: 2024-09-30T07:10:59+00:00

<!-- SC_OFF --><div class="md"><p>Here&#39;s the data</p> <p>23:{\&quot;path_id\&quot;:4928,\&quot;fc_id\&quot;:1343,\&quot;sa_id\&quot;:14103}\n25:[]\n26:[]\n24:{\&quot;key_highlights\&quot;:\&quot;$25\&quot;,\&quot;assurance_widget\&quot;:\&quot;$26\&quot;}\n28:}\n2f:{\&quot;s\&quot;:\&quot;<a href="https://www.bigbasket.com/media/uploads/p/s/40322465-8%5C_1-portronics-muffs-m2%22">https://www.bigbasket.com/media/uploads/p/s/40322465-8\_1-portronics-muffs-m2&quot;</a>}</p> <p>another data example: <a href="https://kasmweb.com/get-started.txt?_rsc=1wtp7">https://kasmweb.com/get-started.txt?_rsc=1wtp7</a></p> <p>I want to convert it into a key: value pair</p> <p>. i.e. 23: &quot;remaining value&quot;, 25: &quot;remaining value&quot;</p> <p>I&#39;ve retried using regex but it doesn&#39;t work properly as fails in certain edge cases.</p> <p>regex: (\b([0-9a-f]+):|(?:\\n)*([0-9a-f]+)):\s*(.*?)(?=(\b([0-9a-f]+):|(?:\\n)*([0-9a-f]+)):|$)</p> <p>As it is SSR, I thought creating a temp nextj

## Any tips to get around Invisible reCAPTCHA v3?
 - [https://www.reddit.com/r/webscraping/comments/1fsm0xl/any_tips_to_get_around_invisible_recaptcha_v3](https://www.reddit.com/r/webscraping/comments/1fsm0xl/any_tips_to_get_around_invisible_recaptcha_v3)
 - RSS feed: $source
 - date published: 2024-09-30T03:10:47+00:00

<!-- SC_OFF --><div class="md"><p>Hi Guys, I have a multistep form which has 2x hidden captchas on the form. </p> <p>One on the first page and another on the 3rd page.</p> <p>I thought I could get around this using the API however, it appears they are using the captcha response to validate the submission.</p> <p>I have using puppeteer with extra stealth and it just keeps getting caught.</p> <p>It wont submit the final form to get the data I need, it will just spin on the submit button, which I believe is because i&#39;ve been flagged. </p> <p>Thanks! </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/should_not_register"> /u/should_not_register </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fsm0xl/any_tips_to_get_around_invisible_recaptcha_v3/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1fsm0xl/any_tips_to_get_around_invisible_recaptcha_v3/">[comments]</a></span>

## Cannot scrape defense table
 - [https://www.reddit.com/r/webscraping/comments/1fskngq/cannot_scrape_defense_table](https://www.reddit.com/r/webscraping/comments/1fskngq/cannot_scrape_defense_table)
 - RSS feed: $source
 - date published: 2024-09-30T01:56:56+00:00

<!-- SC_OFF --><div class="md"><pre><code>Full weblink is https://www.sports-reference.com/cfb/schools/georgia/2024.html Can someone explain to me, why I can only scrape &#39;offense&#39; table? WHen I try to do same thing with &#39;defense&#39;, it cannot find the table. for season in seasons: for team in teams: url =f&#39;https://www.sports-reference.com/cfb/schools/{team}/{season}/gamelog/&#39; off_df = pd.read_html(url, header=1, attrs={&#39;id&#39;:&#39;offense&#39;})[0] def_df = pd.read_html(url, header=1, attrs={&#39;id&#39;:&#39;defense&#39;})[0] time.sleep(random.randint(4,5)) </code></pre> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/andreyk88"> /u/andreyk88 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fskngq/cannot_scrape_defense_table/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1fskngq/cannot_scrape_defense_table/">[comments]</a></span>

## Can somebody ask NKHoncho to fix Nekohouse's SubscribeStar importer?
 - [https://www.reddit.com/r/webscraping/comments/1fsjmk6/can_somebody_ask_nkhoncho_to_fix_nekohouses](https://www.reddit.com/r/webscraping/comments/1fsjmk6/can_somebody_ask_nkhoncho_to_fix_nekohouses)
 - RSS feed: $source
 - date published: 2024-09-30T01:01:50+00:00

<!-- SC_OFF --><div class="md"><p>Can somebody ask NKHoncho to fix Nekohouse&#39;s SubscribeStar importer by giving it the ability to import text and multiple images? I don&#39;t have Telegram and I can&#39;t find His email anywhere.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/burai1992"> /u/burai1992 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fsjmk6/can_somebody_ask_nkhoncho_to_fix_nekohouses/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1fsjmk6/can_somebody_ask_nkhoncho_to_fix_nekohouses/">[comments]</a></span>

## Scraping Minecraft Marketplace
 - [https://www.reddit.com/r/webscraping/comments/1fsiz4f/scraping_minecraft_marketplace](https://www.reddit.com/r/webscraping/comments/1fsiz4f/scraping_minecraft_marketplace)
 - RSS feed: $source
 - date published: 2024-09-30T00:28:13+00:00

<!-- SC_OFF --><div class="md"><p>I found this website and they somehow scraped something that isnt released yet? How can I do this myself?</p> <p><a href="https://chunk.gg/@minecraft/a-minecraft-movie-hero-pack">https://chunk.gg/@minecraft/a-minecraft-movie-hero-pack</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Grape_wtf"> /u/Grape_wtf </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fsiz4f/scraping_minecraft_marketplace/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1fsiz4f/scraping_minecraft_marketplace/">[comments]</a></span>

