# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## Python Web Scraping multiple pages where the URL stays the same?
 - [https://www.reddit.com/r/webscraping/comments/1fnxr5d/python_web_scraping_multiple_pages_where_the_url](https://www.reddit.com/r/webscraping/comments/1fnxr5d/python_web_scraping_multiple_pages_where_the_url)
 - RSS feed: $source
 - date published: 2024-09-23T22:49:40+00:00

<table> <tr><td> <a href="https://www.reddit.com/r/webscraping/comments/1fnxr5d/python_web_scraping_multiple_pages_where_the_url/"> <img src="https://preview.redd.it/65cgdkhi1nqd1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d82e23e084669a265d058bd83f634887c57897c6" alt="Python Web Scraping multiple pages where the URL stays the same?" title="Python Web Scraping multiple pages where the URL stays the same?" /> </a> </td><td> <!-- SC_OFF --><div class="md"><p>Hello! So I‚Äôm currently learning web scraping and I‚Äôm using the site pictured, nba.com/players . There‚Äôs a giant list of nba players spread into 100 pages. I‚Äôve learned how to web scrape when the url changes with the page but not for something like this. The URL stays the exact same but upon scraping it only gets the 50 on the first page. Wondering if there‚Äôs something I need to learn here. I‚Äôve attached an image of the website with the HTML. Thanks! </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.redd

## Weekly Discussion - 23 Sep 2024
 - [https://www.reddit.com/r/webscraping/comments/1fnmjua/weekly_discussion_23_sep_2024](https://www.reddit.com/r/webscraping/comments/1fnmjua/weekly_discussion_23_sep_2024)
 - RSS feed: $source
 - date published: 2024-09-23T15:00:57+00:00

<!-- SC_OFF --><div class="md"><p>Welcome to the weekly discussion thread! Whether you&#39;re a seasoned web scraper or just starting out, this is the perfect place to discuss topics that might not warrant a dedicated post, such as:</p> <ul> <li>Techniques for extracting data from popular sites like LinkedIn, Facebook, etc.</li> <li>Industry news, trends, and insights on the web scraping job market</li> <li>Challenges and strategies in marketing and monetizing your scraping projects</li> </ul> <p>Like our monthly <a href="https://reddit.com/r/webscraping/about/sticky?num=1">self-promotion</a> thread, mentions of paid services and tools are permitted ü§ù. If you&#39;re new to web scraping, be sure to check out the <a href="https://webscraping.fyi">beginners guide</a> üå±</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/AutoModerator"> /u/AutoModerator </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fnmjua/weekly_discussion_23_s

## PyPasser reCaptchaV3 Token Still Results in Authentication Errors
 - [https://www.reddit.com/r/webscraping/comments/1fne28u/pypasser_recaptchav3_token_still_results_in](https://www.reddit.com/r/webscraping/comments/1fne28u/pypasser_recaptchav3_token_still_results_in)
 - RSS feed: $source
 - date published: 2024-09-23T06:29:16+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;m trying to authenticate with a website using Python&#39;s requests library, and the site uses reCAPTCHA v3 for login. I attempted to use the pypasser library to generate a valid reCAPTCHA token, but I keep receiving a 401 Unauthorized error when making the POST request.</p> <p>Here‚Äôs my code:</p> <pre><code>import requests from pypasser import reCaptchaV3 headers = { &quot;Accept&quot;: &quot;application/json, text/plain, */*&quot;, &quot;Accept-Language&quot;: &quot;en-US,en;q=0.9&quot;, &quot;Authorization&quot;: &quot;&quot;, &quot;Connection&quot;: &quot;keep-alive&quot;, &quot;Content-Type&quot;: &quot;application/json;charset=UTF-8&quot;, &quot;DNT&quot;: &quot;1&quot;, &quot;Origin&quot;: &quot;https://public.txdpsscheduler.com&quot;, &quot;Referer&quot;: &quot;https://public.txdpsscheduler.com/&quot;, &quot;Sec-Fetch-Dest&quot;: &quot;empty&quot;, &quot;Sec-Fetch-Mode&quot;: &quot;cors&quot;, &quot;Sec-Fetch-Site&quot;: &quot;same-site&

## How do i get started with a webcrawler for a specific task
 - [https://www.reddit.com/r/webscraping/comments/1fna11g/how_do_i_get_started_with_a_webcrawler_for_a](https://www.reddit.com/r/webscraping/comments/1fna11g/how_do_i_get_started_with_a_webcrawler_for_a)
 - RSS feed: $source
 - date published: 2024-09-23T02:17:33+00:00

<!-- SC_OFF --><div class="md"><p>Hi All, </p> <p>Looking for advice to be pointed in the right direction.</p> <p>This is for a side project for a client. </p> <p>From understanding the client&#39;s end goal; </p> <p>I would need to create a web crawler to crawl and scrape newly registered domain with a specific ccTLD</p> <p>Any idea how i can get started with this?</p> <p>From what i have planned and understand, </p> <p>i would need to create a crawler that goes out every couple of days to &quot;find&quot; newly created domain with a specfic ccTLD. </p> <p>Check if a website exist, </p> <p>If website exist</p> <p>Crawl the site</p> <p>if relevant content exist, </p> <p>scrape site</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/ChmodPlusEx"> /u/ChmodPlusEx </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fna11g/how_do_i_get_started_with_a_webcrawler_for_a/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/w

## Web scraping a sports website
 - [https://www.reddit.com/r/webscraping/comments/1fn9myb/web_scraping_a_sports_website](https://www.reddit.com/r/webscraping/comments/1fn9myb/web_scraping_a_sports_website)
 - RSS feed: $source
 - date published: 2024-09-23T01:56:52+00:00

<!-- SC_OFF --><div class="md"><p>Hey all, new to the community. I am currently locally scraping a sports website. I am avoiding rate limiting by sleeping often enough. Also I am using a VPN just incase. I‚Äôm sorry that this question gets asked a billion times, but can I get in any legal trouble? All the data is public and doesn‚Äôt need any sort of account. You can imagine box scores on ESPN for football is what I‚Äôm scraping. No scraping of images or logos, just stats. Thanks in advance for your help. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/ilikedogs4ever"> /u/ilikedogs4ever </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fn9myb/web_scraping_a_sports_website/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1fn9myb/web_scraping_a_sports_website/">[comments]</a></span>

## Scraping data I paid for?
 - [https://www.reddit.com/r/webscraping/comments/1fn7r91/scraping_data_i_paid_for](https://www.reddit.com/r/webscraping/comments/1fn7r91/scraping_data_i_paid_for)
 - RSS feed: $source
 - date published: 2024-09-23T00:19:26+00:00

<!-- SC_OFF --><div class="md"><p>I think I&#39;m in trouble. Scraped Daily Fantasy Sports data using my subscription to a site. I did not try to hide this. I used my own email and login. I only wanted to use this data for my own personal use. I wanted to analyze it in a way the website was not capable of. I am pretty sure the website is about to sue me based on their social media account.</p> <p>What type of punishments can I be looking at?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/yocamyo"> /u/yocamyo </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fn7r91/scraping_data_i_paid_for/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1fn7r91/scraping_data_i_paid_for/">[comments]</a></span>

## Does executing driver javascript make bot detectable?
 - [https://www.reddit.com/r/webscraping/comments/1fn7lky/does_executing_driver_javascript_make_bot](https://www.reddit.com/r/webscraping/comments/1fn7lky/does_executing_driver_javascript_make_bot)
 - RSS feed: $source
 - date published: 2024-09-23T00:11:35+00:00

<!-- SC_OFF --><div class="md"><p>I have a good undetected browser setup (passes CDP checks etc) but the website I want to scrape requires interactions with elements hidden under #shadow-root; of course I can retrieve them with driver.execute_script(&quot;return arguments[0].shadowRoot&quot;) but does this make the browser detectable as bot?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Plastic-Pattern-8993"> /u/Plastic-Pattern-8993 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1fn7lky/does_executing_driver_javascript_make_bot/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1fn7lky/does_executing_driver_javascript_make_bot/">[comments]</a></span>

