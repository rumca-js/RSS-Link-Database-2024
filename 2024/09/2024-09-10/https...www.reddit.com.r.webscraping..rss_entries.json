[{"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-10T22:46:21+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m just starting my coding journey and being able to scrape websites is a milestone I\u2019m looking to hit. Say I consistently put in a few hours a day on coding courses, practice etc, how long would it take before realistically I\u2019d be able to code my own scrapers? How advanced is it?</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/3leavclova\"> /u/3leavclova </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fdv6pc/how_long_will_it_take_to_learn_how_to/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fdv6pc/how_long_will_it_take_to_learn_how_to/\">[comments]</a></span>", "id": 1121367, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fdv6pc/how_long_will_it_take_to_learn_how_to", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "How long will it take to learn how to proficiently write scraping code from zero coding experience", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-10T22:09:47+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Is it possible to search conditioner products with the active ingridient &quot;amodimethicone&quot; on the website Sephora for example, since their own filters dont include that?</p> <p>I dont mean &quot;amodimethicone site:sephora.com&quot; on google, but within this sub url path: <a href=\"https://www.sephora.com/shop/conditioner-hair\">https://www.sephora.com/shop/conditioner-hair</a></p> <p>So i just get Conditioner results. If yes, where could I start? </p> <p>I just read about webscraping so im pretty much a noob Thank you</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Medizin7\"> /u/Medizin7 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fdudwx/seaeching_for_ingridients_within_a_website/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fdudwx/seaeching_for_ingridients_within_a_website/\">[comments]</a></span>", "id": 1121368, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fdudwx/seaeching_for_ingridients_within_a_website", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Seaeching for Ingridients within a Website", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-10T20:46:18+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I am trying to scrape a website that has APIs. One of the API gives json only if we are logged in.<br/> I got logged in cookies and then send requests, I am successfully sending the request.</p> <p>But the problem is that, those cookies expire after some time and I have to get new cookies to send the request. </p> <p>Is there a way, that I can get fresh cookies automatically before scraping the website?</p> <p>Note: I read somewhere that we can login manually using selenium and save cookies. These cookies are then used for scraping. But I do not know how to get cookies from selenium and use them for request library.</p> <p>Can you help me out? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Shot-Craft-650\"> /u/Shot-Craft-650 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fdsfzt/how_to_get_new_cookies_everytime_from_a_password/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.c", "id": 1120651, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fdsfzt/how_to_get_new_cookies_everytime_from_a_password", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "How to get new cookies everytime from a password protected website?", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-10T19:37:44+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m flustered because I\u2019m using Bruno to replicate the request that is being made from my browser to Amazon.com (with the proper headers) and it works completely fine. </p> <p>Yet, when I use the exact same headers in an axios request, I\u2019m getting blocked. Is it possible the axios library is triggering something on the server to block my request? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Substantial_Sock5427\"> /u/Substantial_Sock5427 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fdqs1u/bruno_works_axios_doesnt_with_the_same_exact/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fdqs1u/bruno_works_axios_doesnt_with_the_same_exact/\">[comments]</a></span>", "id": 1120394, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fdqs1u/bruno_works_axios_doesnt_with_the_same_exact", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Bruno works, Axios doesn\u2019t with the same exact headers.", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-10T17:46:31+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello fellow Scrapers!</p> <p>I have been \u201cScraping\u201d for about 6 years on almost a daily basis on side projects/business , getting down to the nitty gritty of web sites/ antibody. I have stumbled across a Senior Web Scraping position which seems to be perfect. I have had the first interview which went well but I am expecting a panel interview soon. Problem is I feel like I won\u2019t perform well under pressure \ud83d\ude02\ud83d\ude02. Ex. Drawing a blank on when to use soup.find vs. soup.findAll \ud83d\ude02\ud83d\ude02\ud83d\ude02. </p> <p>My question is for Seniors. What was your panel/code interview like? Is there anything that I should be aware of or study before the big day? Any advice . Feel free to share </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/friday305\"> /u/friday305 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fdo1n1/calling_all_senior_web_scrapers/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping", "id": 1119926, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fdo1n1/calling_all_senior_web_scrapers", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Calling All Senior Web Scrapers", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-10T15:26:07+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I am new to programming but have had some success &quot;developing&quot; web applications using AI coding assistants like Cursor and generating code with Claude and other LLMs. </p> <p>I&#39;ve made something like an RSS aggregation tool that lets you classify items into defined folders. I&#39;d like to expand on the functionality by adding the ability to scrape the content behind links and then using an LLM API to generate a summary of the content within a folder. If some items are paywalled, nothing useful wil be scraped, but I assume that the AI can be prompted to disregard useless files. </p> <p>I&#39;ve never learned python or attempted projects like this. Just trying to get some perspective on how difficult it will be. Is there any hope of getting there with AI guidance and assisted coding? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Mountain_Candle_8693\"> /u/Mountain_Candle_8693 </a> <br/> <span><a hr", "id": 1118803, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fdklec/scraping_and_ai_solution", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Scraping and AI solution", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-10T14:22:47+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey guys! I need to scrap all the data behind a web embedded Power Bi like this one:</p> <p><a href=\"https://app.powerbi.com/view?r=eyJrIjoiZTJkNDNiNWQtNDY2ZC00ZWRhLWI5MTUtMDc5NmE2ZDY5M2RjIiwidCI6ImRhMDU0NzFhLWJiMTEtNDEzMi1iOTRkLWMwMjM3NWQyYTQxYSIsImMiOjR9\">https://app.powerbi.com/view?r=eyJrIjoiZTJkNDNiNWQtNDY2ZC00ZWRhLWI5MTUtMDc5NmE2ZDY5M2RjIiwidCI6ImRhMDU0NzFhLWJiMTEtNDEzMi1iOTRkLWMwMjM3NWQyYTQxYSIsImMiOjR9</a></p> <p>Is there any way to do it? I know selenium, regular expressions and XPath.</p> <p>Cheers</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Sufficient_Hat_1203\"> /u/Sufficient_Hat_1203 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fdj3ch/collect_data_from_a_web_embedded_power_bi/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fdj3ch/collect_data_from_a_web_embedded_power_bi/\">[comments]</a></span>", "id": 1118330, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fdj3ch/collect_data_from_a_web_embedded_power_bi", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Collect data from a web embedded Power Bi", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-10T13:38:29+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>When server receive a request. 1. server sends another request to another server(extract data using httpx). 2. server decodes the response, saves it into DB, and returns that response to the client</p> <p>Is it possible, and how I can manage workers with sync ?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Marioomario01\"> /u/Marioomario01 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fdi3iz/how_i_can_integre_an_async_scraper_into_django_app/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fdi3iz/how_i_can_integre_an_async_scraper_into_django_app/\">[comments]</a></span>", "id": 1117743, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fdi3iz/how_i_can_integre_an_async_scraper_into_django_app", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "How I can integre an async scraper into Django app", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-10T13:26:58+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I am new to webscraping and I am wondering how do I get past the two factor authentication. When I log in it redirects to two factor authentication page and there is no option to disable it. There is an option to remember for 30 days. I would also not mind inputting it some way each time I run my code. Anything helps. Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Realistic-Corgi-6671\"> /u/Realistic-Corgi-6671 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fdhug1/webscraping_with_2fa/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fdhug1/webscraping_with_2fa/\">[comments]</a></span>", "id": 1117744, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fdhug1/webscraping_with_2fa", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Webscraping with 2fa", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-10T12:27:44+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Join the chat: \ud83d\udcc5 <a href=\"https://www.addevent.com/event/eb22748441\">https://www.addevent.com/event/eb22748441</a></p> <p>I wanted to share something exciting with you all. Tomorrow, there is a fireside chat with Shane Evans, the CEO of Zyte!We\u2019ll be discussing the evolution of web scraping tools, the story behind web scraping APIs, and why it\u2019s a good time to rethink our strategies.</p> <p>Got questions or thoughts on web scraping? This is the perfect chance to bring them up!</p> <p>Also, we have a lively discussion going on about web scraping in the Extract Data Community on Discord: <a href=\"https://discord.gg/ASVrp4Mt\">Join the Community</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/lakshayyn\"> /u/lakshayyn </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fdgme4/web_scraping_join_the_discussion/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments", "id": 1117218, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fdgme4/web_scraping_join_the_discussion", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Web Scraping: Join the Discussion", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-10T10:27:16+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi</p> <p>I am using beautifulsoup for webscrapping and I cant extract genres and voting. </p> <p>Title, imdb_rating, year, metascore all these are successful. </p> <p>I am doing this for data analysis project. I want to extract all these details into csv file and use tableau for analysis. Please someone help me with this</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Bloodshot12_\"> /u/Bloodshot12_ </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fdekpc/i_am_trying_to_web_scrape_imdb_website_but_i_cant/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fdekpc/i_am_trying_to_web_scrape_imdb_website_but_i_cant/\">[comments]</a></span>", "id": 1116294, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fdekpc/i_am_trying_to_web_scrape_imdb_website_but_i_cant", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "I am trying to web scrape IMDB website but I cant extract genres, votings", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-10T09:02:16+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone,</p> <p>I\u2019m interested in scraping data from the Google Workspace Marketplace, specifically to get a comprehensive list of Google Sheets add-ons along with their download counts and user ratings. I\u2019ve tried browsing the marketplace and using search terms, but I\u2019m looking for a more systematic way to gather this information.</p> <p><strong>Here\u2019s what I\u2019m aiming to achieve:</strong></p> <ul> <li>Extract a complete list of Google Sheets add-ons.</li> <li>Include details like download numbers and user ratings for each add-on.</li> </ul> <p><strong>Questions:</strong></p> <ol> <li>Has anyone done web scraping for Google Sheets add-ons or similar data? What tools or libraries did you use?</li> <li>Are there any challenges or limitations I should be aware of when scraping data from the Google Workspace Marketplace?</li> <li>Any tips or best practices for scraping such information efficiently and ethically?</li> </ol> <p>I\u2019d appreciate any advice", "id": 1115938, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fdde8i/seeking_advice_on_web_scraping_google_sheets", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Seeking Advice on Web Scraping Google Sheets Add-Ons with Download Counts and Ratings", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-10T05:04:05+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019ve been messing around with axios in an attempt to scrape some product review data, and my script is easily being detected by anti-bot even if I use custom headers that are copied from the browser, including cookies. </p> <p>My question is this then. Code is code. There is definitely a way to mimic the browser using purely axios, but how do sites like postman get it done as I noticed my requests work on there but not in my scripts via node. </p> <p>Any suggestions or references on information to learn more about regarding mimicking the browser using requests, and how to accept cookies perhaps?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Substantial_Sock5427\"> /u/Substantial_Sock5427 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fda5ep/how_do_you_go_about_accepting_cookies_to_mimic/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fda5ep/how_do", "id": 1114972, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fda5ep/how_do_you_go_about_accepting_cookies_to_mimic", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "How do you go about accepting cookies to mimic the browser when making requests?", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-10T03:53:34+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello. I&#39;m seeking help scraping the CA Public Works website: <a href=\"https://www.dir.ca.gov\">https://www.dir.ca.gov</a>. My goal is to see when a project is awarded <a href=\"https://services.dir.ca.gov/gsp?id=dir_projects&amp;table=x_cdoi2_csm_portal_project\">https://services.dir.ca.gov/gsp?id=dir_projects&amp;table=x_cdoi2_csm_portal_project</a> and who the contractor who won the contract is. <a href=\"https://services.dir.ca.gov/gsp?id=dir_contractors&amp;table=x_cdoi2_letf_core_contractor_lookup\">https://services.dir.ca.gov/gsp?id=dir_contractors&amp;table=x_cdoi2_letf_core_contractor_lookup</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ncipolla\"> /u/ncipolla </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fd8zcq/would_someone_be_willing_to_help_me_scrape_the_ca/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fd8zcq/would_someone_be_wi", "id": 1114771, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fd8zcq/would_someone_be_willing_to_help_me_scrape_the_ca", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Would someone be willing to help me scrape the CA public works website?", "user": null, "vote": 0}]