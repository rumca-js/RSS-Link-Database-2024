<!DOCTYPE html><html><head>   <meta>     <title>Hey everyone! I’ve been working on an VLM driven app that processes surveillance videos, automatically extracts frames, and generates detailed annotations to highlight notable events, actions, and objects. It’s powered by a fine-tuned Florence-2 VLM that I specifically trained on the SPHAR dataset</title>   </meta>   <style>
.youtube_player_container {
    position: relative;
    width: 50%;
    padding-bottom: 26.25%;
    /* background-color: yellow; */
}
.youtube_player_frame {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    border: 0;
}
       </style></head><body><a href="index.html"><h2>Index</h2></a><a href="https://www.reddit.com/r/programming/comments/1ffrgkb/hey_everyone_ive_been_working_on_an_vlm_driven"><h1>[1138291] Hey everyone! I’ve been working on an VLM driven app that processes surveillance videos, automatically extracts frames, and generates detailed annotations to highlight notable events, actions, and objects. It’s powered by a fine-tuned Florence-2 VLM that I specifically trained on the SPHAR dataset</h1></a><div>https://www.reddit.com/r/programming/.rss</div><div>2024-09-13 10:32:47+00:00</div><div><pre>  submitted by   <a href="https://www.reddit.com/user/BriefAd4761"> /u/BriefAd4761 </a> <br/> <span><a href="https://github.com/Ravi-Teja-konda/Surveillance_Video_Summarizer">[link]</a></span> <span><a href="https://www.reddit.com/r/programming/comments/1ffrgkb/hey_everyone_ive_been_working_on_an_vlm_driven/">[comments]</a></span></pre></div></body></html>