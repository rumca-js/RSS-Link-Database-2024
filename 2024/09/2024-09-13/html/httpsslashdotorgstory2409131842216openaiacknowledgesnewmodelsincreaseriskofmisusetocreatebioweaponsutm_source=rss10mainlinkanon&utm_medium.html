<!DOCTYPE html><html><head>   <meta>     <title>OpenAI Acknowledges New Models Increase Risk of Misuse To Create Bioweapons</title>   </meta>   <style>
.youtube_player_container {
    position: relative;
    width: 50%;
    padding-bottom: 26.25%;
    /* background-color: yellow; */
}
.youtube_player_frame {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    border: 0;
}
       </style></head><body><a href="index.html"><h2>Index</h2></a><a href="https://slashdot.org/story/24/09/13/1842216/openai-acknowledges-new-models-increase-risk-of-misuse-to-create-bioweapons?utm_source=rss1.0mainlinkanon&utm_medium=feed"><h1>[1141803] OpenAI Acknowledges New Models Increase Risk of Misuse To Create Bioweapons</h1></a><div>https://rss.slashdot.org/Slashdot/slashdotMain</div><div>2024-09-13 20:47:19.277875+00:00</div><div><pre>OpenAI's latest models have "meaningfully" increased the risk that AI will be misused to create biological weapons [non-paywalled link], the company has acknowledged. From a report: The San Francisco-based company announced its new models, known as o1, on Thursday, touting their new abilities to reason, solve hard maths problems and answer scientific research questions. OpenAI's system card, a tool to explain how the AI operates, said the new models had a "medium risk" for issues related to chemical, biological, radiological and nuclear (CBRN) weapons -- the highest risk that OpenAI has ever given for its models. The company said it meant that the technology has "meaningfully improved" the ability of experts to create bioweapons. AI software with more advanced capabilities, such as the ability to perform step-by-step reasoning, pose an increased risk of misuse in the hands of bad actors, according to experts.<p><div>
&lt;a class="slashp</div></p></pre></div></body></html>