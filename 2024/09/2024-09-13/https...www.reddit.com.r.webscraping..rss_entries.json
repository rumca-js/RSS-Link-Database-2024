[{"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-13T22:52:58+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>basicly it would run a local model that can solve capcha without the need of a 3rd party service only a extention and a ai model </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/nekohacker591_\"> /u/nekohacker591_ </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fg7vv3/im_broke_and_want_to_bypass_capcacha_so_wondering/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fg7vv3/im_broke_and_want_to_bypass_capcacha_so_wondering/\">[comments]</a></span>", "id": 1142458, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fg7vv3/im_broke_and_want_to_bypass_capcacha_so_wondering", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "im broke and want to bypass capcacha so wondering if their is a AI capcha i can use localy that is free of charge", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-13T22:41:16+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi Guys,</p> <p>Newbie here.</p> <p>I would like to scrape some specific push notifications from my windows machine. It seems that they are sent by chrome (that&#39;s where i have added them), but they appear in the notification bar on windows. </p> <p>I saw a post about using Linux and Dust but i actually would like to do it with a Windows Machine.</p> <p>Anyone has advises?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Hackinglife1\"> /u/Hackinglife1 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fg7n0x/scraping_push_notifications_from_windows/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fg7n0x/scraping_push_notifications_from_windows/\">[comments]</a></span>", "id": 1142459, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fg7n0x/scraping_push_notifications_from_windows", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Scraping Push Notifications from Windows", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-13T22:11:10+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m working on a project that requires searching across podcast episodes and I&#39;ve been playing with the listen notes API. I recently came across Taddy&#39;s Podcast API and it seems cheaper with fewer restrictions and a richer API. Has anyone actually used this? If so, please share your reasoning for using this over Listen Notes.</p> <p>I&#39;m mainly concerned about the recency and completeness of the data they provide. I&#39;ve tried Podcast Index as well but it looks like they only share links to the RSS feeds of the whole podcasts but I need episode-level searching like ListenNotes provides. Is the only option to use podcast index in this case, to scrape all of the data myself and then run search? </p> <p>Any advice would be appreciated!</p> <p>P.S : my previous post got removed for self-promotion but I promise I am not affiliated with any of these products I just want to choose one to use. Although in hindsight I understand how it looked ", "id": 1142285, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fg6zwq/request_advice_for_scraping_podcast_data", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Request advice for scraping Podcast data", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-13T21:27:43+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Any idea on how to scrape this? I need all the events for November, including details. I am struggling with this. Can somebody please help me? Thank you in advance </p> <p><a href=\"https://tcmupstate.org/greenville/plan-your-visit/calendar/\">https://tcmupstate.org/greenville/plan-your-visit/calendar/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/data_girl23\"> /u/data_girl23 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fg60gt/dynamic_calendar/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fg60gt/dynamic_calendar/\">[comments]</a></span>", "id": 1142286, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fg60gt/dynamic_calendar", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Dynamic Calendar", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-13T19:30:18+00:00", "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1fg3as6/transforming_natural_language_to_sql_a_python/\"> <img src=\"https://preview.redd.it/unc6tjrtomod1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0695380076d4fc759a67fecc9a822138a19e9bc3\" alt=\"\ud83c\udf1f Transforming Natural Language to SQL: A Python Tool Using LLMA3.1 and LangChain \ud83c\udf1f\" title=\"\ud83c\udf1f Transforming Natural Language to SQL: A Python Tool Using LLMA3.1 and LangChain \ud83c\udf1f\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/seotanvirbd\"> /u/seotanvirbd </a> <br/> <span><a href=\"https://i.redd.it/unc6tjrtomod1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fg3as6/transforming_natural_language_to_sql_a_python/\">[comments]</a></span> </td></tr></table>", "id": 1141597, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fg3as6/transforming_natural_language_to_sql_a_python", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 86, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": "https://preview.redd.it/unc6tjrtomod1.png?width=640&crop=smart&auto=webp&s=0695380076d4fc759a67fecc9a822138a19e9bc3", "title": "\ud83c\udf1f Transforming Natural Language to SQL: A Python Tool Using LLMA3.1 and LangChain \ud83c\udf1f", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-13T18:37:01+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Any idea how to scrape this <a href=\"https://maps.saudicensus.sa/arcportal/apps/experiencebuilder/experience/?id=f80f2d4e40e149718461492befc96bf9&amp;page=Population\">https://maps.saudicensus.sa/arcportal/apps/experiencebuilder/experience/?id=f80f2d4e40e149718461492befc96bf9&amp;page=Population</a></p> <p>I just need a start point or key </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PriorityComplete1336\"> /u/PriorityComplete1336 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fg21ab/scrape_maps/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fg21ab/scrape_maps/\">[comments]</a></span>", "id": 1141200, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fg21ab/scrape_maps", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Scrape maps", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-13T18:09:00+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi Redditor\u2019s I\u2019ve recently been asked by a mate if I could make something to help him out with his workload. Would it be possible to scrape multiple websites and all their associated pages for specific key terms and if that term is present to return the URL for the page In which it appears? Any pointers would be appreciated as this seems relatively doable but I\u2019m unsure if I\u2019m missing any potential problems that would prevent this being viable.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ganjamun99\"> /u/Ganjamun99 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fg1dex/we_scraping_for_specific_key_terms/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1fg1dex/we_scraping_for_specific_key_terms/\">[comments]</a></span>", "id": 1141201, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1fg1dex/we_scraping_for_specific_key_terms", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "We scraping for specific key terms", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-13T17:10:28+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>B</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/yoloyolohehaw\"> /u/yoloyolohehaw </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ffzz4m/what_are_the_online_tools_available_to_check_what/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ffzz4m/what_are_the_online_tools_available_to_check_what/\">[comments]</a></span>", "id": 1140907, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1ffzz4m/what_are_the_online_tools_available_to_check_what", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "What are the online tools available to check what anti bot are present in a webpage", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-13T15:55:19+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey all,</p> <p>I&#39;ve been dabbling in some Python and thought a good exercise would be to scrape goodreads, specifically just the first 10 books in the search results of a given keyword, it then displays the relevant information I want it to and whatnot, but, for the life of me, I cannot figure out how to display the first 3 reviews of each individual book and it&#39;s driving me a bit crazy. For reference, I&#39;ll paste the code below, if someone could let me know what I&#39;ve been doing wrong, I would highly appreciate it. </p> <p><strong>Disclaimer</strong>: this has also been posted in <a href=\"/r/learnpython\">r/learnpython</a>, but I haven&#39;t received any input yet. </p> <pre><code>import requests from bs4 import BeautifulSoup import json from datetime import datetime import argparse # This, in theory, extracts the first 3 reviews per book def get_top_reviews(book_url): review_list = [] try: print(f&quot;Fetching reviews from {book_url}.", "id": 1140417, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1ffy735/python_code_thats_supposed_to_scrape_goodreadscom", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Python code that's supposed to scrape goodreads.com, failing 1 aspect, can't figure it out.", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-13T13:52:52+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>trying to check this site turns out its using <a href=\"http://asp.net\">asp.net</a> and the pagination to next page dose not change url and its driving me crazy iam doin basic stuff here using soup and requests </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Snoparino\"> /u/Snoparino </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ffva8t/how_to_scrape_asp_sites/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ffva8t/how_to_scrape_asp_sites/\">[comments]</a></span>", "id": 1139854, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1ffva8t/how_to_scrape_asp_sites", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "How to scrape asp sites ?", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-13T11:50:42+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Scraping grocery store</p> <p>Hello, I built a tool to scrape online grocery stores. I\u2019m saving products details : title, picture. And scraping prices every 2 days to store them in my database.</p> <p>I\u2019m then planning on doing a price comparison website for these products.</p> <p>Do you think my scraping is legal ? Could I get into trouble for it ?</p> <p>Thanks !!</p> <p>Edit : I\u2019m in France and will scrape French website/companies. The grocery stores I\u2019m scraping don\u2019t require login, the informations are public.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/r-obeen\"> /u/r-obeen </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ffsrk4/scraping_grocery_store/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ffsrk4/scraping_grocery_store/\">[comments]</a></span>", "id": 1139030, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1ffsrk4/scraping_grocery_store", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Scraping grocery store", "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-09-13T09:14:38+00:00", "description": "<!-- SC_OFF --><div class=\"md\"><p>Champs!</p> <p>Beginner question: is it illegal to scrape/ crawl public available data (no log-in, no T&amp;C accepted, no IP) and sell it to somebody that requested it? Or buy it from somebody and then resell it?</p> <p>Thanks</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/OleksandrBrasov1990\"> /u/OleksandrBrasov1990 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ffqct5/reselling_web_scraping_data/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1ffqct5/reselling_web_scraping_data/\">[comments]</a></span>", "id": 1138284, "language": null, "link": "https://www.reddit.com/r/webscraping/comments/1ffqct5/reselling_web_scraping_data", "manual_status_code": 0, "page_rating": 27, "page_rating_contents": 85, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.reddit.com/r/webscraping/.rss", "source_obj__id": 467, "status_code": 0, "tags": [], "thumbnail": null, "title": "Reselling web scraping data", "vote": 0}]