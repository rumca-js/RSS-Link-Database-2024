[{"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-05-13T09:00:00+00:00", "description": "<article>\n\t<section class=\"page\">\n<p>\u201cAI models currently shine at helping so-so coders get more stuff done that works in the time they have,\u201d <a href=\"https://twitter.com/DavidShowalter_/status/1788750697376120909\" rel=\"nofollow\">argues</a> engineer David Showalter. But is that right? Showalter was responding to Santiago Valdarrama\u2019s <a href=\"https://twitter.com/svpino/status/1788614944914887023\" rel=\"nofollow\">contention</a> that large language models (LLMs) are untrustworthy coding assistants. Valdarrama says, \u201cUntil LLMs give us the same guarantees [as programming languages, which consistently get computers to respond to commands], they\u2019ll be condemned to be eternal \u2018cool demos,\u2019 useless for most serious applications.\u201d He is correct that LLMs are decidedly inconsistent in how they respond to prompts. The same prompt will yield different LLM responses. And Showalter is quite possibly incorrect: AI models may \u201cshine\u201d at helping average developers generate <em>more</em> code, but tha", "language": "en-us", "link": "https://www.infoworld.com/article/3715462/ai-coding-tools-are-your-interns-not-your-replacement.html#tk.rss_all", "manual_status_code": 0, "page_rating": 32, "page_rating_contents": 100, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "http://www.infoworld.com/index.rss", "source_obj__id": 151, "status_code": 0, "tags": [], "thumbnail": "https://images.idgesg.net/images/idge/imported/imageapi/2023/08/08/13/shutterstock_1901618698-100936241-small-100944432-small.jpg", "title": "AI coding tools are your interns, not your replacement", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-05-13T09:00:00+00:00", "description": "<article>\n\t<section class=\"page\">\n<p>Back in 2014, when the wave of containers, Kubernetes, and distributed computing was breaking over the technology industry, Torkel \u00d6degaard was working as a platform engineer at eBay Sweden. Like other <a href=\"https://www.infoworld.com/article/3215275/what-is-devops-transforming-software-development.html\">devops</a> pioneers, \u00d6degaard was grappling with the new form factor of microservices and containers and struggling to climb the steep Kubernetes operations and troubleshooting learning curve.\u00a0</p><p>As an engineer striving to make <a href=\"https://www.infoworld.com/article/3271126/what-is-cicd-continuous-integration-and-continuous-delivery-explained.html\">continuous delivery</a> both safe and easy for developers, \u00d6degaard needed a way to visualize the production state of the Kubernetes system and the behavior of users.\u00a0Unfortunately, there was no specific playbook for how to extract, aggregate, and visualize the telemetry data from these systems", "language": "en-us", "link": "https://www.infoworld.com/article/3715402/grafana-shining-a-light-into-kubernetes-clusters.html#tk.rss_all", "manual_status_code": 0, "page_rating": 32, "page_rating_contents": 100, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "http://www.infoworld.com/index.rss", "source_obj__id": 151, "status_code": 0, "tags": [], "thumbnail": "https://images.idgesg.net/images/article/2024/03/shutterstock_987349-100962352-small.jpg", "title": "Grafana: Shining a light into Kubernetes clusters", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-05-13T09:00:00+00:00", "description": "<article>\n\t<section class=\"page\">\n<p>Back in the ancient days of <a href=\"https://www.infoworld.com/article/3214424/what-is-machine-learning-intelligence-derived-from-data.html\">machine learning</a>, before you could use <a href=\"https://www.infoworld.com/article/3709489/large-language-models-the-foundations-of-generative-ai.html\">large language models</a> (LLMs) as foundations for tuned models, you essentially had to train every possible machine learning model on all of your data to find the best (or least bad) fit. By ancient, I mean prior to the seminal paper on the transformer neural network architecture, \u201c<a href=\"https://dl.acm.org/doi/10.5555/3295222.3295349\" rel=\"nofollow\">Attention is all you need</a>,\u201d in 2017.</p><p class=\"jumpTag\"><a href=\"/article/3715396/understanding-the-generative-ai-development-process.html#jump\">To read this article in full, please click here</a></p></section></article>", "language": "en-us", "link": "https://www.infoworld.com/article/3715396/understanding-the-generative-ai-development-process.html#tk.rss_all", "manual_status_code": 0, "page_rating": 32, "page_rating_contents": 100, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "http://www.infoworld.com/index.rss", "source_obj__id": 151, "status_code": 0, "tags": [], "thumbnail": "https://images.idgesg.net/images/article/2024/04/shutterstock_424982974-100963100-small.jpg", "title": "Understanding the generative AI development process", "user": null, "vote": 0}]