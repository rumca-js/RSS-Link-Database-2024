[{"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-05-13T21:00:41+00:00", "description": "<p><a href=\"https://llm.datasette.io/en/stable/changelog.html#v0-14\">LLM 0.14, with support for GPT-4o</a></p>\nIt's been a while since the last LLM release. This one adds support for OpenAI's new model:</p>\n<pre><code>llm -m gpt-4o \"fascinate me\"\n</code></pre>\n<p>Also a new <code>llm logs -r</code> (or <code>--response</code>) option for getting back just the response from your last prompt, without wrapping it in Markdown that includes the prompt.</p>\n<p>Plus nine new <a href=\"https://llm.datasette.io/en/stable/plugins/directory.html\">plugins</a> since 0.13!", "language": "en-us", "link": "https://simonwillison.net/2024/May/13/llm-014/#atom-everything", "manual_status_code": 0, "page_rating": 32, "page_rating_contents": 100, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://simonwillison.net/atom/everything", "source_obj__id": 423, "status_code": 0, "tags": [], "thumbnail": null, "title": "LLM 0.14, with support for GPT-4o", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-05-13T19:09:49+00:00", "description": "<p><a href=\"https://openai.com/index/hello-gpt-4o/\">Hello GPT-4o</a></p>\nOpenAI announced a new model today: GPT-4o, where the o stands for \"omni\".</p>\n<p>It looks like this is the <code>gpt2-chatbot</code> we've been <a href=\"https://simonwillison.net/2024/May/8/gpt2-chatbot-confirmed-as-openai/\">seeing in the Chat Arena</a> the past few weeks.</p>\n<p>GPT-4o doesn't seem to be a huge leap ahead of GPT-4 in terms of \"intelligence\" - whatever that might mean - but it has a bunch of interesting new characteristics.</p>\n<p>First, it's multi-modal across text, images and audio as well. The audio demos from this morning's launch were extremely impressive.</p>\n<p>ChatGPT's previous voice mode worked by passing audio through a speech-to-text model, then an LLM, then a text-to-speech for the output. GPT-4o does everything with the one model, reducing latency to the point where it can act as a live interpreter between people speaking in two different languages. It also has the ability to inter", "language": "en-us", "link": "https://simonwillison.net/2024/May/13/gpt-4o/#atom-everything", "manual_status_code": 0, "page_rating": 32, "page_rating_contents": 100, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://simonwillison.net/atom/everything", "source_obj__id": 423, "status_code": 0, "tags": [], "thumbnail": null, "title": "Hello GPT-4o", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-05-13T14:35:56+00:00", "description": "<blockquote cite=\"https://www.timpaul.co.uk/posts/using-ai-to-generate-web-forms-from-pdfs/\"><p>I\u2019m no developer, but I got the AI part working in about an hour.<br /><br />What took longer was the other stuff: identifying the problem, designing and building the UI, setting up the templating, routes and data architecture.<br /><br />It reminded me that, in order to capitalise on the potential of AI technologies, we need to really invest in the other stuff too, especially data infrastructure.<br /><br />It would be ironic, and a huge shame, if AI hype sucked all the investment out of those things.</p></blockquote><p class=\"cite\">&mdash; <a href=\"https://www.timpaul.co.uk/posts/using-ai-to-generate-web-forms-from-pdfs/\">Tim Paul</a>", "language": "en-us", "link": "https://simonwillison.net/2024/May/13/tim-paul/#atom-everything", "manual_status_code": 0, "page_rating": 32, "page_rating_contents": 100, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://simonwillison.net/atom/everything", "source_obj__id": 423, "status_code": 0, "tags": [], "thumbnail": null, "title": "Quoting Tim Paul", "user": null, "vote": 0}, {"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-05-13T04:08:46+00:00", "description": "<p><a href=\"https://hazyresearch.stanford.edu/blog/2024-05-12-tk\">GPUs Go Brrr</a></p>\nFascinating, detailed low-level notes on how to get the most out of NVIDIA's H100 GPUs (currently selling for around $40,000 a piece) from the research team at Stanford who created FlashAttention, among other things.</p>\n<blockquote>\n<p>The swizzled memory layouts are flat-out incorrectly documented, which took considerable time for us to figure out.</p>\n</blockquote>\n\n    <p>Via <a href=\"https://news.ycombinator.com/item?id=40337936\">Hacker News</a></p>", "language": "en-us", "link": "https://simonwillison.net/2024/May/13/gpus-go-brrr/#atom-everything", "manual_status_code": 0, "page_rating": 32, "page_rating_contents": 100, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://simonwillison.net/atom/everything", "source_obj__id": 423, "status_code": 0, "tags": [], "thumbnail": null, "title": "GPUs Go Brrr", "user": null, "vote": 0}]