[{"age": null, "album": "", "artist": null, "bookmarked": false, "comments": [], "date_published": "2024-05-30T11:00:42+00:00", "description": "Get the guide to cybersecurity in the GAI era \u2192 https://ibm.biz/BdmJg3\nLearn more about cybersecurity for AI \u2192  https://ibm.biz/BdmJgk\n\nWondering how chatbots can be hacked? In this video, IBM Distinguished Engineer and Adjunct Professor Jeff Crume explains the risks of large language models and how prompt injections can exploit AI systems, posing significant cybersecurity threats. Find out how organizations can protect against such attacks and ensure the integrity of their AI systems.\n\nGet the latest on the evolving threat landscape \u2192 https://ibm.biz/BdmJg6", "language": null, "link": "https://www.youtube.com/watch?v=jrHRe9lSqqA", "manual_status_code": 0, "page_rating": 32, "page_rating_contents": 100, "page_rating_visits": 0, "page_rating_votes": 0, "permanent": false, "source": "https://www.youtube.com/feeds/videos.xml?channel_id=UCKWaEZ-_VweaEx1j62do_vQ", "source_obj__id": 432, "status_code": 0, "tags": [], "thumbnail": "https://i3.ytimg.com/vi/jrHRe9lSqqA/hqdefault.jpg", "title": "What Is a Prompt Injection Attack?", "user": null, "vote": 0}]