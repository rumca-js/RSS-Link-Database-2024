# Source:InfoWorld, URL:http://www.infoworld.com/index.rss, language:en-us

## OpenAI unveils specs for desired AI model behavior
 - [https://www.infoworld.com/article/3715399/openai-unveils-specs-for-desired-ai-model-behavior.html#tk.rss_all](https://www.infoworld.com/article/3715399/openai-unveils-specs-for-desired-ai-model-behavior.html#tk.rss_all)
 - RSS feed: http://www.infoworld.com/index.rss
 - date published: 2024-05-09T22:30:00+00:00

<article>
	<section class="page">
<p>In a bid to “deepen the public conversation about how AI models should behave,” AI company OpenAI has introduced Model Spec, a document that shares the company’s approach to shaping desired model behavior.</p><p><a href="https://cdn.openai.com/spec/model-spec-2024-05-08.html" rel="nofollow">Model Spec</a>, now in a first draft, was <a href="https://openai.com/index/introducing-the-model-spec/" rel="nofollow">introduced May 8</a>. The document specifies OpenAI’s approach to shaping desired model behavior and how the company evaluates trade-offs when conflicts arise. The approach includes objectives, rules, and default behaviors that will guide OpenAI’s researchers and AI trainers who work on reinforcement learning from human feedback (RLHF). The company will also explore how much its models can learn directly from the Model Spec.</p><p class="jumpTag"><a href="/article/3715399/openai-unveils-specs-for-desired-ai-model-behavior.html#jump">To read thi

## GitHub takes aim at software supply chain security
 - [https://www.infoworld.com/article/3715460/github-takes-aim-at-software-supply-chain-security.html#tk.rss_all](https://www.infoworld.com/article/3715460/github-takes-aim-at-software-supply-chain-security.html#tk.rss_all)
 - RSS feed: http://www.infoworld.com/index.rss
 - date published: 2024-05-09T17:30:00+00:00

<article>
	<section class="page">
<p>GitHub has introduced Artifact Attestations, a software signing and verification feature based on <a href="https://www.infoworld.com/article/3696209/sigstore-roots-of-trust-for-software-artifacts.html">Sigstore</a> that protects the integrity of software builds in <a href="https://www.infoworld.com/article/3698188/what-is-github-actions-automated-cicd-for-github.html">GitHub Actions</a> workflows. Artifiact Attestations is now available in a public beta.</p><p><a href="https://github.blog/2024-05-02-introducing-artifact-attestations-now-in-public-beta/" rel="nofollow">Announced May 2</a>, Artifact Attestations allows project maintainers to create a “tamper-proof, unforgeable paper trail” that links software artifacts to the process that created them. “Downstream consumers of this metadata can use it as a foundation for new security and validity checks through policy evaluations via tools like <a href="https://www.openpolicyagent.org/docs/latest/pol

## Highlights from the Django Developer Survey 2024
 - [https://www.infoworld.com/article/3715395/highlights-from-the-django-developer-survey-2024.html#tk.rss_all](https://www.infoworld.com/article/3715395/highlights-from-the-django-developer-survey-2024.html#tk.rss_all)
 - RSS feed: http://www.infoworld.com/index.rss
 - date published: 2024-05-09T09:00:00+00:00

<article>
	<section class="page">
<p>Django has been a <a href="https://www.infoworld.com/article/3600191/5-big-and-powerful-python-web-frameworks.html">leading “batteries included” Python web framework</a> for more than a decade. The fifth major release, which arrived in December, brought even <a href="https://www.infoworld.com/article/3711367/5-great-new-features-in-django-5.html">more power and ease to Django</a>.</p><p>Curious about the latest Django development trends? JetBrains’ PyCharm team, in collaboration with the Django Foundation, surveyed over 4,000 developers worldwide to analyze framework usage. Here’s what we found:</p><ul>
<li>Django remains the top pick for 74% of developers.</li>
<li>One in three Django developers also uses <a href="https://www.infoworld.com/article/3619522/get-started-with-flask-30.html">Flask</a> or <a href="https://www.infoworld.com/article/3629409/get-started-with-fastapi.html">FastAPI</a>.</li>
<li>Django is commonly used for full-stack and API

## Protecting LLM applications with Azure AI Content Safety
 - [https://www.infoworld.com/article/3715305/protecting-llm-applications-with-azure-ai-content-safety.html#tk.rss_all](https://www.infoworld.com/article/3715305/protecting-llm-applications-with-azure-ai-content-safety.html#tk.rss_all)
 - RSS feed: http://www.infoworld.com/index.rss
 - date published: 2024-05-09T09:00:00+00:00

<article>
	<section class="page">
<p>Both extremely promising and extremely risky, <a href="https://www.infoworld.com/article/3689973/what-is-generative-ai-artificial-intelligence-that-creates.html">generative AI</a> has distinct failure modes that we need to defend against to protect our users and our code. We’ve all seen the news, where chatbots are encouraged to be insulting or racist, or <a href="https://www.infoworld.com/article/3709489/large-language-models-the-foundations-of-generative-ai.html">large language models</a> (LLMs) are exploited for malicious purposes, and where outputs are at best fanciful and at worst dangerous.</p><p>None of this is particularly surprising. It’s possible to craft complex prompts that force undesired outputs, pushing the input window past the guidelines and guardrails we’re using. At the same time, we can see outputs that go beyond the data in the foundation model, generating text that’s no longer grounded in reality, producing plausible, semantic

