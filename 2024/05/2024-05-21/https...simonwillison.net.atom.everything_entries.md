# Source:Simon Willison's Weblog, URL:https://simonwillison.net/atom/everything, language:en-us

## New Phi-3 models: small, medium and vision
 - [https://simonwillison.net/2024/May/21/phi-3-models-small-medium-and-vision/#atom-everything](https://simonwillison.net/2024/May/21/phi-3-models-small-medium-and-vision/#atom-everything)
 - RSS feed: https://simonwillison.net/atom/everything
 - date published: 2024-05-21T20:04:30+00:00

<p><a href="https://www.reddit.com/r/LocalLLaMA/comments/1cxa6w5/phi3_small_medium_are_now_available_under_the_mit/">New Phi-3 models: small, medium and vision</a></p>
I couldn't find a good official announcement post to link to about these three newly released models, but this post on LocalLLaMA on Reddit has them in one place: Phi-3 small (7B), Phi-3 medium (14B) and Phi-3 vision (4.2B) (the previously released model was Phi-3 mini - 3.8B).</p>
<p>You can try out the <a href="https://ai.azure.com/explore/models/Phi-3-vision-128k-instruct/version/1/registry/azureml">vision model directly here</a>, no login required. It didn't do <a href="https://twitter.com/simonw/status/1793009034863260035">a great job</a> with my first test image though, hallucinating the text.</p>
<p>As with Mini these are all released under an MIT license.</p>
<p>UPDATE: Here's <a href="https://github.com/microsoft/Phi-3CookBook/blob/main/md/01.Introduce/Phi3Family.md">a page from the newly published Phi-3 Cookbo

## Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet
 - [https://simonwillison.net/2024/May/21/scaling-monosemanticity-extracting-interpretable-features-from-c/#atom-everything](https://simonwillison.net/2024/May/21/scaling-monosemanticity-extracting-interpretable-features-from-c/#atom-everything)
 - RSS feed: https://simonwillison.net/atom/everything
 - date published: 2024-05-21T18:25:40+00:00

<p><a href="https://transformer-circuits.pub/2024/scaling-monosemanticity/#safety-relevant-sycophancy">Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet</a></p>
Big advances in the field of LLM interpretability from Anthropic, who managed to extract millions of understandable features from their production Claude 3 Sonnet model (the mid-point between the inexpensive Haiku and the GPT-4-class Opus).</p>
<p>Some delightful snippets in here such as this one:</p>
<blockquote>
<p>We also find a variety of features related to sycophancy, such as an empathy / “yeah, me too” feature 34M/19922975, a sycophantic praise feature 1M/847723, and a sarcastic praise feature 34M/19415708.</p>
</blockquote>

    <p>Via <a href="https://news.ycombinator.com/item?id=40429540">Hacker News</a></p>

