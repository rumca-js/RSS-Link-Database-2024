# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## NBA Betting Prediction Model
 - [https://www.reddit.com/r/webscraping/comments/1hhc0hr/nba_betting_prediction_model](https://www.reddit.com/r/webscraping/comments/1hhc0hr/nba_betting_prediction_model)
 - RSS feed: $source
 - date published: 2024-12-18T21:15:59+00:00

<!-- SC_OFF --><div class="md"><p><strong>Hello! ï¿½</strong>ï¿½</p> <p>I&#39;ve been working on a script to help me analyze NBA stats for sports bets and research. My goal is to build a strong foundation using <strong>Python</strong> and tools like the <code>nba_api</code> library. For context, I use data apps like <strong>Hall of Fame Bets</strong> and <strong>Outlier Pro</strong>, but I wanted to create something of my own to start learning scripting and stat analysis.</p> <p>The script fetches player game logs, projects key averages (Points, Rebounds, Assists, etc.), and exports the results to a CSV file. It even supports partial player name searches (like &#39;Tatum&#39; for Jayson Tatum).</p> <h1>ðŸ”§ What Iâ€™ve Done So Far:</h1> <ol> <li>Fetch NBA player stats using the <code>nba_api</code> library.</li> <li>Calculate stat projections based on user-specified recent games (default = last 5).</li> <li>Export results to a CSV file for further analysis.</li> </ol> <h1>ðŸš€ Whatâ€™s Next?</h1> 

## Seeking Reliable Free IP Sources and Proxy Check Tools
 - [https://www.reddit.com/r/webscraping/comments/1hhbrae/seeking_reliable_free_ip_sources_and_proxy_check](https://www.reddit.com/r/webscraping/comments/1hhbrae/seeking_reliable_free_ip_sources_and_proxy_check)
 - RSS feed: $source
 - date published: 2024-12-18T21:04:54+00:00

<!-- SC_OFF --><div class="md"><p>Need help with a project - looking for a good source of free IPs for testing. Also, need a reliable site to check if these proxies are active and not CAPTCHA-blocked by Google. Any recommendations? Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Yabadabado2319"> /u/Yabadabado2319 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hhbrae/seeking_reliable_free_ip_sources_and_proxy_check/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hhbrae/seeking_reliable_free_ip_sources_and_proxy_check/">[comments]</a></span>

## Need a webscraping tool to scrape company details from a website.
 - [https://www.reddit.com/r/webscraping/comments/1hhamec/need_a_webscraping_tool_to_scrape_company_details](https://www.reddit.com/r/webscraping/comments/1hhamec/need_a_webscraping_tool_to_scrape_company_details)
 - RSS feed: $source
 - date published: 2024-12-18T20:15:42+00:00

<!-- SC_OFF --><div class="md"><p>Hello all. I have a task that requires me to extract 2500+ company details from a website. The said website lists company names and shows the details only when you click on them. Also it consists of 90 pages. I tried using a desktop app with a pagination feature but couldn&#39;t figure it out. Any advice is much appreciated.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/mformero"> /u/mformero </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hhamec/need_a_webscraping_tool_to_scrape_company_details/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hhamec/need_a_webscraping_tool_to_scrape_company_details/">[comments]</a></span>

## Browsing the web with AI - Perplexity vs Copilot vs AI agents
 - [https://www.reddit.com/r/webscraping/comments/1hhajjh/browsing_the_web_with_ai_perplexity_vs_copilot_vs](https://www.reddit.com/r/webscraping/comments/1hhajjh/browsing_the_web_with_ai_perplexity_vs_copilot_vs)
 - RSS feed: $source
 - date published: 2024-12-18T20:12:15+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;m diving head first into AI agents to browse the web and I realized I need a consistent benchmark to measure results.</p> <p>So this is part of a series of small tests where we start with a query and compare how different tools provide results.</p> <p>The tools I chose to compare (not exhaustive):</p> <ul> <li><a href="https://www.perplexity.ai/">Perplexity</a> - an LLM search-engine with up-to-date data from the web <ul> <li><a href="https://www.google.com/">Google AI Overview</a> discarded because it&#39;s hard to reproduce results</li> </ul></li> <li><a href="https://copilot.microsoft.com/">Copilot</a> - LLM with internet connection (similar to ChatGPT with browsing enabled)</li> <li>AI Agents <ul> <li>There&#39;s a few options but I will use something like OneQuery as an example </li> </ul></li> </ul> <p>To keep things consistent, I&#39;m going to paste the raw results from these tools.</p> <h1>1) Task</h1> <pre><code>Find two issues open o

## Get all NCAA athletes?
 - [https://www.reddit.com/r/webscraping/comments/1hh8758/get_all_ncaa_athletes](https://www.reddit.com/r/webscraping/comments/1hh8758/get_all_ncaa_athletes)
 - RSS feed: $source
 - date published: 2024-12-18T18:32:07+00:00

<!-- SC_OFF --><div class="md"><p>Is there a site where you can scrape all NCAA athletes? I found the NCAA directory, but that only lists the schools, not the athletes themselves</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/themasterofbation"> /u/themasterofbation </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hh8758/get_all_ncaa_athletes/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hh8758/get_all_ncaa_athletes/">[comments]</a></span>

## noob webscraper trying to extract some data from a website
 - [https://www.reddit.com/r/webscraping/comments/1hh5sse/noob_webscraper_trying_to_extract_some_data_from](https://www.reddit.com/r/webscraping/comments/1hh5sse/noob_webscraper_trying_to_extract_some_data_from)
 - RSS feed: $source
 - date published: 2024-12-18T16:48:46+00:00

<!-- SC_OFF --><div class="md"><p><a href="https://www.noon.com/uae-en/sports-and-outdoors/exercise-and-fitness/yoga-16328/">https://www.noon.com/uae-en/sports-and-outdoors/exercise-and-fitness/yoga-16328/</a></p> <p>this is the exact link that im trying to extract the data from .</p> <p>I&#39;m using beautiful soup for extraction of data . I&#39;ve tried going using the beautiful soup html parser but well its not really working for this website . i tried sorting them using the tag product box but well that didnt work either . I&#39;m kinda new to web scraping .</p> <p>thank you for you help :)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/TheBlade1029"> /u/TheBlade1029 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hh5sse/noob_webscraper_trying_to_extract_some_data_from/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hh5sse/noob_webscraper_trying_to_extract_some_data_from/">[co

## How can I determine the purpose of the site I'm on?
 - [https://www.reddit.com/r/webscraping/comments/1hh3euv/how_can_i_determine_the_purpose_of_the_site_im_on](https://www.reddit.com/r/webscraping/comments/1hh3euv/how_can_i_determine_the_purpose_of_the_site_im_on)
 - RSS feed: $source
 - date published: 2024-12-18T15:00:52+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;ve been using requests and beautifulsoup to webscrape but im open to using other tools. I&#39;m trying to figure out the best way to determine what the purpose of a site im on is e.g.</p> <p>job listing<br/> social media post<br/> blog post<br/> news article</p> <p>etc</p> <p>i tried taking the text from the site and giving it to an llm and giving it a set of 2-4 classes to choose from but it was pretty bad at classifying. any good way of doing this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/boringblobking"> /u/boringblobking </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hh3euv/how_can_i_determine_the_purpose_of_the_site_im_on/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hh3euv/how_can_i_determine_the_purpose_of_the_site_im_on/">[comments]</a></span>

## Browsing the web with AI - Perplexity vs Copilot vs AI agents
 - [https://www.reddit.com/r/webscraping/comments/1hh1yzd/browsing_the_web_with_ai_perplexity_vs_copilot_vs](https://www.reddit.com/r/webscraping/comments/1hh1yzd/browsing_the_web_with_ai_perplexity_vs_copilot_vs)
 - RSS feed: $source
 - date published: 2024-12-18T13:49:49+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;m diving head first into AI agents to browse the web and I realized I need a consistent benchmark to measure results.</p> <p>So this is part of a series of small tests where we start with a query and compare how different tools provide results.</p> <p>The tools I chose to compare (not exhasutive):</p> <ul> <li><a href="https://www.perplexity.ai/">Perplexity</a> - an LLM search-engine with up-to-date data from the web <ul> <li><a href="https://www.google.com/">Google AI Overview</a> discarded because it&#39;s hard to reproduce results</li> </ul></li> <li><a href="https://copilot.microsoft.com/">Copilot</a> - LLM with internet connection (similar to ChatGPT with browsing enabled)</li> <li><a href="https://onequery.app/">OneQuery</a> - AI agent to browse the web <ul> <li>There&#39;s others too but for the sake of time and ease of use I picked this one </li> </ul></li> </ul> <p>To keep things consistent, I&#39;m going to paste the raw results from 

## Scraping a jewelry website
 - [https://www.reddit.com/r/webscraping/comments/1hgz91o/scraping_a_jewelry_website](https://www.reddit.com/r/webscraping/comments/1hgz91o/scraping_a_jewelry_website)
 - RSS feed: $source
 - date published: 2024-12-18T11:02:57+00:00

<!-- SC_OFF --><div class="md"><p>So basically I new to webscraping and i need to scrape a jewery website. </p> <p>I would be needing the images and the description along with the handel. </p> <p>Can anyone guide me that how can this be automated? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Cold-End-4353"> /u/Cold-End-4353 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hgz91o/scraping_a_jewelry_website/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hgz91o/scraping_a_jewelry_website/">[comments]</a></span>

## Scheduler
 - [https://www.reddit.com/r/webscraping/comments/1hgtv48/scheduler](https://www.reddit.com/r/webscraping/comments/1hgtv48/scheduler)
 - RSS feed: $source
 - date published: 2024-12-18T04:34:44+00:00

<!-- SC_OFF --><div class="md"><p>Currently I am using Task scheduler on Windows OS to run scraping code thrice every day for my personal project. But it can&#39;t be run when I am not logged in. Once I am logged in, only it starts working.. I can&#39;t use github actions as site which I am scraping blocks it.. Anyone using cloud for the same? Which one is cheapest if only 30 mins of running every day plus max 1GB storage..</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/No-Day-5479"> /u/No-Day-5479 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hgtv48/scheduler/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hgtv48/scheduler/">[comments]</a></span>

## Decode websockets messages
 - [https://www.reddit.com/r/webscraping/comments/1hgopj0/decode_websockets_messages](https://www.reddit.com/r/webscraping/comments/1hgopj0/decode_websockets_messages)
 - RSS feed: $source
 - date published: 2024-12-18T00:02:55+00:00

<!-- SC_OFF --><div class="md"><p>Hello all, I&#39;m not too experienced in networks or scraping, but I&#39;ve been investigating how to retrieve backend API endpoints of betting sites. Some were easier than others, however, William Hill&#39;s was interesting.</p> <p>Upon establishing a connection to the websocket, and replicating the necessary headers and responses by inspecting the networks tab, I&#39;ve found that most of these data are encoded and are unreadable. Although, it seems the responses that we send back to the websocket seems to be a request for the client to subscribe to a certain match event.</p> <p>Message sent (Hex 41 Bytes) 00000000: 0003 0125 3e73 636f 7265 626f 6172 6473 ...%&gt;scoreboards</p> <p>00000001: 2f76 312f 4f42 5f45 5633 3338 3930 3935 /v1/OB_EV3389095</p> <p>00000002: 352f 7375 6d6d 6172 79 5/summary</p> <p>Message received (Hex) 00000000: 0057 00d3 f421 2473 636f 7265 626f 6172 .W...!$scoreboar</p> <p>00000001: 6473 2f76 312f 4f42 5f45 5633 3339 3135

