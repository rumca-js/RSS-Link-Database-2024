[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-25T19:10:14+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1hm6um6/so_curious_how_this_website_does_such_a_good_job/\"> <img src=\"https://preview.redd.it/b9gijniym19e1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ebc154729c420858b8c5b6c2cf05b9f94b32a3a1\" alt=\"So curious how this website does such a good job scraping Frontier Airlines flights. Looks like they have their own API that they make multiple calls out to. It's pretty quick and has GoWild ticket data which is a big deal. If anyone has any ideas let me know. I'd like to create my own personal one.\" title=\"So curious how this website does such a good job scraping Frontier Airlines flights. Looks like they have their own API that they make multiple calls out to. It's pretty quick and has GoWild ticket data which is a big deal. If anyone has any ideas let me know. I'd like to create my own personal one.\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/velenova\"> /u/velenova </a> <br",
        "id": 1779366,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hm6um6/so_curious_how_this_website_does_such_a_good_job",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/b9gijniym19e1.png?width=640&crop=smart&auto=webp&s=ebc154729c420858b8c5b6c2cf05b9f94b32a3a1",
        "title": "So curious how this website does such a good job scraping Frontier Airlines flights. Looks like they have their own API that they make multiple calls out to. It's pretty quick and has GoWild ticket data which is a big deal. If anyone has any ideas let me know. I'd like to create my own personal one.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-25T15:09:50+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello,</p> <p>I am working on a website/bot hybrid app for personal use, but I&#39;ve run into an issue that I hope someone might be able to help me with.</p> <p>My app scrapes <a href=\"http://Jisho.org\">Jisho.org</a> for words and sentence examples, it works for the most part, but I am having issues of scraping the furigana on any sentence examples and I can&#39;t seem to work out why. For example here on the page for neko we have these examples: <a href=\"https://jisho.org/search/%E3%81%AD%E3%81%93%20%23sentences\">https://jisho.org/search/%E3%81%AD%E3%81%93%20%23sentences</a>, so the furigana is the small symbols above the kanji characters. You might notice that you can not highlight these symbols, and I&#39;m wondering if that is why the scrape is messing up. So on my website atm it kinda finds the furigana naturally from the search output, then puts it next to the kanji rather than on top. </p> <p>TL;DR I want my website to scrape the sentence exa",
        "id": 1778447,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hm2cxf/web_scraping_furigana_from_jishoorg",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Web Scraping Furigana from Jisho.org?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-25T12:47:43+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1hm04sg/greetings_im_new_here_is_there_any_scraper_that/\"> <img src=\"https://preview.redd.it/fgppi7ygqz8e1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=da1a8b717eea30e791750c4a37120c5d145a8594\" alt=\"Greetings! I'm new here. Is there any scraper that scrapes places/ businesses page from Instead of Gmaps? Supposedly has more result, over 300 Instead of 120.\" title=\"Greetings! I'm new here. Is there any scraper that scrapes places/ businesses page from Instead of Gmaps? Supposedly has more result, over 300 Instead of 120.\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/6UwO9\"> /u/6UwO9 </a> <br/> <span><a href=\"https://i.redd.it/fgppi7ygqz8e1.png\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hm04sg/greetings_im_new_here_is_there_any_scraper_that/\">[comments]</a></span> </td></tr></table>",
        "id": 1777987,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hm04sg/greetings_im_new_here_is_there_any_scraper_that",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://preview.redd.it/fgppi7ygqz8e1.png?width=640&crop=smart&auto=webp&s=da1a8b717eea30e791750c4a37120c5d145a8594",
        "title": "Greetings! I'm new here. Is there any scraper that scrapes places/ businesses page from Instead of Gmaps? Supposedly has more result, over 300 Instead of 120.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-25T12:34:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am scraping a NBC-owned site&#39;s API and they have crazy bot detection. Very strict cloudflare security &amp; captcha/turnstile, custom WAF, custom session management and more. Essentially, I think there are like 4-5 layers of protection. Their recent security patch resulted in their API returning 200s with partial responses, which my backend accepted happily - so it was even hard to determine when their patch was applied and probably went unnoticed for a week or so.</p> <p>I am running a small startup. We have limited cash and still trying to find PMF. Our scraping operation costs just keep growing because of these guys. Started out free, then $500/month, then $700/month and now its up to $2k/month. We are also looking to drastically increase scraping frequency when we find PMF and/or have some more paying customers. For context, right now I think we are using 40 concurrent threads and scraping about 250 subdomains every hour and a half or so us",
        "id": 1777986,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hlzynt/how_to_get_around_highcost_scraping_of_heavily",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to get around high-cost scraping of heavily bot detected sites?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-25T11:38:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all</p> <p>I\u2019m curious how others handle saving spider data to mssql when running concurrent spiders</p> <p>I\u2019ve tried row level locking and batching (splitting update vs insertion) but am not able to solve it. I\u2019m attempting a redis based solution which is introducing its own set of issues as well</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/z8784\"> /u/z8784 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hlz8dj/mssql_question/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hlz8dj/mssql_question/\">[comments]</a></span>",
        "id": 1777751,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hlz8dj/mssql_question",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "MSSQL Question",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-25T08:37:46+00:00",
        "description": "&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BodybuilderLost328\"> /u/BodybuilderLost328 </a> <br/> <span><a href=\"https://news.ycombinator.com/item?id=42496918\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hlwzm4/show_hn_rtrvrai_ai_web_agent_for_automating/\">[comments]</a></span>",
        "id": 1777291,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hlwzm4/show_hn_rtrvrai_ai_web_agent_for_automating",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Show HN: rtrvr.ai \u2013 AI Web Agent for Automating Workflows and Data Extraction",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-25T01:27:33+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1hlr169/web_scraping_made_easy_with_python_selenium/\"> <img src=\"https://external-preview.redd.it/GAgjrT3ROBPpkNfY-hCFppt82pU4_bZCqzlQDiZFiS0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d3f5bfad64f941bf40c5ce9241c33a11a3de9f71\" alt=\"Web Scraping Made Easy with Python Selenium\" title=\"Web Scraping Made Easy with Python Selenium\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Web Scraping Made Easy with Python Selenium | Beginner&#39;s Guide to Automate Websites</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Capable-Post-5674\"> /u/Capable-Post-5674 </a> <br/> <span><a href=\"https://youtu.be/BUXOLESjYX8?si=KBFoq-yZ54Xe4hSv\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hlr169/web_scraping_made_easy_with_python_selenium/\">[comments]</a></span> </td></tr></table>",
        "id": 1776479,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hlr169/web_scraping_made_easy_with_python_selenium",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/GAgjrT3ROBPpkNfY-hCFppt82pU4_bZCqzlQDiZFiS0.jpg?width=320&crop=smart&auto=webp&s=d3f5bfad64f941bf40c5ce9241c33a11a3de9f71",
        "title": "Web Scraping Made Easy with Python Selenium",
        "vote": 0
    }
]