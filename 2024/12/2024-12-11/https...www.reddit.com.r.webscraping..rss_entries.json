[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-11T22:27:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I cant seem to find any, does anyone know why most are gone and if there are any alternatives?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/GoldenretriverYT\"> /u/GoldenretriverYT </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hc5ygc/are_all_hcaptcha_solvers_gone/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hc5ygc/are_all_hcaptcha_solvers_gone/\">[comments]</a></span>",
        "id": 1692529,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hc5ygc/are_all_hcaptcha_solvers_gone",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Are all hCaptcha solvers gone?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-11T20:56:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>This barely counts as web scraping, but I suspect this community will know best how to handle my blocker. I am hitting honk mobile&#39;s GraphQL server to get a list of available parking reservations for a particular site they manage. I am using this in a simple python script using requests. </p> <p>If I hit this using the Altair GraphQL client extension I can successfully return data, but if I export the reqest as a cURL, the request is flagged by cloudflare and blocked, returning a 403 and an HTML page: <code>This website is using a security service to protect itself from online attacks. The action you just performed triggered the security solution. There are several actions that could trigger this block including submitting a certain word or phrase, a SQL command or malformed data.</code> </p> <p>I&#39;ve tried using the same headers and building the request to match what is being sent by FF/Edge as closely as possible. You can see the cURL reques",
        "id": 1691613,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hc3ubb/circumvent_cloudflare_blocking_otherwise_valid",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Circumvent cloudflare blocking otherwise valid graphQL query",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-11T18:35:10+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I follow an indie hacker called levelsio. He says his Luggage Losers app scrapes data. I have built a Google Reviews scraper, but it breaks every few months when the webpage structure changes.</p> <p>For this reason, I am ruling out future products that rely on scraping. He has 10&#39;s of apps, so I can&#39;t see how he could be maintaining multiple scrapers. Any idea how this would be working?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/AchillesFirstStand\"> /u/AchillesFirstStand </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hc0gft/how_does_levelsio_rely_on_scrapers/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hc0gft/how_does_levelsio_rely_on_scrapers/\">[comments]</a></span>",
        "id": 1690778,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hc0gft/how_does_levelsio_rely_on_scrapers",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How does levelsio rely on scrapers?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-11T17:24:22+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I will be hired in a web scraping job and the only worker in the area, i want use the most common tool for targeted study(intern) and standardization, is a finance assessor company.</p> <p>I am studying, scrapy.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ContentBottle957\"> /u/ContentBottle957 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hbyqil/most_used_toolsframework_in_the_job_market/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hbyqil/most_used_toolsframework_in_the_job_market/\">[comments]</a></span>",
        "id": 1690173,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hbyqil/most_used_toolsframework_in_the_job_market",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Most used tools/framework in the job market",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-11T17:24:21+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I will be hired in a web scraping job and the only worker in the area, i want use the most common tool for targeted study(intern) and standardization, is a finance assessor company.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ContentBottle957\"> /u/ContentBottle957 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hbyqib/most_used_toolsframework_in_the_job_market/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hbyqib/most_used_toolsframework_in_the_job_market/\">[comments]</a></span>",
        "id": 1690174,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hbyqib/most_used_toolsframework_in_the_job_market",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Most used tools/framework in the job market",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-11T16:09:52+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello,</p> <p>I read the whole documentation but I couldn&#39;t find a direct way to run JavaScript code in an instance of Nodriver. If anyone in here successfully ran JavaScript on Nodriver, I&#39;d appreciate if you share with me how did you do it.</p> <p>Thanks.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/_iamhamza_\"> /u/_iamhamza_ </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hbwxus/how_can_i_execute_javascript_snippets_in/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hbwxus/how_can_i_execute_javascript_snippets_in/\">[comments]</a></span>",
        "id": 1689684,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hbwxus/how_can_i_execute_javascript_snippets_in",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How can I execute JavaScript snippets in Nodriver's browser?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-11T15:07:35+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;ve currently reached a point where I have websites scraped in HTML/markdown format. I&#39;m wondering if there&#39;s a good way to only extract the main content of these websites? I&#39;ve tried stuff like markdownify, readability, newspaper3k but they all seem to miss a lot of content... </p> <p>Any ideas? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Ok_Coyote_8904\"> /u/Ok_Coyote_8904 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hbviy3/best_way_to_extract_main_content_only_from/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hbviy3/best_way_to_extract_main_content_only_from/\">[comments]</a></span>",
        "id": 1689119,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hbviy3/best_way_to_extract_main_content_only_from",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Best way to extract \u201cmain content\u201d only from HTML/Markdown",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-11T14:57:54+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019m developing an app that allows users to input a recipe URL, and the app then parses the HTML to simplify the recipe. However, I\u2019m concerned about the legal implications of this process, especially regarding the terms of service (TOS) of various recipe websites.</p> <p>For instance, a cooking website&#39;s TOS explicitly prohibits actions such as:</p> <ul> <li>Using automated means like spiders, robots, scrapers, or crawlers to harvest data from their services.</li> <li>Copying, reproducing, distributing, republishing, downloading, displaying, posting, or transmitting any part of their services without permission.</li> </ul> <p>Given these restrictions, I\u2019m worried that my app\u2019s functionality might violate such terms, potentially leading to legal issues.</p> <p>Has anyone here navigated similar challenges? How do you ensure compliance with website TOS when developing scraping tools? Are there best practices or alternative approaches to consider for",
        "id": 1689118,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hbvarn/is_my_recipe_summarizing_app_legal",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is My Recipe Summarizing App Legal?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-11T14:17:33+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Sorry if this is the wrong site. Is there a handwriting generator tool out there where I can generate multiple (hundreds) of variation of the same text so I can test out accuracy of an OCR tool I&#39;m using.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ddavid1101\"> /u/ddavid1101 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hbug0p/massmultiple_handwriting_generator_to_test_ocr/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hbug0p/massmultiple_handwriting_generator_to_test_ocr/\">[comments]</a></span>",
        "id": 1688572,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hbug0p/massmultiple_handwriting_generator_to_test_ocr",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Mass/Multiple Handwriting Generator to test OCR",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-11T11:56:42+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m by no means an expert scraper but do utilise a few tools occasionally and know the basics. However one URL has me beat - perhaps it&#39;s purposeful by design to stop scraping. I&#39;d just like to know if any of the experts think this is achievable or I should abandon my efforts.</p> <p>URL: <a href=\"https://www.architects-register.org.uk/\">https://www.architects-register.org.uk/</a></p> <p>It&#39;s public domain data on all architects registered in the UK. First challenge is you can&#39;t return all results and are forced to search - so have opted for &quot;London&quot; with address field. This then returns multiple pages. Second challenge is having to click &quot;View&quot; to then return the full detail (my target data) of each individual - this opens in a new page which none of my tools support.</p> <p>Any suggestions please?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/oHUTCHYo\"> /u/oHUTCHYo </a",
        "id": 1687657,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hbruer/im_beaten_is_this_technically_possible",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I'm beaten. Is this technically possible?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-11T11:13:38+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am trying to scrape reviews from tripadvisor using selenium and beautiful soup but everytime I am getting stuck on solving the captcha (solving the puzzle by sliding one ) .</p> <p>Other alternatives that few of my friends suggested were using captcha solver services or using proxies but isn&#39;t there any way to get it done without having to spend some money on these services ? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Chuggleme\"> /u/Chuggleme </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hbr78s/scraping_reviews_from_tripadvisor/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hbr78s/scraping_reviews_from_tripadvisor/\">[comments]</a></span>",
        "id": 1687276,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hbr78s/scraping_reviews_from_tripadvisor",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping reviews from TripAdvisor",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-11T10:24:45+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>hi. i\u2019m writing a scraper that gets data from a table. unfortunately, this table is a dynamic image you can query with start date and end date. the image looks good and is consistent. </p> <p>i\u2019ll be using an ocr to get this data. any idea how i can make sure that the data being produced is correct? </p> <p>thanks. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/siaosiaos\"> /u/siaosiaos </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hbqiwe/best_practices_for_scraper_using_ocr/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hbqiwe/best_practices_for_scraper_using_ocr/\">[comments]</a></span>",
        "id": 1687275,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hbqiwe/best_practices_for_scraper_using_ocr",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "best practices for scraper using ocr",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-11T04:36:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey folks! I\u2019m diving into web scraping for the first time and could use some advice. I need to scrape data from a website that\u2019s loaded with buttons and dropdown menus. The goal is to click around, configure some options, and download weekly Excel data automatically.</p> <p>I\u2019m really hoping to find a no-code tool that lets me automate these clicks \u2014 maybe something with mouse-click recording or AI that can \u201cremember\u201d the steps. Coding isn\u2019t my thing (yet), so the simpler, the better!</p> <p>Any recommendations for tools that make this easy for a newbie? Thanks in advance for any help!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/tanviraman\"> /u/tanviraman </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hbllnl/need_a_nocode_web_scraper_for_a_buttonheavy/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hbllnl/need_a_nocode_web_scraper_for_a_butto",
        "id": 1685998,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hbllnl/need_a_nocode_web_scraper_for_a_buttonheavy",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need a no-code web scraper for a button-heavy website",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-11T02:39:01+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1hbjf95/100_free_reddit_data_scraper_tool_alternative_to/\"> <img src=\"https://external-preview.redd.it/ezKx51yF9R8OwG2CS48-d-NUobfd14NsSRz8ToCAkzA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9d8ce1b36db67e7b25c41dabbbf5438a2317eaa4\" alt=\"100% Free Reddit Data Scraper Tool \ud83d\ude80 | Alternative to GummySearch\" title=\"100% Free Reddit Data Scraper Tool \ud83d\ude80 | Alternative to GummySearch\" /> </a> </td><td> <!-- SC_OFF --><div class=\"md\"><p>Hey everyone! </p> <p>I made a <strong>free Reddit Data Scraper</strong> because, let\u2019s be honest, who doesn\u2019t love tinkering with data?. Built with <strong>Streamlit</strong>, it\u2019s super easy to use, and it\u2019s free for everyone! I just learnt Python and this has been a really fun project for me.</p> <p>Key Features:</p> <ul> <li><strong>Scrape subreddit posts</strong>: Filter by time and post limits.</li> <li><strong>Extract comments</strong>: Just paste the Reddit post URL. (up to 100",
        "id": 1685999,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hbjf95/100_free_reddit_data_scraper_tool_alternative_to",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/ezKx51yF9R8OwG2CS48-d-NUobfd14NsSRz8ToCAkzA.jpg?width=640&crop=smart&auto=webp&s=9d8ce1b36db67e7b25c41dabbbf5438a2317eaa4",
        "title": "100% Free Reddit Data Scraper Tool \ud83d\ude80 | Alternative to GummySearch",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-11T01:12:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I want to be able to scrape 2 star and less reviews from amazon and the user information is there any way to do this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Turfy7\"> /u/Turfy7 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hbhqel/scraping_negative_reviews_from_amazon/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hbhqel/scraping_negative_reviews_from_amazon/\">[comments]</a></span>",
        "id": 1685205,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hbhqel/scraping_negative_reviews_from_amazon",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping negative reviews from amazon",
        "vote": 0
    }
]