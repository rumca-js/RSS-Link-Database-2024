# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## Scraping Walmart and others, DIY vs 3rd-party scraping services?
 - [https://www.reddit.com/r/webscraping/comments/1hp7mc2/scraping_walmart_and_others_diy_vs_3rdparty](https://www.reddit.com/r/webscraping/comments/1hp7mc2/scraping_walmart_and_others_diy_vs_3rdparty)
 - RSS feed: $source
 - date published: 2024-12-29T22:24:06+00:00

<!-- SC_OFF --><div class="md"><p>Hi folks,</p> <p>I&#39;m a newbie to scraping, long story I want to scrape some grocery info for some essential products from the websites like walmart , I did a little research and found packages like undetectable-chromedriver, but it turned out to be detectable lol. I encountered errors that seem caused by blocking, and I check the console found navigator.webdriver = true... I guess that&#39;s not the only reason to be blocked. so I dig a little more and found it needs to change headers, ips, TLS fingerprint etc. to be not blocked. And then, I found these 3rd-party services that seem to do all dirty works and also charge a certain amount, although I am not sure its reliability and if it&#39;s worth the payment</p> <p>So TLDR: I&#39;m trying to gauge the learning curve to bypass all blockers myself vs. just using a paid 3rd-party API., My request rate is around 25-50 pages every week (when they update the inventory).</p> <p>If anyone has successful 

## Scraping for Housing: Legal Concerns and Opportunities
 - [https://www.reddit.com/r/webscraping/comments/1hp66b3/scraping_for_housing_legal_concerns_and](https://www.reddit.com/r/webscraping/comments/1hp66b3/scraping_for_housing_legal_concerns_and)
 - RSS feed: $source
 - date published: 2024-12-29T21:20:46+00:00

<!-- SC_OFF --><div class="md"><p>Hey guys, I was looking for a new home but didnâ€™t want to pay for any site to send me notifications of new offers. So, I built a scraper that scrapes sites of multiple house brokers every 15 minutes for new listings and sends me an email. I hosted it on my own server, and since I already have a server, I was thinking about setting this up as a service for other people to pay for. However, Iâ€™m a bit worried about the legality. I live in the Netherlands, and I donâ€™t want to get into any trouble. Do you guys know what I should watch out for? Some site terms of service say you cannot scrape their site for commercial reasons, but is that something I should really worry about?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/HackHusky"> /u/HackHusky </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hp66b3/scraping_for_housing_legal_concerns_and/">[link]</a></span> &#32; <span><a href="https://www

## I'm getting constantly blocked while trying to crawl!
 - [https://www.reddit.com/r/webscraping/comments/1hp1zgo/im_getting_constantly_blocked_while_trying_to](https://www.reddit.com/r/webscraping/comments/1hp1zgo/im_getting_constantly_blocked_while_trying_to)
 - RSS feed: $source
 - date published: 2024-12-29T18:15:35+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;m practicing web crawling and trying to automate posting on a Korean forum called DC Inside, using curl_cffi and analyzing network requests with developer tools.</p> <p>However, even though I set the TLS fingerprint and send the headers and data exactly as they appear in the Network tab, the final POST request keeps getting blocked.</p> <p>There are two POST requests being made to the site, and one of them gets a proper response, which leads me to believe that it&#39;s unlikely that the site is tracking user behavior data in that way.</p> <p>Is it possible to distinguish whether a POST request is a normal request or not based solely on the POST request itself? And if so, how can I bypass this block?</p> <p>You can find the entire code and a more detailed explanation in the GitHub repository linked below.</p> <p>It&#39;s a short piece of code involving 1 GET and 2 POST requests, so any help would be incredibly valuable.</p> <p><a href="https://g

## Can amazon lambda replace proxies?
 - [https://www.reddit.com/r/webscraping/comments/1hop7f8/can_amazon_lambda_replace_proxies](https://www.reddit.com/r/webscraping/comments/1hop7f8/can_amazon_lambda_replace_proxies)
 - RSS feed: $source
 - date published: 2024-12-29T05:34:35+00:00

<!-- SC_OFF --><div class="md"><p>I was talking to a friend about my scraping project and talked about proxies. He suggested that I could use amazon lambda if the scraping function is relatively simple, which it is. Since lambda runs the script from different VMs everytime, it should use a new IP address everytime and thus replace the proxy use case. Am I missing something?</p> <p>I know that in some cases, scraper want to use a session, which won&#39;t be possible with AWS lambda, but other than that am I missing something? Is my friend right with his suggestion?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/dimem16"> /u/dimem16 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hop7f8/can_amazon_lambda_replace_proxies/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hop7f8/can_amazon_lambda_replace_proxies/">[comments]</a></span>

## GSA-SRP protocol for authentification with apple services
 - [https://www.reddit.com/r/webscraping/comments/1hop5rm/gsasrp_protocol_for_authentification_with_apple](https://www.reddit.com/r/webscraping/comments/1hop5rm/gsasrp_protocol_for_authentification_with_apple)
 - RSS feed: $source
 - date published: 2024-12-29T05:31:39+00:00

<table> <tr><td> <a href="https://www.reddit.com/r/webscraping/comments/1hop5rm/gsasrp_protocol_for_authentification_with_apple/"> <img src="https://external-preview.redd.it/n27arKI6KDgcPpmIGiLqbgXyf7f1T6n-U2ZTB-VxZME.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=90664b3f7a1fff74e5a614bbe8162455110936c1" alt="GSA-SRP protocol for authentification with apple services" title="GSA-SRP protocol for authentification with apple services" /> </a> </td><td> <!-- SC_OFF --><div class="md"><p>I wrote this for a client a few weeks ago but they don&#39;t seem to be interested anymore, here is the code for you plebs</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/musaspacecadet"> /u/musaspacecadet </a> <br/> <span><a href="https://github.com/musaspacecadet/icloud-auth">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hop5rm/gsasrp_protocol_for_authentification_with_apple/">[comments]</a></span> </td></tr></table>

## Having issues with files from httrack
 - [https://www.reddit.com/r/webscraping/comments/1hooi3o/having_issues_with_files_from_httrack](https://www.reddit.com/r/webscraping/comments/1hooi3o/having_issues_with_files_from_httrack)
 - RSS feed: $source
 - date published: 2024-12-29T04:52:59+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;ve saved a website locally (Mac not PC) from both httrack and sitesucker. When opening the index.html file, the website does not load. I am a complete newbie to dev. Can anyone guide me through this process? I think there may need to be some slight debugging with file names?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Substantial-Face7849"> /u/Substantial-Face7849 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hooi3o/having_issues_with_files_from_httrack/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hooi3o/having_issues_with_files_from_httrack/">[comments]</a></span>

## tellonym api
 - [https://www.reddit.com/r/webscraping/comments/1honayt/tellonym_api](https://www.reddit.com/r/webscraping/comments/1honayt/tellonym_api)
 - RSS feed: $source
 - date published: 2024-12-29T03:44:25+00:00

<!-- SC_OFF --><div class="md"><p>Guys, this API &quot;<a href="https://api.tellonym.me/profiles/name/username">https://api.tellonym.me/profiles/name/username</a>&quot; is seriously hard to work with. I&#39;m trying to scrape it, but no luck. Tried a bunch of different ways, can&#39;t even tell if it&#39;s Cloudflare protection or something else. Any help would be awesomeðŸ˜­ðŸ˜­</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/One_Dig_2271"> /u/One_Dig_2271 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1honayt/tellonym_api/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1honayt/tellonym_api/">[comments]</a></span>

## Copy as curl doesn't return what request returns in webbrowser
 - [https://www.reddit.com/r/webscraping/comments/1holw49/copy_as_curl_doesnt_return_what_request_returns](https://www.reddit.com/r/webscraping/comments/1holw49/copy_as_curl_doesnt_return_what_request_returns)
 - RSS feed: $source
 - date published: 2024-12-29T02:26:12+00:00

<!-- SC_OFF --><div class="md"><p>I am trying to scrape a specific website that has made it quite difficult to do so. One potential solution I thought of was using mitmproxy to intercept and identify the exact request I&#39;m interested in, then copying it as a <code>curl</code> command. My assumption was that by copying the request as <code>curl</code>, it would include all the necessary headers and parameters to make it appear as though the request originated from a browser. However, this didn&#39;t work as expected. When I copied the request as <code>curl</code> and ran it in the terminal without any modifications, the response was just empty text.</p> <p>Note: I am getting a 200 response</p> <p>Can someone explain why this isn&#39;t working as planned?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/dimem16"> /u/dimem16 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1holw49/copy_as_curl_doesnt_return_what_request_ret

## New scraper, need help
 - [https://www.reddit.com/r/webscraping/comments/1hokypn/new_scraper_need_help](https://www.reddit.com/r/webscraping/comments/1hokypn/new_scraper_need_help)
 - RSS feed: $source
 - date published: 2024-12-29T01:37:44+00:00

<!-- SC_OFF --><div class="md"><p>Hey guys, I am working on a project that requires scraping restaurant websites. I am currently stuck on Potbelly&#39;s website -<a href="https://www.potbelly.com/-">https://www.potbelly.com/-</a>. I want to scrape the &quot;Featured&quot; section of the Home Page. Basic HTML requests didn&#39;t work, dynamic js requests with requests-html and selenium didn&#39;t work, and I couldn&#39;t find an API in the network requests. Looking for advice from experienced scrapers on how to go after this one.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/offthedeepend9"> /u/offthedeepend9 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hokypn/new_scraper_need_help/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hokypn/new_scraper_need_help/">[comments]</a></span>

