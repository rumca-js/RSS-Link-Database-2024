[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-13T17:54:58+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Has anyone tried <a href=\"https://www.leads-sniper.com/products/google-maps-scraper\">Leads</a> Sniper? Is it true they offer an unlimited leads lifetime package? Sounds too good to be true\u2014any real experiences?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Dismal_Art_9658\"> /u/Dismal_Art_9658 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hdhzpl/exploring_scraped_data/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hdhzpl/exploring_scraped_data/\">[comments]</a></span>",
        "id": 1705643,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hdhzpl/exploring_scraped_data",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Exploring scraped data",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-13T17:42:26+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am creating an AI tool. This tool will use external API&#39;s on demand. This means that is needs to be able to find and scrape API docs.</p> <p>I am having trouble with dynamic content in the API doc pages. Any suggestions on how to make a general purpose scraper like this?</p> <p>Is this even possible at the moment?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PorterG2003\"> /u/PorterG2003 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hdhpe0/scraping_api_documentation_sites/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hdhpe0/scraping_api_documentation_sites/\">[comments]</a></span>",
        "id": 1705644,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hdhpe0/scraping_api_documentation_sites",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping API Documentation sites",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-13T15:14:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>hi im working on a personal project where i want to display ebay data of sold lego sets. however the number of lego sets is huge (around 21k?) and i was wondering what the most efficient way to scrape all the data would be. currently i used selenium to scrape a singular set but i dont think this is that feasible to do every single set and constantly be updating it every like 2 months even if i rotate through the sets everyday.</p> <p>currently my idea is if i go through the selenium approach would be to broaden the search on ebay and rather than doing a specific set, i would just search lego and scrape all that data and just run it more frequently but if anyone else has other ideas, i would be grateful for reccommendations.</p> <p>Right now, i don&#39;t think selenium can handle what i am trying to achieve. Thank you!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PeanutButterSauce1\"> /u/PeanutButterSauce1 </a>",
        "id": 1704782,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hdeded/webscraping_all_lego_sets_on_ebay",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "webscraping all lego sets on ebay",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-13T13:20:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Is it legal in the EU to scrape data from a 3rd party website, store it in a cloud database, and expose the data through API endpoints for free?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Savings_Diamond1363\"> /u/Savings_Diamond1363 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hdc1ze/exposing_scraped_data_for_free_is_it_legal/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hdc1ze/exposing_scraped_data_for_free_is_it_legal/\">[comments]</a></span>",
        "id": 1703952,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hdc1ze/exposing_scraped_data_for_free_is_it_legal",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Exposing scraped data for free. Is it legal?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-13T12:16:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey public data enthusiasts!</p> <p>We&#39;re excited to announce the release of a new, large-scale social media dataset from Exorde Labs. We&#39;ve developed a robust public data collection engine that&#39;s been quietly amassing an impressive dataset via a distributed network.</p> <p><strong>The Origin Dataset</strong></p> <ul> <li><strong>Scale</strong>: Over 1 billion data points, with 10 million added daily (3.5-4 billion per year at our current rate)</li> <li><strong>Sources</strong>: 6000+ diverse public social media platforms (X, Reddit, BlueSky, YouTube, Mastodon, Lemmy, TradingView, bitcointalk, jeuxvideo dot com, etc.)</li> <li><strong>Collection</strong>: Near real-time capture since August 2023, at a growing scale.</li> <li><strong>Rich Annotations</strong>: Includes original text, metadata (URL, Author Hash, date) emotions, sentiment, top keywords, and theme</li> </ul> <p><strong>Sample Dataset Now Available</strong></p> <p>We&#39;re re",
        "id": 1703473,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hday1v/multilingual_multisource_social_media_dataset_a",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Multi-lingual multi-source social media dataset - a full week",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-13T11:17:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello there, I am building a system that will be quering like hundreads of different websites. </p> <p>I have single entry point that doing request to website. I need a system that will validate the response is success (for metrics only for now). </p> <p>So i have a logic that checks status codes, but i need to check the response body as well to detect any cloudflare/captcha or similar blockage signs. </p> <p>Maybe someone saw somewhere a collection of common xpathes i can look for to detect those in response body? </p> <p>Like i have some examples on hand, but maybe there is some kind of maintainable list or something similar?<br/> Appreciate </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/PawsAndRecreation\"> /u/PawsAndRecreation </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hda29h/detecting_blocked_responses/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscrapi",
        "id": 1703074,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hda29h/detecting_blocked_responses",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Detecting blocked responses",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-13T09:14:27+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>just a little background , i am trying to build a webscraping project for my resume ( i am a 2nd year CS major ) i have already built myself a scrapers which works only on the CISCO website , but the point of the project was to scan for CVEs (common Vulnerebilities and exposures) which gets published on various platform like the company itself (in this case CISCO) and NVD etc . but i could not generalise it (for 1 .py script to scan for every website) do i have to write a seperate script for every website or is there a more efficient way to do this .</p> <p>Please respond with suggestions or solutions if any </p> <p>Thank you for your time </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Positive-Special-616\"> /u/Positive-Special-616 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hd8ge7/is_generalization_possible_in_webscraping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit",
        "id": 1703953,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hd8ge7/is_generalization_possible_in_webscraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "is generalization possible in webscraping ?",
        "vote": 0
    }
]