# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## Cloudflare just a moment... page
 - [https://www.reddit.com/r/webscraping/comments/1hgkqbu/cloudflare_just_a_moment_page](https://www.reddit.com/r/webscraping/comments/1hgkqbu/cloudflare_just_a_moment_page)
 - RSS feed: $source
 - date published: 2024-12-17T21:02:46+00:00

<!-- SC_OFF --><div class="md"><p>I&#39;m currently testing on a website. I&#39;m sending a request once per 5000ms. The two headers I&#39;m sending are <code>Pragma : &quot;no-cache&quot;</code> and <code>User Agent</code>, nothing else. I found out that only these two are necessary to make a request. Also using an ipv6 http proxy.</p> <p>It makes around 5-20 successful requests before getting hit by a Cloudflare just a moment page. Idk what this page looks like but the source code of the response contains &quot;enable javascript&quot;. I&#39;m guessing it&#39;s a captcha. It then resumes as normal and I don&#39;t see the page again , at least not in my testing for 20 mins+. </p> <p>Anyone know the reason for this behaviour? Anything I should consider adding?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Fuarkistani"> /u/Fuarkistani </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hgkqbu/cloudflare_just_a_moment_page/"

## Any way to copy-paste this?
 - [https://www.reddit.com/r/webscraping/comments/1hgknha/any_way_to_copypaste_this](https://www.reddit.com/r/webscraping/comments/1hgknha/any_way_to_copypaste_this)
 - RSS feed: $source
 - date published: 2024-12-17T20:57:56+00:00

<!-- SC_OFF --><div class="md"><p>I want to download historical prices of British pound in US dollars. I can see the info on the page in yahoo finance but I can&#39;t copy and paste it. Anyone know how to do this? I mean, just by hand, not with a scraper.</p> <p><a href="https://finance.yahoo.com/quote/GBPUSD%3DX/history/">https://finance.yahoo.com/quote/GBPUSD%3DX/history/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/tyroboot"> /u/tyroboot </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hgknha/any_way_to_copypaste_this/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hgknha/any_way_to_copypaste_this/">[comments]</a></span>

## Scraping for WooCommerce ?
 - [https://www.reddit.com/r/webscraping/comments/1hgjt2e/scraping_for_woocommerce](https://www.reddit.com/r/webscraping/comments/1hgjt2e/scraping_for_woocommerce)
 - RSS feed: $source
 - date published: 2024-12-17T20:20:01+00:00

<!-- SC_OFF --><div class="md"><p>Hello guys ! </p> <p>First post here.<br/> I have been scraping a full directory before. Now for getting sales leads, I would like to know if there is a way to know which websites in French is using WooCommerce as e-commerce engine ? </p> <p>Is it too far-fetched or is there a way to get some results ?<br/> How would you proceed ? </p> <p>I know that <a href="http://builtwith.com">builtwith.com</a>, <a href="http://wappalyser.com">wappalyser.com</a> and <a href="http://webtechsurvey.com">webtechsurvey.com</a> provide lists by technology/location.<br/> But according to the free samples I got, they are rather inaccurate. </p> <p>TIA</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/ParapenteMexico"> /u/ParapenteMexico </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hgjt2e/scraping_for_woocommerce/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hgjt2e/s

## Open Source Folks, Curious About Sustainability? üåø
 - [https://www.reddit.com/r/webscraping/comments/1hgiymt/open_source_folks_curious_about_sustainability](https://www.reddit.com/r/webscraping/comments/1hgiymt/open_source_folks_curious_about_sustainability)
 - RSS feed: $source
 - date published: 2024-12-17T19:43:11+00:00

<!-- SC_OFF --><div class="md"><p>I‚Äôve been thinking about the challenges of maintaining open-source projects - balancing community, sustainability, and monetization.</p> <p>A fireside chat with <strong>Ariya Hidayat</strong> (PhantomJS) and <strong>Shane Evans</strong> (Scrapy at Zyte) will be diving into this exact topic. It‚Äôs happening <strong>Wednesday, Dec 18th, 2 PM UTC</strong>. <a href="https://www.addevent.com/event/TE24073882"><strong>üåª Here! üåª</strong></a></p> <p>If you‚Äôre into open source - whether as a dev, contributor, or just curious - this might be worth checking out. What are your thoughts on keeping open-source projects sustainable?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/lakshayyn"> /u/lakshayyn </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hgiymt/open_source_folks_curious_about_sustainability/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hgiymt/open_

## Selenium web scraping overcoming popovers
 - [https://www.reddit.com/r/webscraping/comments/1hgcecg/selenium_web_scraping_overcoming_popovers](https://www.reddit.com/r/webscraping/comments/1hgcecg/selenium_web_scraping_overcoming_popovers)
 - RSS feed: $source
 - date published: 2024-12-17T14:57:21+00:00

<!-- SC_OFF --><div class="md"><p>Learning how to webscrape, I told my company that I could potentially scrape this website: fundfinder.live however it has the most annoying popovers i&#39;ve ever seen. </p> <p>This is my code: <a href="https://github.com/Ju436/Webscrape-/blob/main/rebuffed">https://github.com/Ju436/Webscrape-/blob/main/rebuffed</a></p> <p>for some reason it&#39;ll shut down after I go to one of the popovers, wheras I need to scrape all popovers. Could someone help me please?</p> <p>I&#39;m using python selenium</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/wheresmypassionfruit"> /u/wheresmypassionfruit </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hgcecg/selenium_web_scraping_overcoming_popovers/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hgcecg/selenium_web_scraping_overcoming_popovers/">[comments]</a></span>

## Weekly Webscrapers - Hiring, FAQs, etc
 - [https://www.reddit.com/r/webscraping/comments/1hga3rk/weekly_webscrapers_hiring_faqs_etc](https://www.reddit.com/r/webscraping/comments/1hga3rk/weekly_webscrapers_hiring_faqs_etc)
 - RSS feed: $source
 - date published: 2024-12-17T13:01:10+00:00

<!-- SC_OFF --><div class="md"><p><strong>Welcome to the weekly discussion thread!</strong></p> <p>This is a space for web scrapers of all skill levels‚Äîwhether you&#39;re a seasoned expert or just starting out. Here, you can discuss all things scraping, including:</p> <ul> <li>Hiring and job opportunities</li> <li>Industry news, trends, and insights</li> <li>Frequently asked questions, like &quot;How do I scrape LinkedIn?&quot;</li> <li>Marketing and monetization tips</li> </ul> <p>As with our <a href="https://reddit.com/r/webscraping/about/sticky?num=1">monthly thread</a>, self-promotions and paid products are welcome here ü§ù</p> <p>If you&#39;re new to web scraping, make sure to check out the <a href="https://webscraping.fyi">Beginners Guide</a> üå±</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/AutoModerator"> /u/AutoModerator </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hga3rk/weekly_webscrapers_hiring_faqs_etc/">[l

## Way to scrape emails if I have person's full name and address?
 - [https://www.reddit.com/r/webscraping/comments/1hg0yva/way_to_scrape_emails_if_i_have_persons_full_name](https://www.reddit.com/r/webscraping/comments/1hg0yva/way_to_scrape_emails_if_i_have_persons_full_name)
 - RSS feed: $source
 - date published: 2024-12-17T02:53:33+00:00

<!-- SC_OFF --><div class="md"><p>If I have a person&#39;s first name and last name and full address, what is the best way to scrape their email address? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/pitchfork_2000"> /u/pitchfork_2000 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hg0yva/way_to_scrape_emails_if_i_have_persons_full_name/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hg0yva/way_to_scrape_emails_if_i_have_persons_full_name/">[comments]</a></span>

