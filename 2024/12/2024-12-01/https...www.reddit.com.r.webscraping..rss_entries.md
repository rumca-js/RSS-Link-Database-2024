# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## Need help downloading bulk files
 - [https://www.reddit.com/r/webscraping/comments/1h4eod2/need_help_downloading_bulk_files](https://www.reddit.com/r/webscraping/comments/1h4eod2/need_help_downloading_bulk_files)
 - RSS feed: $source
 - date published: 2024-12-01T21:54:31+00:00

<!-- SC_OFF --><div class="md"><p>Hi everyone, looking for help in downloading all epub files from this website: <a href="https://server.elscione.com/">https://server.elscione.com/</a></p> <p>They host good collection of LNs I&#39;m interested in reading further but as mentioned on first page of their website, the creator does not provide ways to bulk download all series files, but you have to manually open each folder to download the file. Also the direct file links are also not downloadable (that&#39;s why they mentioned not to share file link but share folder link instead).</p> <p>Can anyone help me with bulk download from this website? Does anyone has prior experience please. Would really appreciate it.</p> <p>Thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/you-get-used-to-it"> /u/you-get-used-to-it </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1h4eod2/need_help_downloading_bulk_files/">[link]</a></span> &#3

## Not all pages are being scraped
 - [https://www.reddit.com/r/webscraping/comments/1h417b8/not_all_pages_are_being_scraped](https://www.reddit.com/r/webscraping/comments/1h417b8/not_all_pages_are_being_scraped)
 - RSS feed: $source
 - date published: 2024-12-01T11:19:01+00:00

<!-- SC_OFF --><div class="md"><p>Hello all!! I am trying to extract the data from this Web: <a href="https://books.toscrape.com/">https://books.toscrape.com/</a></p> <p>The instructor wrote this code: <a href="https://docs.google.com/document/d/1PK_HRu483-1-UW31WUNMnnZB7iYlg7-lJkotEuV6OZE/edit?usp=drivesdk">https://docs.google.com/document/d/1PK_HRu483-1-UW31WUNMnnZB7iYlg7-lJkotEuV6OZE/edit?usp=drivesdk</a></p> <p>The code only scrapes the first two pages, and I couldn&#39;t figure out what the problem could be.</p> <p>Any help will be appreciated üôè </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Abad0o0o"> /u/Abad0o0o </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1h417b8/not_all_pages_are_being_scraped/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1h417b8/not_all_pages_are_being_scraped/">[comments]</a></span>

## Monthly Self-Promotion - December 2024
 - [https://www.reddit.com/r/webscraping/comments/1h3tkju/monthly_selfpromotion_december_2024](https://www.reddit.com/r/webscraping/comments/1h3tkju/monthly_selfpromotion_december_2024)
 - RSS feed: $source
 - date published: 2024-12-01T03:00:49+00:00

<!-- SC_OFF --><div class="md"><p>Hello and howdy, digital miners of r/webscraping!</p> <p>The moment you&#39;ve all been waiting for has arrived - it&#39;s our once-a-month, no-holds-barred, show-and-tell thread!</p> <ul> <li>Are you bursting with pride over that supercharged, brand-new scraper SaaS or shiny proxy service you&#39;ve just unleashed on the world?</li> <li>Maybe you&#39;ve got a ground-breaking product in need of some intrepid testers?</li> <li>Got a secret discount code burning a hole in your pocket that you&#39;re just itching to share with our talented tribe of data extractors?</li> <li>Looking to make sure your post doesn&#39;t fall foul of the community rules and get ousted by the spam filter?</li> </ul> <p>Well, this is your time to shine and shout from the digital rooftops - Welcome to your haven!</p> <p>Just a friendly reminder, we like to keep all our self-promotion in one handy place, so any promotional posts will be kindly redirected here. Now, let&#39;s get

## Any way to unblurr images on SubscribeStar without paying?
 - [https://www.reddit.com/r/webscraping/comments/1h3tj3d/any_way_to_unblurr_images_on_subscribestar](https://www.reddit.com/r/webscraping/comments/1h3tj3d/any_way_to_unblurr_images_on_subscribestar)
 - RSS feed: $source
 - date published: 2024-12-01T02:58:46+00:00

<!-- SC_OFF --><div class="md"><p>Is there any way to unblurr images on SubscribeStar without paying? Nekohouse&#39;s SubscribeStar importer is still unable to import text and multiple images...</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/burai1992"> /u/burai1992 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1h3tj3d/any_way_to_unblurr_images_on_subscribestar/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1h3tj3d/any_way_to_unblurr_images_on_subscribestar/">[comments]</a></span>

## Url to Markdown
 - [https://www.reddit.com/r/webscraping/comments/1h3t4pw/url_to_markdown](https://www.reddit.com/r/webscraping/comments/1h3t4pw/url_to_markdown)
 - RSS feed: $source
 - date published: 2024-12-01T02:37:04+00:00

<table> <tr><td> <a href="https://www.reddit.com/r/webscraping/comments/1h3t4pw/url_to_markdown/"> <img src="https://external-preview.redd.it/vmbg5iu4r1EBe4uM7Xx64ZR4PszcA4FeFBcWmmCCNr0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6cfc3c6df191574110ef0eac5660d71891f02245" alt="Url to Markdown" title="Url to Markdown" /> </a> </td><td> <!-- SC_OFF --><div class="md"><p>This project provides a powerful web scraping tool that fetches search results and converts them into Markdown format using FastAPI, SearXNG, and Browserless. It includes the capability to use proxies for web scraping and handles HTML content conversion to Markdown efficiently.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Mysterious_Pop_3716"> /u/Mysterious_Pop_3716 </a> <br/> <span><a href="https://github.com/essamamdani/search-result-scraper-markdown">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1h3t4pw/url_to_markdown/">[comments]</

