[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-21T22:08:04+00:00",
        "description": "<table> <tr><td> <a href=\"https://www.reddit.com/r/webscraping/comments/1hjkfdj/i_scraped_25000_remote_jobs_into_an_excel/\"> <img src=\"https://external-preview.redd.it/qdNgH03iYJZiQVmPq1k-ly0Y6bcKk1Zd8LwGlK8vCOU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5ff0870782df390f2f2877770f507181f39dde62\" alt=\"I scraped 25,000 remote jobs into an excel spreadsheet - it's free. you're welcome. upvote so everyone sees it &lt;3 \" title=\"I scraped 25,000 remote jobs into an excel spreadsheet - it's free. you're welcome. upvote so everyone sees it &lt;3 \" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/marvythemantis\"> /u/marvythemantis </a> <br/> <span><a href=\"https://docs.google.com/spreadsheets/d/1uHZQuAFMBOvGLBtJdZA-GXzNk_Ug3EgBgCk7d1Vbrg8/edit?usp=sharing\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hjkfdj/i_scraped_25000_remote_jobs_into_an_excel/\">[comments]</a></span> </td></tr></table>",
        "id": 1759045,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hjkfdj/i_scraped_25000_remote_jobs_into_an_excel",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": "https://external-preview.redd.it/qdNgH03iYJZiQVmPq1k-ly0Y6bcKk1Zd8LwGlK8vCOU.jpg?width=640&crop=smart&auto=webp&s=5ff0870782df390f2f2877770f507181f39dde62",
        "title": "I scraped 25,000 remote jobs into an excel spreadsheet - it's free. you're welcome. upvote so everyone sees it <3",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-21T20:52:11+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi everyone, I work for a small business in Canada that sells solar panels, batteries, and generators. I\u2019m looking to build a scraper to gather product and pricing data from our competitors\u2019 websites. The challenge is that some of the product names differ slightly, so I\u2019m exploring ways to categorize them as the same product using an algorithm or model, like a machine learning approach, to make comparisons easier.</p> <p>We have four main competitors, and while they don\u2019t have as many products as we do, some of their top-selling items overlap with ours, which are crucial to our business. We\u2019re looking at scraping around 700-800 products per competitor, so efficiency and scalability are important.</p> <p>Does anyone have recommendations on the best frameworks, tools, or approaches to tackle this task, especially for handling product categorization effectively? Any advice would be greatly appreciated!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <",
        "id": 1758845,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hjiw8u/web_scraper",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Web Scraper",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-21T20:04:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello,</p> <p>I would like to scrape a pdf especially some Highlighted word. I would like to use an easy tool because I&#39;m not really good at coding... I ve tried &quot;Parseur&quot; but the results were not what I&#39;ve excepted.</p> <p>Thank you very much!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Legitimate_Mud_9245\"> /u/Legitimate_Mud_9245 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hjhx87/tools_to_scrape_pdf/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hjhx87/tools_to_scrape_pdf/\">[comments]</a></span>",
        "id": 1758563,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hjhx87/tools_to_scrape_pdf",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Tools to scrape pdf",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-21T18:29:44+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I am working on importing job postings from a job site and want to scrape the site. I want the job postings to update automatically if they are removed from the source site. I plan to achieve this by checking the URL to see if it still exists on the scraped site. The plugin I use is WordPress with WP Job Board Manager. Are there better ways to do this, perhaps with existing plugins?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Historical_Cook_942\"> /u/Historical_Cook_942 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hjfx9c/automating_job_post_updates_in_wordpress_with_wp/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hjfx9c/automating_job_post_updates_in_wordpress_with_wp/\">[comments]</a></span>",
        "id": 1758264,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hjfx9c/automating_job_post_updates_in_wordpress_with_wp",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Automating Job Post Updates in WordPress with WP Job Board Manager",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-21T18:19:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I\u2019ve been researching companies like Turquoise Health and their ability to aggregate massive amounts of hospital pricing data. Given the variety and complexity of hospital pricing transparency rules and formats (e.g., machine-readable files, PDFs, etc.), I\u2019m curious:</p> <ol> <li><p>What tools or techniques might they use to scrape and process data from thousands of hospitals?</p></li> <li><p>How do they manage data inconsistencies or incomplete files?</p></li> <li><p>Are there any legal or compliance challenges they face while doing this?</p></li> </ol> <p>If anyone here has experience with large-scale web scraping or healthcare data aggregation, I\u2019d love to hear your insights!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/redswooshkalanick\"> /u/redswooshkalanick </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hjfp0p/how_do_companies_like_turquoisehealth_scrape/\">[link]</a></span> &#3",
        "id": 1758564,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hjfp0p/how_do_companies_like_turquoisehealth_scrape",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How do companies like Turquoise.Health scrape hospital pricing data?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-21T18:02:31+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>ive been trying to follow various tutorials on how to scrape amazon products and almost all of them are not working anymore. is there any way ?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Parking_Bluebird826\"> /u/Parking_Bluebird826 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hjfc6b/scraping_amazon/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hjfc6b/scraping_amazon/\">[comments]</a></span>",
        "id": 1758015,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hjfc6b/scraping_amazon",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "scraping amazon",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-21T16:24:05+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I run a niche accommodations aggregator for digital nomads and I&#39;m looking to use AI to find the ones that have a proper office chair + dedicated work space. This has been done for hotels (see <a href=\"https://tripoffice.com\">TripOffice</a>), but I&#39;m wondering if it&#39;s possible to build this AI tool for Airbnbs instead. I&#39;m aware Airbnb&#39;s API has been closed for years, so I&#39;m not entirely sure if this is even possible.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/NationalOwl9561\"> /u/NationalOwl9561 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hjd7u5/help_with_an_airbnb_photo_scraper_using_ai/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hjd7u5/help_with_an_airbnb_photo_scraper_using_ai/\">[comments]</a></span>",
        "id": 1757764,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hjd7u5/help_with_an_airbnb_photo_scraper_using_ai",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Help with an Airbnb photo scraper using AI",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-21T13:32:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have links to MP4 videos hosted on <code>video-node.swarmcdn.com</code>. These videos are part of an online course that I won&#39;t be able to finish in time, so I\u2019d like to download them to watch later.</p> <p>When I try to access the video links directly via my browser\u2019s network tools, the process fails\u2014they only play through the course platform.</p> <p>Is there any GitHub project or similar tool that could help with this? I\u2019ve searched but haven\u2019t found anything so far.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Express6410\"> /u/Express6410 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hj9wdj/how_to_download_videonodeswarmcdncom_videos_for/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hj9wdj/how_to_download_videonodeswarmcdncom_videos_for/\">[comments]</a></span>",
        "id": 1756935,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hj9wdj/how_to_download_videonodeswarmcdncom_videos_for",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "How to Download video-node.swarmcdn.com Videos for Offline Viewing?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-21T13:24:08+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi! I\u2019m searching for a way to scrape and analyze the data of a home renovation forum.</p> <p>I live in a country with no content creation culture, so we have all trove of helpful information buried in decades of forum posts.</p> <p>I\u2019d like to scrape the data and ask questions like: What\u2019s the most common window setup, Most recommended window suppliers, best setup for insulation etc. And I believe the data would give me invaluable answers based on local knowledge.</p> <ol> <li>Is there a tool made for this purpose, scraping and analyzing forum data?</li> <li>Is my second best alternative to scrape the data manually and run it through an LLM?</li> <li>Anything in between?</li> </ol> <p>I\u2019m not doing this to profit or sell the information, i\u2019m genuinely interested in the topic.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/gugavieira\"> /u/gugavieira </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping",
        "id": 1756936,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hj9rh0/scraping_and_analyzing_qa_forum",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping and analyzing (Q&A) forum",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-21T11:29:47+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>For public websites that want to be found/indexed by Google, I use sitemaps to determine which pages have been added or modified. This may not be as exact as continuous scraping a website, but is very cheap. Especially when collecting data over many websites. From following this subreddit I get the impression that sitemaps are not often used for this purpose. </p> <p>How do you collect data over many websites about a specific topic, say recipes without spending breaking the bank?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/WiseChemical3058\"> /u/WiseChemical3058 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hj81d0/using_sitemaps_with_scraping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hj81d0/using_sitemaps_with_scraping/\">[comments]</a></span>",
        "id": 1758565,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hj81d0/using_sitemaps_with_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Using sitemaps with scraping",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-21T00:35:32+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey everyone, as you probably know, L1nked1n doesn\u2019t allow you to search for accounts using an email address. So, I made a script that fixes this and lets you get detailed information about an account in a neat JSON format. However, if you make too many requests, L1nked1n\u2019s anti-bot system obviously starts banning the account.</p> <p>I wanted to ask for your help on how to get around this. I have an idea to create a pool of around 50\u2013100 accounts and just randomly send requests from them. This way, an account can handle anywhere from 100 to 500, sometimes even up to 1000 requests a day before getting banned. Thanks, everyone, for your attention!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/TheErl\"> /u/TheErl </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hiy2px/find_account_by_email/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hiy2px/find_ac",
        "id": 1754604,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hiy2px/find_account_by_email",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Find account by email",
        "vote": 0
    }
]