# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## I scraped 25,000 remote jobs into an excel spreadsheet - it's free. you're welcome. upvote so everyone sees it <3
 - [https://www.reddit.com/r/webscraping/comments/1hjkfdj/i_scraped_25000_remote_jobs_into_an_excel](https://www.reddit.com/r/webscraping/comments/1hjkfdj/i_scraped_25000_remote_jobs_into_an_excel)
 - RSS feed: $source
 - date published: 2024-12-21T22:08:04+00:00

<table> <tr><td> <a href="https://www.reddit.com/r/webscraping/comments/1hjkfdj/i_scraped_25000_remote_jobs_into_an_excel/"> <img src="https://external-preview.redd.it/qdNgH03iYJZiQVmPq1k-ly0Y6bcKk1Zd8LwGlK8vCOU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5ff0870782df390f2f2877770f507181f39dde62" alt="I scraped 25,000 remote jobs into an excel spreadsheet - it's free. you're welcome. upvote so everyone sees it &lt;3 " title="I scraped 25,000 remote jobs into an excel spreadsheet - it's free. you're welcome. upvote so everyone sees it &lt;3 " /> </a> </td><td> &#32; submitted by &#32; <a href="https://www.reddit.com/user/marvythemantis"> /u/marvythemantis </a> <br/> <span><a href="https://docs.google.com/spreadsheets/d/1uHZQuAFMBOvGLBtJdZA-GXzNk_Ug3EgBgCk7d1Vbrg8/edit?usp=sharing">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hjkfdj/i_scraped_25000_remote_jobs_into_an_excel/">[comments]</a></span> </td></tr></table>

## Web Scraper
 - [https://www.reddit.com/r/webscraping/comments/1hjiw8u/web_scraper](https://www.reddit.com/r/webscraping/comments/1hjiw8u/web_scraper)
 - RSS feed: $source
 - date published: 2024-12-21T20:52:11+00:00

<!-- SC_OFF --><div class="md"><p>Hi everyone, I work for a small business in Canada that sells solar panels, batteries, and generators. I’m looking to build a scraper to gather product and pricing data from our competitors’ websites. The challenge is that some of the product names differ slightly, so I’m exploring ways to categorize them as the same product using an algorithm or model, like a machine learning approach, to make comparisons easier.</p> <p>We have four main competitors, and while they don’t have as many products as we do, some of their top-selling items overlap with ours, which are crucial to our business. We’re looking at scraping around 700-800 products per competitor, so efficiency and scalability are important.</p> <p>Does anyone have recommendations on the best frameworks, tools, or approaches to tackle this task, especially for handling product categorization effectively? Any advice would be greatly appreciated!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <

## Tools to scrape pdf
 - [https://www.reddit.com/r/webscraping/comments/1hjhx87/tools_to_scrape_pdf](https://www.reddit.com/r/webscraping/comments/1hjhx87/tools_to_scrape_pdf)
 - RSS feed: $source
 - date published: 2024-12-21T20:04:28+00:00

<!-- SC_OFF --><div class="md"><p>Hello,</p> <p>I would like to scrape a pdf especially some Highlighted word. I would like to use an easy tool because I&#39;m not really good at coding... I ve tried &quot;Parseur&quot; but the results were not what I&#39;ve excepted.</p> <p>Thank you very much!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Legitimate_Mud_9245"> /u/Legitimate_Mud_9245 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hjhx87/tools_to_scrape_pdf/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hjhx87/tools_to_scrape_pdf/">[comments]</a></span>

## Automating Job Post Updates in WordPress with WP Job Board Manager
 - [https://www.reddit.com/r/webscraping/comments/1hjfx9c/automating_job_post_updates_in_wordpress_with_wp](https://www.reddit.com/r/webscraping/comments/1hjfx9c/automating_job_post_updates_in_wordpress_with_wp)
 - RSS feed: $source
 - date published: 2024-12-21T18:29:44+00:00

<!-- SC_OFF --><div class="md"><p>I am working on importing job postings from a job site and want to scrape the site. I want the job postings to update automatically if they are removed from the source site. I plan to achieve this by checking the URL to see if it still exists on the scraped site. The plugin I use is WordPress with WP Job Board Manager. Are there better ways to do this, perhaps with existing plugins?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Historical_Cook_942"> /u/Historical_Cook_942 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hjfx9c/automating_job_post_updates_in_wordpress_with_wp/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hjfx9c/automating_job_post_updates_in_wordpress_with_wp/">[comments]</a></span>

## How do companies like Turquoise.Health scrape hospital pricing data?
 - [https://www.reddit.com/r/webscraping/comments/1hjfp0p/how_do_companies_like_turquoisehealth_scrape](https://www.reddit.com/r/webscraping/comments/1hjfp0p/how_do_companies_like_turquoisehealth_scrape)
 - RSS feed: $source
 - date published: 2024-12-21T18:19:05+00:00

<!-- SC_OFF --><div class="md"><p>I’ve been researching companies like Turquoise Health and their ability to aggregate massive amounts of hospital pricing data. Given the variety and complexity of hospital pricing transparency rules and formats (e.g., machine-readable files, PDFs, etc.), I’m curious:</p> <ol> <li><p>What tools or techniques might they use to scrape and process data from thousands of hospitals?</p></li> <li><p>How do they manage data inconsistencies or incomplete files?</p></li> <li><p>Are there any legal or compliance challenges they face while doing this?</p></li> </ol> <p>If anyone here has experience with large-scale web scraping or healthcare data aggregation, I’d love to hear your insights!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/redswooshkalanick"> /u/redswooshkalanick </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hjfp0p/how_do_companies_like_turquoisehealth_scrape/">[link]</a></span> &#3

## scraping amazon
 - [https://www.reddit.com/r/webscraping/comments/1hjfc6b/scraping_amazon](https://www.reddit.com/r/webscraping/comments/1hjfc6b/scraping_amazon)
 - RSS feed: $source
 - date published: 2024-12-21T18:02:31+00:00

<!-- SC_OFF --><div class="md"><p>ive been trying to follow various tutorials on how to scrape amazon products and almost all of them are not working anymore. is there any way ?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Parking_Bluebird826"> /u/Parking_Bluebird826 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hjfc6b/scraping_amazon/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hjfc6b/scraping_amazon/">[comments]</a></span>

## Help with an Airbnb photo scraper using AI
 - [https://www.reddit.com/r/webscraping/comments/1hjd7u5/help_with_an_airbnb_photo_scraper_using_ai](https://www.reddit.com/r/webscraping/comments/1hjd7u5/help_with_an_airbnb_photo_scraper_using_ai)
 - RSS feed: $source
 - date published: 2024-12-21T16:24:05+00:00

<!-- SC_OFF --><div class="md"><p>I run a niche accommodations aggregator for digital nomads and I&#39;m looking to use AI to find the ones that have a proper office chair + dedicated work space. This has been done for hotels (see <a href="https://tripoffice.com">TripOffice</a>), but I&#39;m wondering if it&#39;s possible to build this AI tool for Airbnbs instead. I&#39;m aware Airbnb&#39;s API has been closed for years, so I&#39;m not entirely sure if this is even possible.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/NationalOwl9561"> /u/NationalOwl9561 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hjd7u5/help_with_an_airbnb_photo_scraper_using_ai/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hjd7u5/help_with_an_airbnb_photo_scraper_using_ai/">[comments]</a></span>

## How to Download video-node.swarmcdn.com Videos for Offline Viewing?
 - [https://www.reddit.com/r/webscraping/comments/1hj9wdj/how_to_download_videonodeswarmcdncom_videos_for](https://www.reddit.com/r/webscraping/comments/1hj9wdj/how_to_download_videonodeswarmcdncom_videos_for)
 - RSS feed: $source
 - date published: 2024-12-21T13:32:06+00:00

<!-- SC_OFF --><div class="md"><p>I have links to MP4 videos hosted on <code>video-node.swarmcdn.com</code>. These videos are part of an online course that I won&#39;t be able to finish in time, so I’d like to download them to watch later.</p> <p>When I try to access the video links directly via my browser’s network tools, the process fails—they only play through the course platform.</p> <p>Is there any GitHub project or similar tool that could help with this? I’ve searched but haven’t found anything so far.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Express6410"> /u/Express6410 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hj9wdj/how_to_download_videonodeswarmcdncom_videos_for/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hj9wdj/how_to_download_videonodeswarmcdncom_videos_for/">[comments]</a></span>

## Scraping and analyzing (Q&A) forum
 - [https://www.reddit.com/r/webscraping/comments/1hj9rh0/scraping_and_analyzing_qa_forum](https://www.reddit.com/r/webscraping/comments/1hj9rh0/scraping_and_analyzing_qa_forum)
 - RSS feed: $source
 - date published: 2024-12-21T13:24:08+00:00

<!-- SC_OFF --><div class="md"><p>Hi! I’m searching for a way to scrape and analyze the data of a home renovation forum.</p> <p>I live in a country with no content creation culture, so we have all trove of helpful information buried in decades of forum posts.</p> <p>I’d like to scrape the data and ask questions like: What’s the most common window setup, Most recommended window suppliers, best setup for insulation etc. And I believe the data would give me invaluable answers based on local knowledge.</p> <ol> <li>Is there a tool made for this purpose, scraping and analyzing forum data?</li> <li>Is my second best alternative to scrape the data manually and run it through an LLM?</li> <li>Anything in between?</li> </ol> <p>I’m not doing this to profit or sell the information, i’m genuinely interested in the topic.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/gugavieira"> /u/gugavieira </a> <br/> <span><a href="https://www.reddit.com/r/webscraping

## Using sitemaps with scraping
 - [https://www.reddit.com/r/webscraping/comments/1hj81d0/using_sitemaps_with_scraping](https://www.reddit.com/r/webscraping/comments/1hj81d0/using_sitemaps_with_scraping)
 - RSS feed: $source
 - date published: 2024-12-21T11:29:47+00:00

<!-- SC_OFF --><div class="md"><p>For public websites that want to be found/indexed by Google, I use sitemaps to determine which pages have been added or modified. This may not be as exact as continuous scraping a website, but is very cheap. Especially when collecting data over many websites. From following this subreddit I get the impression that sitemaps are not often used for this purpose. </p> <p>How do you collect data over many websites about a specific topic, say recipes without spending breaking the bank?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/WiseChemical3058"> /u/WiseChemical3058 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hj81d0/using_sitemaps_with_scraping/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hj81d0/using_sitemaps_with_scraping/">[comments]</a></span>

## Find account by email
 - [https://www.reddit.com/r/webscraping/comments/1hiy2px/find_account_by_email](https://www.reddit.com/r/webscraping/comments/1hiy2px/find_account_by_email)
 - RSS feed: $source
 - date published: 2024-12-21T00:35:32+00:00

<!-- SC_OFF --><div class="md"><p>Hey everyone, as you probably know, L1nked1n doesn’t allow you to search for accounts using an email address. So, I made a script that fixes this and lets you get detailed information about an account in a neat JSON format. However, if you make too many requests, L1nked1n’s anti-bot system obviously starts banning the account.</p> <p>I wanted to ask for your help on how to get around this. I have an idea to create a pool of around 50–100 accounts and just randomly send requests from them. This way, an account can handle anywhere from 100 to 500, sometimes even up to 1000 requests a day before getting banned. Thanks, everyone, for your attention!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/TheErl"> /u/TheErl </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hiy2px/find_account_by_email/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hiy2px/find_ac

