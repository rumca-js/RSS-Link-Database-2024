[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-23T21:48:53+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m trying to scrape different social media types for post links and their thumbnail. This works well on my local device (~3 seconds), but takes 9+ seconds on my vps. Is there any way I can speed this up? Currently I&#39;m only using rotating user agents, blocking css etc., and using proxies. Do I have to use cookies or is there anything else I&#39;m missing? I&#39;m getting the data by entering profile links and am not mass scraping. Only 6 posts per user because I need that for my softwares front end.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/bad-ass-jit\"> /u/bad-ass-jit </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hkyb55/scraping_social_media_posts_is_too_slow/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hkyb55/scraping_social_media_posts_is_too_slow/\">[comments]</a></span>",
        "id": 1769919,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hkyb55/scraping_social_media_posts_is_too_slow",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Scraping social media posts is too slow",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-23T21:20:34+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hey!</p> <p>I need a web scraper that can get a set of instructions and implement them on a set of pre-chosen addresses. Basically I need it to do stuff like go into a page with listings, filter (it might differ between sites) extract each listing data, if there is a &quot;load more&quot; then do it of course, then go through all the pages and implement the same process. </p> <p>I&#39;m wondering if there is anything out there dynamic enough that I can just do this &quot;script&quot; without having to implement specific flows for each site individually. </p> <p>Thanks a lot! </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ruthenz1\"> /u/ruthenz1 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hkxq25/looking_for_a_dynamic_probably_ai_web_scraper/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hkxq25/looking_for_a_dynamic_probably_ai_web_scraper/\">[c",
        "id": 1769920,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hkxq25/looking_for_a_dynamic_probably_ai_web_scraper",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Looking for a dynamic (probably AI) web scraper",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-23T08:43:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>FBREF Response Code 403</p> <p>I\u2019ve built a web scraper for FBREF.com that I\u2019ve been using for the past couple years, but this morning I\u2019m receiving the error code 403.</p> <p>Anyone else have a similar issue?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/arjybarji\"> /u/arjybarji </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hkjnjc/fbref_response_code_403/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hkjnjc/fbref_response_code_403/\">[comments]</a></span>",
        "id": 1765479,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hkjnjc/fbref_response_code_403",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "FBREF Response Code 403",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-23T04:41:06+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I&#39;m going to be using the InfluxDB cloud free plan but I&#39;m unsure of whether the alerts would be a problem. The following is from their page.<br/> <strong>Alerts</strong>:</p> <ul> <li>2 checks</li> <li>2 notification rules</li> <li>Unlimited Slack notification endpoints</li> </ul> <p>Firstly what would I be using them for? The system malfunctioning by not writing new data? Or would this be for alerts for a large change in data that is unexpected?<br/> Before I commit to using Influx I want to make sure this isn&#39;t something that would make me not use their service. Thx</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Immortalphoenixphire\"> /u/Immortalphoenixphire </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hkg8lj/are_alerts_something_necessary_in_a_db/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hkg8lj/are_alerts_something_necessa",
        "id": 1764855,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hkg8lj/are_alerts_something_necessary_in_a_db",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Are alerts something necessary in a db?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-23T04:00:37+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>So some time ago I came across a post somewhere on the internet that mentioned packages for web automation that can be used for scraping, one of which was DrissionPage, which worked great but there is also another package mentioned that works similar to DrissionPage which isn&#39;t based on using webdriver, but sadly I don&#39;t recall the name of the repo, does anyone happens to know about it?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/OtwakO\"> /u/OtwakO </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hkfkg9/python_web_automation_package_that_isnt_based_on/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hkfkg9/python_web_automation_package_that_isnt_based_on/\">[comments]</a></span>",
        "id": 1764856,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hkfkg9/python_web_automation_package_that_isnt_based_on",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Python web automation package that isn't based on webdriver.",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_dead_since": null,
        "date_published": "2024-12-23T00:03:56+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Guys is it impossible to find free good working proxy\u2019s now days?</p> <p>I Just want Indian or Argentina proxy real quick but I didn\u2019t find a single one. Or am I noob? Please help me out </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ParticularCod2815\"> /u/ParticularCod2815 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hkbbs3/free_proxy/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1hkbbs3/free_proxy/\">[comments]</a></span>",
        "id": 1764179,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1hkbbs3/free_proxy",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Free Proxy",
        "vote": 0
    }
]