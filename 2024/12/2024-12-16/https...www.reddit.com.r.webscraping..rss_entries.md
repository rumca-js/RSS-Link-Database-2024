# Source:webscraping, URL:https://www.reddit.com/r/webscraping/.rss, language:en

## Technical Safety BC Webscraping Project
 - [https://www.reddit.com/r/webscraping/comments/1hfskxq/technical_safety_bc_webscraping_project](https://www.reddit.com/r/webscraping/comments/1hfskxq/technical_safety_bc_webscraping_project)
 - RSS feed: $source
 - date published: 2024-12-16T20:25:18+00:00

<!-- SC_OFF --><div class="md"><p>Hi everyone,</p> <p>Iâ€™m working on an exciting web scraping project and would love your input to determine its feasibility and any potential challenges. The task involves scraping detailed business information from the Technical Safety BC website, navigating through multiple technologies (e.g., Electrical, Gas, Elevating Devices), handling pagination for ~7,050 business entries, and extracting data from individual business pages.</p> <p>Here&#39;s the URL: <a href="https://www.technicalsafetybc.ca/regulatory-resources/find-a-licensed-contractor">https://www.technicalsafetybc.ca/regulatory-resources/find-a-licensed-contractor</a></p> <p>I also published my project workflow online for a more detailed breakdown of how I&#39;m planning to go about it here: <a href="https://docs.google.com/document/d/e/2PACX-1vQZB3nYUNW8YrtyelBZm_MsAEiDbZEDpsGlWZ4ySmnTyRlH794su7UeO2g_1w4DzbtIIhbROpx121dG/pub">https://docs.google.com/document/d/e/2PACX-1vQZB3nYUNW8YrtyelBZ

## Protected workbook in Google Sheets
 - [https://www.reddit.com/r/webscraping/comments/1hfnlkq/protected_workbook_in_google_sheets](https://www.reddit.com/r/webscraping/comments/1hfnlkq/protected_workbook_in_google_sheets)
 - RSS feed: $source
 - date published: 2024-12-16T16:56:30+00:00

<!-- SC_OFF --><div class="md"><p>A high-profile scientific paper in the field released its summary data (as is supposed to according to the data provider and journal rules) but idiotically enabled &quot;protection&quot; for Google Sheets. You can view but you can&#39;t copy-paste things which is completely against the spirit of what they are meant to do (thousands of records per sheet, impossible to write it all down.</p> <p>I tried obvious things like full-page screenshot, saving the page, PDF, etc. but Sheets manages to block that. </p> <p>Example page:</p> <p><a href="https://proteome-phenome-atlas.com/csv?src=L2FwaS9nZXRXaWRlRG93bmxvYWRDc3Y/c2VhcmNoQXJnPVR5cGUgMSBkaWFiZXRlcyB3aXRob3V0IGNvbXBsaWNhdGlvbnMmZGlzZWFzZVR5cGU9aW5jaWRlbnQmcG9wdWxhdGlvbj1hbGwmbGV2ZWw9MSZpc0Rpc2Vhc2U9dHJ1ZSZpc1NlbnNpdGl2ZT10cnVl&amp;name=Type%201%20diabetes%20without%20complications">https://proteome-phenome-atlas.com/csv?src=L2FwaS9nZXRXaWRlRG93bmxvYWRDc3Y/c2VhcmNoQXJnPVR5cGUgMSBkaWFiZXRlcyB3aXRob3V0IGNv

## Big update to Scrapling library!
 - [https://www.reddit.com/r/webscraping/comments/1hfmul8/big_update_to_scrapling_library](https://www.reddit.com/r/webscraping/comments/1hfmul8/big_update_to_scrapling_library)
 - RSS feed: $source
 - date published: 2024-12-16T16:23:54+00:00

<table> <tr><td> <a href="https://www.reddit.com/r/webscraping/comments/1hfmul8/big_update_to_scrapling_library/"> <img src="https://external-preview.redd.it/fsrttsl7asqWYh-wJKwmxCMs6B4lHcDT7rXtPOvKRaI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=06c6ace3f90f0c62a62e323c2459dec0ddb22f8d" alt="Big update to Scrapling library!" title="Big update to Scrapling library!" /> </a> </td><td> <!-- SC_OFF --><div class="md"><p>Scrapling 0.2.9 has been released now with a lot of new features like async support with better performance and stealth!</p> <p>The last time I talked about Scrapling here was in 0.2 and a lot of updates have been done since then.</p> <p>Check it out and tell me what you think.</p> <p><a href="https://github.com/D4Vinci/Scrapling">https://github.com/D4Vinci/Scrapling</a></p> <p><a href="https://preview.redd.it/5k675opdl87e1.jpg?width=2949&amp;format=pjpg&amp;auto=webp&amp;s=4b101bf5aeadf3fa1a3814cc7e8301eff89cd977">https://preview.redd.it/5k675opdl87e1.jpg?width=2949

## Scraping Event Data and estimating Visitor Counts
 - [https://www.reddit.com/r/webscraping/comments/1hfhl3u/scraping_event_data_and_estimating_visitor_counts](https://www.reddit.com/r/webscraping/comments/1hfhl3u/scraping_event_data_and_estimating_visitor_counts)
 - RSS feed: $source
 - date published: 2024-12-16T12:02:05+00:00

<!-- SC_OFF --><div class="md"><p>Hey there,</p> <p>I hope this is the right subreddit to ask this kind of question, since it somewhat falls in the niche of webscraping :)</p> <p>I&#39;m working on a project where I want to figure out how many people are likely to attend events or be at certain locations at specific times. The plan is to scrape data from event calendars (like dates, times, locations) and then use some kind of existing tools or services to estimate visitor numbers. Im based in Austria and specifically looking at Austrian events if that&#39;s releveant</p> <p>So far, I&#39;ve looked into services like PredictHQ and <a href="http://Placer.ai">Placer.ai</a> which seem to offer some tools where i can just plug in event data and (hopefully) get an estimated visitor count returned. </p> <p>Here are some questions I have:</p> <ol> <li>What are your thoughts on how to best scrape event data? Websites like Fb, Eventbrite but also regional/local websites will be relevant</li> <

## I build Random User Agent for Scraping
 - [https://www.reddit.com/r/webscraping/comments/1hfhbdk/i_build_random_user_agent_for_scraping](https://www.reddit.com/r/webscraping/comments/1hfhbdk/i_build_random_user_agent_for_scraping)
 - RSS feed: $source
 - date published: 2024-12-16T11:44:59+00:00

<!-- SC_OFF --><div class="md"><p>I am doing some scraping work to scrape some of job posting website I do it regularly and I read some of blog they said try to use proxy and rotate your user agent on every request </p> <p>So I build one npm package for it Here is link - <a href="https://www.npmjs.com/package/@rahulxf/random-user-agent">https://www.npmjs.com/package/@rahulxf/random-user-agent</a></p> <p>I need your some of suggestions so I can improve it ? </p> <p>Thank you in advance </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Manzil_Info180"> /u/Manzil_Info180 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hfhbdk/i_build_random_user_agent_for_scraping/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hfhbdk/i_build_random_user_agent_for_scraping/">[comments]</a></span>

## Is Scraping with GitHub Action is good idea
 - [https://www.reddit.com/r/webscraping/comments/1hfh98s/is_scraping_with_github_action_is_good_idea](https://www.reddit.com/r/webscraping/comments/1hfh98s/is_scraping_with_github_action_is_good_idea)
 - RSS feed: $source
 - date published: 2024-12-16T11:41:02+00:00

<!-- SC_OFF --><div class="md"><p>I am scraping some of job portal using nodejs with rotating user agent and running cron job on GitHub action </p> <p>I am worried about my GitHub profile like if the website blocked the GitHub ip ???</p> <p>Is it good idea to scrape using GitHub action??</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Manzil_Info180"> /u/Manzil_Info180 </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hfh98s/is_scraping_with_github_action_is_good_idea/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hfh98s/is_scraping_with_github_action_is_good_idea/">[comments]</a></span>

## Multi-sources rich social media dataset - a full month
 - [https://www.reddit.com/r/webscraping/comments/1hfgytm/multisources_rich_social_media_dataset_a_full](https://www.reddit.com/r/webscraping/comments/1hfgytm/multisources_rich_social_media_dataset_a_full)
 - RSS feed: $source
 - date published: 2024-12-16T11:21:23+00:00

<!-- SC_OFF --><div class="md"><p>Hey, data enthusiasts and web scraping aficionados!<br/> Weâ€™re thrilled to share a massive new social media dataset just dropped on Hugging Face! ðŸš€</p> <h1>Access the Data:</h1> <h1><a href="https://huggingface.co/datasets/Exorde/exorde-social-media-one-month-2024">ðŸ‘‰Exorde Social Media One Month 2024</a></h1> <h1>Whatâ€™s Inside?</h1> <ul> <li><strong>Scale</strong>: 270 million posts collected over one month (Nov 14 - Dec 13, 2024)</li> <li><strong>Methodology</strong>: Total sampling of the web, statistical capture of <strong>all topics</strong></li> <li><strong>Sources</strong>: 6000+ platforms including Reddit, Twitter, BlueSky, YouTube, Mastodon, Lemmy, and more</li> <li><strong>Rich Annotations</strong>: Original text, metadata, emotions, sentiment, top keywords, and themes</li> <li><strong>Multi-language</strong>: Covers 122 languages with translated keywords</li> <li><strong>Unique features:</strong> English top keywords, allowing super-quick s

## Got blocked while scraping
 - [https://www.reddit.com/r/webscraping/comments/1hf8tmr/got_blocked_while_scraping](https://www.reddit.com/r/webscraping/comments/1hf8tmr/got_blocked_while_scraping)
 - RSS feed: $source
 - date published: 2024-12-16T02:19:07+00:00

<!-- SC_OFF --><div class="md"><p>The prompt said it should be 5 minutes only but Iâ€™ve been blocked since last night. What can I do to continue?</p> <p>Hereâ€™s what I tried that did not work 1. Changing device (both ipad and iphone also blocked) 2. Changing browser (safari and chrome)</p> <p>Things I can improve to prevent getting blocked next time based on research: 1. Proxy and heading rotation 2. Variable timeouts</p> <p>Iâ€™m using beautiful soup and requests</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/cordelia_foxx"> /u/cordelia_foxx </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hf8tmr/got_blocked_while_scraping/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hf8tmr/got_blocked_while_scraping/">[comments]</a></span>

## Need a website for web scraping nutritional data
 - [https://www.reddit.com/r/webscraping/comments/1hf80pc/need_a_website_for_web_scraping_nutritional_data](https://www.reddit.com/r/webscraping/comments/1hf80pc/need_a_website_for_web_scraping_nutritional_data)
 - RSS feed: $source
 - date published: 2024-12-16T01:37:01+00:00

<!-- SC_OFF --><div class="md"><p>I am actually learning web scraping using beautiful soup and selenium and have decided to work on a project that will be useful for keeping log of what I ate and how much nutrition I got throughout the day. Anybody knows any website that allows us to scrape nutritional data for free?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Tara_Babu"> /u/Tara_Babu </a> <br/> <span><a href="https://www.reddit.com/r/webscraping/comments/1hf80pc/need_a_website_for_web_scraping_nutritional_data/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/webscraping/comments/1hf80pc/need_a_website_for_web_scraping_nutritional_data/">[comments]</a></span>

