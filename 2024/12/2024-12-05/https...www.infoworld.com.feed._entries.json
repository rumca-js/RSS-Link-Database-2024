[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_published": "2024-12-05T22:01:57+00:00",
        "description": "<div id=\"remove_no_follow\">\n\t\t<div class=\"grid grid--cols-10@md grid--cols-8@lg article-column\">\n\t\t\t\t\t  <div class=\"col-12 col-10@md col-6@lg col-start-3@lg\">\n\t\t\t\t\t\t<div class=\"article-column__content\">\n<section class=\"wp-block-bigbite-multi-title\"><div class=\"container\"></div></section>\n\n\n\n<p><a href=\"https://www.infoworld.com/article/3544913/openai-updates-api-with-model-distillation-prompt-caching-abilities.html\">OpenAI</a> has introduced the Usage API, an API that allows enterprises to track their activity across the OpenAI API. With the Usage API, OpenAI API usage and costs can be assessed programmatically, the company said. \u00a0</p>\n\n\n\n<p>Announced December 4, the <a href=\"https://platform.openai.com/docs/api-reference/usage\">OpenAI Usage API </a>\u00a0monitors token usage by minute, hour, or day and filters usage data by factors such as model, API key, project ID, and user ID. Users can check daily spending via a costs endpoint for budget oversight. The Usage API, OpenAI said, is buil",
        "id": 1653121,
        "language": "en-US",
        "link": "https://www.infoworld.com/article/3618202/openai-unveils-api-for-tracking-openai-api-usage-costs.html",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 468,
        "source_url": "https://www.infoworld.com/feed/",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "OpenAI unveils API for tracking OpenAI API usage, costs",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_published": "2024-12-05T20:06:00+00:00",
        "description": "<div id=\"remove_no_follow\">\n\t\t<div class=\"grid grid--cols-10@md grid--cols-8@lg article-column\">\n\t\t\t\t\t  <div class=\"col-12 col-10@md col-6@lg col-start-3@lg\">\n\t\t\t\t\t\t<div class=\"article-column__content\">\n<section class=\"wp-block-bigbite-multi-title\"><div class=\"container\"></div></section>\n\n\n\n<p>Google has introduced a new family of<a href=\"https://www.infoworld.com/article/2337065/google-unveils-paligemma-announces-gemma-2.html\"> PaliGemma</a> vision-language models, offering scalable performance, long captioning, and support for specialized tasks.</p>\n\n\n\n<p>PaliGemma 2 was <a href=\"https://developers.googleblog.com/en/introducing-paligemma-2-powerful-vision-language-models-simple-fine-tuning/\">announced December 5</a>, nearly seven months after the initial version launched as the first vision-language model in the <a href=\"https://www.infoworld.com/article/2336188/google-stresses-safety-with-gemma-open-models.html\">Gemma</a> family. Building on <a href=\"https://www.infoworld.com/arti",
        "id": 1652311,
        "language": "en-US",
        "link": "https://www.infoworld.com/article/3618131/google-introduces-paligemma-2-vision-language-ai-models.html",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 468,
        "source_url": "https://www.infoworld.com/feed/",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Google introduces PaliGemma 2 vision-language AI models",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_published": "2024-12-05T09:00:00+00:00",
        "description": "<div id=\"remove_no_follow\">\n\t\t<div class=\"grid grid--cols-10@md grid--cols-8@lg article-column\">\n\t\t\t\t\t  <div class=\"col-12 col-10@md col-6@lg col-start-3@lg\">\n\t\t\t\t\t\t<div class=\"article-column__content\">\n<section class=\"wp-block-bigbite-multi-title\"><div class=\"container\"></div></section>\n\n\n\n<p>Modern AI is about a lot more than chatbots, as shown by Microsoft\u2019s Ignite 2024 pivot to using its stable of <a href=\"https://www.infoworld.com/article/3709489/large-language-models-the-foundations-of-generative-ai.html\">large and small language models</a> to power <a href=\"https://www.infoworld.com/article/2335891/building-ai-agents-with-semantic-kernel.html\">autonomous agents</a>. Much of its focus was on using productivity tools and software-generated events to trigger AI-orchestrated workflows, but the company touched on <a href=\"https://techcommunity.microsoft.com/blog/azure-ai-services-blog/transforming-video-into-value-with-azure-ai-content-understanding/4297114\">the importance of multi",
        "id": 1647614,
        "language": "en-US",
        "link": "https://www.infoworld.com/article/3617403/get-started-with-azure-ai-content-understanding.html",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 86,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 468,
        "source_url": "https://www.infoworld.com/feed/",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Get started with Azure AI Content Understanding",
        "vote": 0
    }
]