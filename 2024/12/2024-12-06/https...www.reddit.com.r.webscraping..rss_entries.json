[
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_published": "2024-12-06T23:27:04+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hello, so I&#39;ve been working on a personal project for quite some time now and had written quite a few processes that involved web scraping from the following website <a href=\"https://www.oddsportal.com/basketball/usa/nba-2023-2024/results/#/page/2/\">https://www.oddsportal.com/basketball/usa/nba-2023-2024/results/#/page/2/</a></p> <p>I had been scraping data by inspecting the element and going to the network tab to find the hidden API, which had been working just fine. After taking maybe a month off of this project, I come back and try to scrape data from the website, only to find that the API I had been using no longer seems to work. When I try to find a new API, I find my issue: instead of returning the data I want in raw JSON form, it is now encrypted. Is there anyway around this, or will I have to resort to Selenium?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/captainmugen\"> /u/captainmugen </a> <br/>",
        "id": 1660568,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1h8eur5/hidden_api_no_longer_works",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Hidden API No Longer Works?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_published": "2024-12-06T23:25:34+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>hello! any one know about how can i scrape data from android app using python or any other technique???</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Mysterious-Emu1283\"> /u/Mysterious-Emu1283 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1h8etmj/android_app_scraping/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1h8etmj/android_app_scraping/\">[comments]</a></span>",
        "id": 1660569,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1h8etmj/android_app_scraping",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "android app scraping",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_published": "2024-12-06T22:12:22+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi all, I am having been some web scraping from time to time, I have used Python BS4 but I found the headless browser tools are much better at bypassing.</p> <p>So what yours tools of choice? In terms of ease of use, can it be bundle to an application, community support.</p> <p>I used selenium, playwright, and little bit of puppeteer, mainly for test automations, I hope to hear from you!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Safe_Owl_6123\"> /u/Safe_Owl_6123 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1h8d8ym/which_tool_do_you_prefer/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1h8d8ym/which_tool_do_you_prefer/\">[comments]</a></span>",
        "id": 1660276,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1h8d8ym/which_tool_do_you_prefer",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Which tool do you prefer?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_published": "2024-12-06T21:05:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>My scrapers get blocked when I run from a datacenter and residential proxies are too expensive. Instead, I have a 2016 Intel MacBook Pro I&#39;d like to set up to automatically run my scrapers. It would be plugged in 24/7, lid closed. </p> <p>Is this a reasonable solution? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/goblerfan19\"> /u/goblerfan19 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1h8bql5/old_macbook_pro_as_a_scraping_server/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1h8bql5/old_macbook_pro_as_a_scraping_server/\">[comments]</a></span>",
        "id": 1660277,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1h8bql5/old_macbook_pro_as_a_scraping_server",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Old MacBook Pro as a scraping server",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_published": "2024-12-06T16:18:57+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>i try use ixbrowser, and they create new chrome profile with custom fingerprint.</p> <p>i need create my own chrome and can custom fingerprint to, </p> <p>any one know how to build this ?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Alternative_Brain478\"> /u/Alternative_Brain478 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1h851u0/anyone_know_how_to_create_own_browser_with_custom/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1h851u0/anyone_know_how_to_create_own_browser_with_custom/\">[comments]</a></span>",
        "id": 1658206,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1h851u0/anyone_know_how_to_create_own_browser_with_custom",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "anyone know how to create own browser with custom fingerprint",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_published": "2024-12-06T15:06:16+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I have this website that I want to scrappe through python requests, and not a headless browser, the problem is I couldn&#39;t find how the url changes when you click on a filter (e.g 1 BHK or something else) when make a filter, the relative url changes to a weird typo !</p> <p>Here is the link : <a href=\"https://housing.com/in/buy/searches/mumbai\">https://housing.com/in/buy/searches/mumbai</a></p> <p>Try to change the Bhk type and select two types of bhk for example, and you&#39;ll have a link like this : <a href=\"https://housing.com/in/buy/searches/CcPskwz0ocdh7q42r5\">https://housing.com/in/buy/searches/CcPskwz0ocdh7q42r5</a> (selected 2 bhk, 3 bhk).</p> <p>Please help me out to reverse engineer this website, I spent nights without no results !</p> <p>I inspected all the APIs in network tab, the first api sent has in its payload the hash value that I want, so I don&#39;t know from where he get it !</p> </div><!-- SC_ON --> &#32; submitted by &#32; <",
        "id": 1659878,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1h83dnv/i_cant_reverse_engineer_this_website_when_i_apply",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "I can't reverse engineer this website when I apply filters",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_published": "2024-12-06T13:22:28+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>What kind of tools do you use? Has it been effective?</p> <p>Is it better to use an LLM for this or to train your own AI?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Spirited_Paramedic_8\"> /u/Spirited_Paramedic_8 </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1h818b7/is_anybody_using_ai_scraping_to_find_undervalued/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1h818b7/is_anybody_using_ai_scraping_to_find_undervalued/\">[comments]</a></span>",
        "id": 1656731,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1h818b7/is_anybody_using_ai_scraping_to_find_undervalued",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Is anybody using AI + Scraping to find undervalued items?",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_published": "2024-12-06T11:42:46+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>I came across an interesting <strong>Python-based Email Automation Tool</strong> built using Scrapy that makes email scraping and campaign management a breeze. Here\u2019s a quick overview of what it offers:</p> <h1>Key Features:</h1> <ul> <li><strong>Web Scraping</strong>: Extracts email addresses from websites using Scrapy.</li> <li><strong>Data Validation</strong>: Filters out invalid and duplicate emails.</li> <li><strong>Email Automation</strong>: After scraping emails, it automatically triggers email campaigns to those addresses.</li> </ul> <h1>How It Works:</h1> <ol> <li>Set up a Python environment and install Scrapy.</li> <li>Run the tool to scrape email addresses from target websites.</li> <li>Use the collected emails for an automated email campaign.</li> </ol> <p>This tool is great for anyone looking to automate their email outreach, especially for researchers and marketers who want to streamline their processes.</p> <p>You can check out the ful",
        "id": 1656314,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1h7zi80/email_automation_tool_with_scrapy",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Email Automation Tool with Scrapy",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_published": "2024-12-06T06:22:48+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Hi, I am trying to scrape data from a car aggregator and i am having issues with the api endpoint.</p> <p>The issue is with <a href=\"http://www.autotempest.com\">www.autotempest.com</a> api endpoint for search. I can see the initial list of results but can&#39;t figure out how to get the next page of results. There is a searchAfter which includes information from the last car and clicking the &quot;more cars&quot; button gives you a new set of results with the searchAfter changed.</p> <p>I can&#39;t seem to figure out how to query this. There seems to be some connection between the token and searchAfter or something. Any help would be appreciated.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Evilbunz\"> /u/Evilbunz </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1h7v2i2/need_help_finding_next_page_results_from_api/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscrap",
        "id": 1654672,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1h7v2i2/need_help_finding_next_page_results_from_api",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Need help finding next page results from api endpoint",
        "vote": 0
    },
    {
        "age": null,
        "album": "",
        "author": null,
        "bookmarked": false,
        "comments": [],
        "date_published": "2024-12-06T03:04:39+00:00",
        "description": "<!-- SC_OFF --><div class=\"md\"><p>Are there any tools that let you scrape emails based on live search engine results? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/BergHeimDorf\"> /u/BergHeimDorf </a> <br/> <span><a href=\"https://www.reddit.com/r/webscraping/comments/1h7rke5/email_scraping_from_live_search_results/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/webscraping/comments/1h7rke5/email_scraping_from_live_search_results/\">[comments]</a></span>",
        "id": 1654059,
        "language": null,
        "link": "https://www.reddit.com/r/webscraping/comments/1h7rke5/email_scraping_from_live_search_results",
        "manual_status_code": 0,
        "page_rating": 27,
        "page_rating_contents": 85,
        "page_rating_visits": 0,
        "page_rating_votes": 0,
        "permanent": false,
        "source__id": 467,
        "source_url": "https://www.reddit.com/r/webscraping/.rss",
        "status_code": 0,
        "tags": [],
        "thumbnail": null,
        "title": "Email scraping from live search results",
        "vote": 0
    }
]